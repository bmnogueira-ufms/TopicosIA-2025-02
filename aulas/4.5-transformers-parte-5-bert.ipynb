{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v5pELG5FoMx2",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1761098195795,
     "user": {
      "displayName": "Bruno Magalhaes Nogueira",
      "userId": "18320277366917905276"
     },
     "user_tz": 240
    },
    "id": "v5pELG5FoMx2"
   },
   "outputs": [],
   "source": [
    "# !pip install transformers==4.57.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a0453",
   "metadata": {
    "id": "0c2a0453"
   },
   "source": [
    "# 5.1 - Introdução ao BERT: Pré-treinamento e Arquitetura\n",
    "\n",
    "Na aula anterior, exploramos detalhadamente o **Transformer**, arquitetura proposta no artigo *Attention is All You Need (Vaswani et al., 2017)*.  \n",
    "Vimos como o modelo substitui as recorrências por **atenção auto-regressiva**, resultando em paralelização e aprendizado mais eficiente de dependências de longo alcance.\n",
    "\n",
    "O **BERT (Bidirectional Encoder Representations from Transformers)**, proposto por **Devlin et al. (2018)**, é um passo além dessa ideia.  \n",
    "Ele se baseia **exclusivamente na parte do encoder do Transformer**, mas introduz um novo paradigma: **aprendizado de representações de linguagem profundas e bidirecionais**, usando **pré-treinamento auto-supervisionado**.\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/bert_pt_ft.png\" width=\"50%%\">\n",
    "\n",
    "Fonte: Devlin et al. (2018)\n",
    "\n",
    "---\n",
    "\n",
    "## Por que BERT?\n",
    "\n",
    "Antes do BERT, os modelos de linguagem típicos (como GPT-1 ou ELMo) processavam texto **em apenas uma direção**:\n",
    "\n",
    "- Modelos *left-to-right* (como GPT): preveem o próximo token a partir dos anteriores.  \n",
    "- Modelos *right-to-left* (como LM reversos): preveem o token anterior.  \n",
    "- ELMo (2018) combinava duas redes LSTM unidirecionais, mas de forma ainda limitada.\n",
    "\n",
    "Essas abordagens **não capturavam o contexto completo** de uma palavra em sua sentença, já que a representação dependia apenas do passado ou do futuro, mas não dos dois **ao mesmo tempo**.\n",
    "\n",
    "O BERT resolve isso ao:\n",
    "- Treinar **bidirecionalmente**, olhando para a **sentença inteira**;  \n",
    "- Usar um esquema de pré-treinamento **auto-supervisionado** (sem rótulos humanos);  \n",
    "- E depois **ajustar** o modelo (*fine-tuning*) para tarefas específicas de NLP.\n",
    "\n",
    "---\n",
    "\n",
    "## Transfer Learning em NLP\n",
    "\n",
    "Assim como o *ImageNet* revolucionou a visão computacional com o conceito de **pré-treinamento + fine-tuning**, o BERT trouxe essa revolução para o **Processamento de Linguagem Natural (PLN)**.\n",
    "\n",
    "O processo segue duas fases:\n",
    "\n",
    "1. **Pré-treinamento (Pretraining)**  \n",
    "   - O modelo aprende conhecimento linguístico geral a partir de **grandes corpora** (Wikipedia + BooksCorpus).  \n",
    "   - Duas tarefas auto-supervisionadas são usadas:\n",
    "     - **Masked Language Modeling (MLM)**: prever palavras mascaradas no texto.  \n",
    "     - **Next Sentence Prediction (NSP)**: prever se uma sentença B segue naturalmente uma sentença A.\n",
    "\n",
    "2. **Ajuste fino (Fine-tuning)**  \n",
    "   - O modelo é adaptado para uma tarefa específica: classificação, QA, NER, etc.  \n",
    "   - Os mesmos pesos são reutilizados, e apenas algumas camadas finais são ajustadas.\n",
    "\n",
    "Essa combinação tornou o BERT um **modelo universal de linguagem**, facilmente adaptável a diversas tarefas de NLP.\n",
    "\n",
    "---\n",
    "\n",
    "## Intuição: O que o BERT aprende?\n",
    "\n",
    "Durante o pré-treinamento, o BERT **aprende as relações contextuais** entre as palavras:\n",
    "- Como palavras diferentes se associam em frases;  \n",
    "- Que estrutura sintática e semântica definem o sentido;  \n",
    "- Que palavras são prováveis em determinados contextos.\n",
    "\n",
    "Com isso, ele gera **embeddings contextuais**, ou seja, o vetor de uma palavra depende da **sentença em que ela aparece**.\n",
    "\n",
    "> Exemplo:  \n",
    "> - Em “Ele foi ao **banco** sacar dinheiro”, “banco” → instituição financeira.  \n",
    "> - Em “Ela sentou no **banco** do parque”, “banco” → assento.  \n",
    ">\n",
    "> O BERT gera embeddings diferentes para cada uso.\n",
    "\n",
    "---\n",
    "\n",
    "## Arquitetura Geral\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/bert_size_architecture.png\" width=\"50%%\">\n",
    "\n",
    "Fonte: [Huggingface](https://huggingface.co/blog/bert-101)\n",
    "\n",
    "O BERT baseia-se **no encoder do Transformer**, repetido *N* vezes.  \n",
    "Cada camada contém:\n",
    "\n",
    "1. **Multi-Head Self-Attention**  \n",
    "   - Permite que cada token atenda a todos os outros tokens da sentença, em ambas as direções.  \n",
    "   - É aqui que o “Bidirectional” de BERT acontece.\n",
    "\n",
    "2. **Feed-Forward Network (FFN)**  \n",
    "   - Aplica transformações não lineares em cada posição, aprendendo representações mais ricas.\n",
    "\n",
    "3. **Residual Connections + Layer Normalization**  \n",
    "   - Facilitam o fluxo de gradientes e a estabilidade do treinamento.\n",
    "\n",
    "---\n",
    "\n",
    "## Configurações originais\n",
    "\n",
    "| Modelo | Camadas (L) | Heads | Dimensão (`d_model`) | Dim. Feedforward | Parâmetros |\n",
    "|:--------|:------------:|:------:|:--------------------:|:----------------:|:-----------:|\n",
    "| **BERT Base** | 12 | 12 | 768 | 3072 | 110M |\n",
    "| **BERT Large** | 24 | 16 | 1024 | 4096 | 340M |\n",
    "\n",
    "---\n",
    "\n",
    "## Entrada do BERT\n",
    "\n",
    "O BERT processa o texto em forma de tokens especiais:\n",
    "\n",
    "- **[CLS]** → marca o início da sequência (usado para classificação).  \n",
    "- **[SEP]** → separa sentenças (usado em tarefas de pares).  \n",
    "- **[MASK]** → substitui tokens que o modelo deve prever.\n",
    "\n",
    "> Exemplo:  \n",
    "> Entrada: `[CLS] O gato [MASK] no tapete [SEP]`  \n",
    "> Saída: prever a palavra “dormiu”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0df512",
   "metadata": {
    "id": "ac0df512"
   },
   "source": [
    "# 5.2 - Objetivos de Pré-Treinamento do BERT\n",
    "\n",
    "O sucesso do BERT vem de seu **pré-treinamento auto-supervisionado** em larga escala.  \n",
    "Ele não usa rótulos humanos: aprende diretamente com **texto cru**, aplicando duas tarefas artificiais que forçam o modelo a entender a estrutura e o sentido da linguagem.\n",
    "\n",
    "Essas duas tarefas são:\n",
    "\n",
    "1. **Masked Language Modeling (MLM)**  \n",
    "2. **Next Sentence Prediction (NSP)**\n",
    "\n",
    "Vamos entender cada uma delas com muito detalhe.\n",
    "\n",
    "---\n",
    "\n",
    "## 5.2.1. Masked Language Modeling (MLM)\n",
    "\n",
    "O objetivo do **MLM** é ensinar o modelo a *prever palavras faltantes* (ou mascaradas) a partir do contexto.\n",
    "\n",
    "### Intuição\n",
    "\n",
    "Imagine a seguinte frase:\n",
    "\n",
    "> “O cachorro **[MASK]** o carteiro.”\n",
    "\n",
    "O modelo deve prever a palavra mais provável para **[MASK]**, considerando **todas as palavras** da sentença — tanto antes quanto depois.\n",
    "\n",
    "Dessa forma, o BERT aprende **representações bidirecionais**, já que olha para a esquerda e para a direita ao mesmo tempo.\n",
    "\n",
    "---\n",
    "\n",
    "### Como o processo funciona\n",
    "\n",
    "1. **Tokenização e inserção de tokens especiais**  \n",
    "   O texto é dividido em *subtokens* (usando WordPiece) e recebe marcadores especiais:\n",
    "\n",
    "> [CLS] O cachorro [MASK] o carteiro [SEP]\n",
    "\n",
    "\n",
    "2. **Escolha aleatória dos tokens a mascarar**  \n",
    "Em cada sequência, **15% dos tokens** são selecionados para mascaramento.\n",
    "\n",
    "3. **Substituições aplicadas (segundo o paper original):**\n",
    "- 80% → substituídos por `[MASK]`  \n",
    "  > Ex: “O cachorro **[MASK]** o carteiro”\n",
    "- 10% → substituídos por uma palavra **aleatória**  \n",
    "  > Ex: “O cachorro **comeu** o carteiro”  \n",
    "- 10% → **mantidos iguais**, mas ainda contam como alvos de predição  \n",
    "  > Ex: “O cachorro **mordeu** o carteiro”\n",
    "\n",
    "Isso força o modelo a não se apoiar apenas no token `[MASK]` e a construir **representações contextuais robustas**.\n",
    "\n",
    "---\n",
    "\n",
    "### Exemplo Prático\n",
    "\n",
    "Entrada:\n",
    "\n",
    "> [CLS] O cachorro [MASK] o carteiro [SEP]\n",
    "\n",
    "Saída esperada:\n",
    "\n",
    "> [CLS] O cachorro mordeu o carteiro [SEP]\n",
    "\n",
    "Durante o treinamento, o modelo gera uma distribuição de probabilidade sobre todo o vocabulário e tenta **maximizar a probabilidade do token correto**.\n",
    "\n",
    "---\n",
    "\n",
    "### Resultado\n",
    "\n",
    "Ao final do pré-treino, o BERT aprende vetores de embeddings altamente contextuais:\n",
    "- A palavra “mordeu” está associada a “cachorro” e “carteiro”.\n",
    "- Se a mesma palavra aparecer em outro contexto (“Ele **mordeu** a língua”), o vetor muda, refletindo o novo sentido.\n",
    "\n",
    "---\n",
    "\n",
    "## 5.2.2. Next Sentence Prediction (NSP)\n",
    "\n",
    "Além de entender palavras, o BERT também precisa compreender **relações entre sentenças**.  \n",
    "Essa é a função do **Next Sentence Prediction (NSP)**.\n",
    "\n",
    "---\n",
    "\n",
    "### Intuição\n",
    "\n",
    "O NSP ensina o modelo a entender **coerência e continuidade textual**.\n",
    "\n",
    "Ele recebe **dois segmentos de texto (A e B)** e precisa responder:\n",
    "\n",
    "> “A sentença B realmente vem depois da sentença A no texto original?”\n",
    "\n",
    "---\n",
    "\n",
    "### Como o processo funciona\n",
    "\n",
    "Durante o pré-treinamento:\n",
    "\n",
    "- 50% dos pares (A,B) são **verdadeiros** → B realmente segue A.  \n",
    "- 50% dos pares são **falsos** → B vem de uma parte aleatória do corpus.\n",
    "\n",
    "O modelo deve classificar entre:\n",
    "\n",
    "| Rótulo | Significado | Exemplo |\n",
    "|:-------|:-------------|:---------|\n",
    "| `IsNext` | B segue A | A: “Ele pegou o guarda-chuva.”<br>B: “Saiu para a rua.” |\n",
    "| `NotNext` | B é aleatória | A: “Ele pegou o guarda-chuva.”<br>B: “O bolo estava delicioso.” |\n",
    "\n",
    "---\n",
    "\n",
    "### Entrada típica do BERT para NSP\n",
    "\n",
    "O modelo recebe os dois segmentos concatenados, separados por tokens especiais:\n",
    "\n",
    "> [CLS] Ele pegou o guarda-chuva. [SEP] Saiu para a rua. [SEP]\n",
    "\n",
    "Além disso, ele adiciona **embeddings segmentais** (também chamados *token type embeddings*), que indicam se cada token pertence à sentença A ou B.\n",
    "\n",
    "| Tipo de embedding | Função |\n",
    "|:------------------|:--------|\n",
    "| **Token embeddings** | Representa cada palavra ou subtoken. |\n",
    "| **Segment embeddings** | Indicam a qual sentença o token pertence (A ou B). |\n",
    "| **Positional embeddings** | Indicam a posição de cada token na sequência. |\n",
    "\n",
    "O vetor final de entrada de cada token é a **soma** desses três componentes.\n",
    "\n",
    "---\n",
    "\n",
    "### Exemplo Prático\n",
    "\n",
    "Entrada:\n",
    "\n",
    "> [CLS] O cachorro latiu. [SEP] O carteiro correu. [SEP]\n",
    "\n",
    "Rótulo: `IsNext`\n",
    "\n",
    "Durante o pré-treino, o BERT aprende:\n",
    "- Que “latiu” e “carteiro” ocorrem juntos com frequência;  \n",
    "- Que há relação causal ou temporal entre as sentenças.\n",
    "\n",
    "Isso o prepara para tarefas posteriores como *Question Answering*, *Natural Language Inference* e *Paraphrase Detection*.\n",
    "\n",
    "---\n",
    "\n",
    "## Saída do Pré-Treinamento\n",
    "\n",
    "Durante o pré-treino, o BERT otimiza **duas funções de perda simultaneamente**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = \\mathcal{L}_{MLM} + \\mathcal{L}_{NSP}\n",
    "$$\n",
    "\n",
    "- **$\\mathcal{L}_{MLM}$** → erro de predição das palavras mascaradas.  \n",
    "- **$\\mathcal{L}_{NSP}$** → erro de classificação entre `IsNext` e `NotNext`.\n",
    "\n",
    "A combinação dessas perdas permite que o modelo aprenda tanto **relações locais (entre palavras)** quanto **globais (entre sentenças)**.\n",
    "\n",
    "---\n",
    "\n",
    "## Resumo Visual\n",
    "\n",
    "O BERT é, portanto, um **modelo de linguagem bidirecional e contextual**, treinado de forma auto-supervisionada, capaz de ser ajustado para praticamente qualquer tarefa de PLN.\n",
    "\n",
    "\n",
    "<pre>\n",
    "Entrada:\n",
    "[CLS] A sentença A ... [SEP] sentença B ... [SEP]\n",
    "\n",
    "↓ Embeddings = Token + Segment + Position\n",
    "\n",
    "↓ Encoder do Transformer (12 camadas)\n",
    "\n",
    "↓\n",
    "Saídas:\n",
    " - Vetores de cada token (para MLM)\n",
    " - Vetor [CLS] (para NSP)\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1db883",
   "metadata": {
    "id": "5b1db883"
   },
   "source": [
    "# 5.3 Os três tipos de embeddings no BERT\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/bert_embeddings.png\" width=\"50%%\">\n",
    "\n",
    "Fonte: Devlin et al. (2018)\n",
    "\n",
    "O BERT não usa apenas *word embeddings*.  \n",
    "Cada token de entrada é representado pela **soma de três vetores** diferentes:\n",
    "\n",
    "$$\n",
    "\\text{InputEmbedding}(t_i) = \\text{TokenEmb}(t_i) + \\text{SegmentEmb}(s_i) + \\text{PositionEmb}(p_i)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 5.3.1 Token Embeddings\n",
    "São os embeddings “normais” de palavras, como nos modelos anteriores (Word2Vec, GloVe, etc).  \n",
    "Cada palavra (ou subpalavra, no caso do BERT) é convertida em um vetor denso.\n",
    "\n",
    "Exemplo:\n",
    "```text\n",
    "[CLS] o filme foi ótimo [SEP]\n",
    "```\n",
    "\n",
    "Os tokens podem ser:\n",
    "```text\n",
    "[CLS], o, fil, ##me, foi, ót, ##imo, [SEP]\n",
    "```\n",
    "\n",
    "Cada um recebe um vetor aprendido — esses vetores formam a **base semântica** da frase.\n",
    "\n",
    "---\n",
    "\n",
    "## 5.3.2 Position Embeddings\n",
    "Transformers não têm noção de ordem (eles não são recorrentes).  \n",
    "Por isso, o BERT adiciona **positional embeddings fixos** que indicam a posição de cada token na sequência.\n",
    "\n",
    "Esses vetores são somados ao embedding de cada token e permitem que o modelo diferencie, por exemplo:\n",
    "\n",
    "```text\n",
    "o cachorro mordeu o homem\n",
    "o homem mordeu o cachorro\n",
    "```\n",
    "\n",
    "Apesar das mesmas palavras, as posições diferentes mudam completamente o significado.\n",
    "\n",
    "---\n",
    "\n",
    "## 5.3.3 Segment (ou Sentence) Embeddings\n",
    "\n",
    "Durante o pré-treinamento, o BERT usa o **Next Sentence Prediction (NSP)**, que exige lidar com **pares de sentenças**.  \n",
    "Para que o modelo saiba **qual token pertence a qual sentença**, o BERT adiciona embeddings de segmento:\n",
    "\n",
    "| Token | Segment Embedding |\n",
    "|:-------|:-----------------:|\n",
    "| `[CLS]` | A |\n",
    "| `O` | A |\n",
    "| `filme` | A |\n",
    "| `foi` | A |\n",
    "| `ótimo` | A |\n",
    "| `[SEP]` | A |\n",
    "| `Não` | B |\n",
    "| `gostei` | B |\n",
    "| `.` | B |\n",
    "| `[SEP]` | B |\n",
    "\n",
    "→ Tokens da **primeira sentença** recebem `Segment A`  \n",
    "→ Tokens da **segunda sentença** recebem `Segment B`\n",
    "\n",
    "Esses vetores de segmento são aprendidos junto com o resto da rede.\n",
    "\n",
    "---\n",
    "\n",
    "## 5.3.4 Combinação Final\n",
    "Para cada token, o vetor final de entrada é a soma:\n",
    "\n",
    "$$\n",
    "\\text{EmbeddingFinal}(t_i) =\n",
    "\\text{TokenEmb}(t_i)\n",
    "+ \\text{SegmentEmb}(s_i)\n",
    "+ \\text{PositionEmb}(p_i)\n",
    "$$\n",
    "\n",
    "\n",
    "Essa combinação fornece ao modelo:\n",
    "\n",
    "- **significado** da palavra (Token),\n",
    "- **ordem** na sequência (Position),\n",
    "- **identificação** da sentença (Segment).\n",
    "\n",
    "Essa soma é o **ponto de partida do aprendizado contextual** no BERT.  \n",
    "Os três tipos de embeddings são aprendidos (ou fixos, no caso posicional) e evoluem durante o pré-treinamento.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d12d7",
   "metadata": {
    "id": "a14d12d7"
   },
   "source": [
    "## 5.4 — BERT na prática: Masked Language Modeling (MLM) + Next Sentence Prediction (NSP)\n",
    "\n",
    "Nesta seção vamos **reproduzir em pequena escala** os objetivos de pré-treinamento do BERT usando `BertForPreTraining` (que já inclui as duas cabeças: **MLM** e **NSP**).\n",
    "\n",
    "### O que vamos fazer\n",
    "\n",
    "1. **Mini-corpus**: definimos algumas sentenças curtas (você pode substituir pelo seu conjunto).\n",
    "2. **Pares para NSP**: criamos pares (A,B) rotulados:\n",
    "   - `IsNext` quando B realmente segue A no texto original;\n",
    "   - `NotNext` quando B é uma sentença aleatória.\n",
    "3. **Tokenização**: `[CLS] A [SEP] B [SEP]`, com `token_type_ids` (A=0, B=1).\n",
    "4. **Máscaras para MLM (80/10/10)** sobre ~15% dos tokens “previstáveis”.\n",
    "5. **Treino curto**: otimizamos **uma única loss conjunta**:  \n",
    "   $\\mathcal{L} = \\mathcal{L}_{MLM} + \\mathcal{L}_{NSP}$\n",
    "6. **Inspeção de saídas**:\n",
    "   - Top-k predições para `[MASK]`;\n",
    "   - Probabilidades `IsNext/NotNext` do NSP para um par de teste.\n",
    "\n",
    "### Dicas\n",
    "\n",
    "- **MLM** força o BERT a aprender **contexto bidirecional** (olhando esquerda e direita).  \n",
    "- **NSP** ensina **coerência entre sentenças** (embora trabalhos posteriores mostrem que remover NSP às vezes ajuda; aqui mantemos por fidelidade ao BERT original).  \n",
    "- Em produção, corpora são massivos (Wikipedia + BooksCorpus). Aqui, **mini-setup** para visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd171d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "2169b309fa0b4a7ea0b2d169eca9304d",
      "8512fe2d0390420cacc9860a34948d1f",
      "969e02b73e28418c9e46d660932e0335",
      "602fe170d0fa4a9e8289340d389d01be",
      "60649f63928e40a4b4d92364744aa925",
      "f1ad27e141a341289dd794df04f2aef8",
      "b0ec1fc39a6a40239e859ab9f87d0535",
      "53a6e3de432747788dbc5b6c5d47723f",
      "32713cd38eb64597b895db034a020abd",
      "becd85b9d0ab425883d03d128bb15730",
      "1b501e21dade4541a8cff13d5d0d6fe4",
      "b9f33343020549599d4dbb329ad5e26c",
      "1df2713322fa47d5807a94337b49158e",
      "64a04f0530a34c91b780bbd05664f041",
      "c040ffe8cb9542b0bb3e6e835e021021",
      "06b4567b458c4b34b0c6cf14ecd5e140",
      "458e077f1d8d4293a6f69ba7841a69a8",
      "f7a44c6b89d24a1ea15a66bf484deadb",
      "7a2aca84a2f4478e8c7203a1ce8b4466",
      "d79af1bcdb3b4d068df10fc4802b0627",
      "9f2fb9e052d44359bb62a87f1ca5f6f8",
      "b6fbaf4655c741cf861ff7769840986d",
      "4434341001c74f5f980b7af282d405b7",
      "885c4ec9ea464e1589760cb496e95365",
      "bcf881141cd045b5b78f469894f3a993",
      "49b33a35dbaa4d80acc8df3c9e283dc3",
      "5ad0adf354a54c3aa37d3dc7c5ffb519",
      "8e8ef2549b3b461f883ccfdcc1e85a4b",
      "96e3382567704b6fb358c252be3fed07",
      "456eaaf0079740729e22e7ee14521e52",
      "09e7cf75322044d091f285323f73bbd3",
      "472e7ef2a53c424aa111c6d05c5194dd",
      "007e14a7b0484fe382ce6ea6553b33b0",
      "55c5edfa16c04c4a98caf74c1672aa6c",
      "39fcdc2adc974156ab9b3cf0d0b5659b",
      "fe62a5de99e84ba488eccd06cc2d43e5",
      "b4d4097ad5e9423b9db70cccba6abbc1",
      "19644b37b47b4f07a6af33388066b7da",
      "7da5c879db4145c18381605bc913ef6b",
      "6417f89546094943b76c4928f6051dd4",
      "d11c374301394ce9b913c2d57d850dea",
      "2b263c6d8ec9435283999ce0a769fa3d",
      "61e02de3deaf4b0881b293e913bf71e8",
      "066bafd1cda54fd39d09c8b15d93cd68",
      "1988766bcef54cbabbe03969118338a2",
      "f55646981f254a7e9889d9f4cf6b952c",
      "7854e03c883941ed895f3d057ae77e4a",
      "ec4a4b4f274b46179c5755f0b6334f1f",
      "065320bead224e0b828b63f3977832c1",
      "90cdc87113a74f72884c662448e5bf88",
      "69bd57449c334d12871ef164851ff772",
      "61735386d9a54e8a99accf6822cd9527",
      "fb6be34bbace468fbe71a00cf962a61c",
      "36b96b84c0ea4c04bfbe00eb41f0b759",
      "a5568ae260d74f5e89c2ba83b238d11d"
     ]
    },
    "executionInfo": {
     "elapsed": 49730,
     "status": "ok",
     "timestamp": 1761096944201,
     "user": {
      "displayName": "Bruno Magalhaes Nogueira",
      "userId": "18320277366917905276"
     },
     "user_tz": 240
    },
    "id": "3ffd171d",
    "outputId": "a6489dbe-a962-474c-c9c1-e5a8b0bf77cb"
   },
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# BERT Pretraining Demo: MLM + NSP (didático)\n",
    "# ===========================================\n",
    "import math, random, torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizerFast,\n",
    "    BertForPreTraining,\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 0) Setup\n",
    "# ---------------------------\n",
    "SEED = 7\n",
    "random.seed(SEED); torch.manual_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Mini-corpus (edite à vontade)\n",
    "#    Cada \"documento\" é uma lista de sentenças em ordem.\n",
    "# ---------------------------\n",
    "documents = [\n",
    "    [\n",
    "        \"the cat sat on the mat.\",\n",
    "        \"it looked out the window.\",\n",
    "        \"then it jumped down.\",\n",
    "        \"the dog barked loudly.\"\n",
    "    ],\n",
    "    [\n",
    "        \"deep learning changed natural language processing.\",\n",
    "        \"transformers enable parallel training.\",\n",
    "        \"bert learns bidirectional context.\",\n",
    "        \"masked language modeling is powerful.\"\n",
    "    ],\n",
    "    [\n",
    "        \"paris is the capital of france.\",\n",
    "        \"the eiffel tower is in paris.\",\n",
    "        \"tourists visit the louvre.\",\n",
    "        \"french cuisine is famous.\"\n",
    "    ],\n",
    "]\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Gerar pares (A,B) para NSP\n",
    "#    - 50% IsNext (B segue A no mesmo doc)\n",
    "#    - 50% NotNext (B aleatória de outro lugar)\n",
    "# ---------------------------\n",
    "def build_nsp_pairs(docs, num_pairs=300):\n",
    "    pairs = []\n",
    "    for _ in range(num_pairs):\n",
    "        doc = random.choice(docs)\n",
    "        if len(doc) >= 2 and random.random() < 0.5:\n",
    "            # IsNext: escolher A e B consecutivos no mesmo doc\n",
    "            i = random.randint(0, len(doc) - 2)\n",
    "            A, B = doc[i], doc[i+1]\n",
    "            label = 0  # IsNext\n",
    "        else:\n",
    "            # NotNext: A de um doc e B aleatória de outro doc\n",
    "            docA = random.choice(docs)\n",
    "            A = random.choice(docA)\n",
    "            # garanta B de outro doc para ser (em geral) NotNext\n",
    "            docB = random.choice([d for d in docs if d is not docA])\n",
    "            B = random.choice(docB)\n",
    "            label = 1  # NotNext\n",
    "        pairs.append((A, B, label))\n",
    "    return pairs\n",
    "\n",
    "pairs = build_nsp_pairs(documents, num_pairs=400)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Tokenizer e encoding de pares\n",
    "# ---------------------------\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "MAX_LEN = 64\n",
    "def encode_pair(a, b):\n",
    "    enc = tokenizer(\n",
    "        a, b,\n",
    "        add_special_tokens=True,\n",
    "        max_length=MAX_LEN,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    # enc: input_ids, token_type_ids, attention_mask\n",
    "    return {k: v.squeeze(0) for k, v in enc.items()}\n",
    "\n",
    "# ---------------------------\n",
    "# 4) MLM: selecionar posições a mascarar (15%) e aplicar 80/10/10\n",
    "#    - ignorar especiais [CLS]/[SEP]/PAD na seleção\n",
    "# ---------------------------\n",
    "CLS_ID = tokenizer.cls_token_id\n",
    "SEP_ID = tokenizer.sep_token_id\n",
    "PAD_ID = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n",
    "MASK_ID = tokenizer.mask_token_id\n",
    "\n",
    "def apply_mlm_masking(input_ids, mlm_prob=0.15):\n",
    "    labels = input_ids.clone()\n",
    "\n",
    "    # candidatos \"previstáveis\" (não especiais)\n",
    "    special_ids = {CLS_ID, SEP_ID, PAD_ID}\n",
    "    can_mask = torch.ones_like(input_ids, dtype=torch.bool)\n",
    "    for sid in special_ids:\n",
    "        can_mask &= (input_ids != sid)\n",
    "\n",
    "    # amostra binária de quais posições mascarar\n",
    "    probs = torch.full(input_ids.shape, mlm_prob, device=input_ids.device)\n",
    "    mask_positions = (torch.bernoulli(probs).bool()) & can_mask\n",
    "\n",
    "    # 80% -> [MASK]\n",
    "    mask80 = mask_positions & (torch.rand_like(input_ids, dtype=torch.float) < 0.8)\n",
    "    input_ids[mask80] = MASK_ID\n",
    "\n",
    "    # 10% -> token aleatório\n",
    "    # (onde foi selecionado p/ máscara mas não entrou no 80%)\n",
    "    remaining = mask_positions & (~mask80)\n",
    "    rand10 = remaining & (torch.rand_like(input_ids, dtype=torch.float) < 0.5)\n",
    "    vocab_size = tokenizer.vocab_size\n",
    "    random_tokens = torch.randint(low=0, high=vocab_size, size=input_ids.shape, device=input_ids.device)\n",
    "    input_ids[rand10] = random_tokens[rand10]\n",
    "\n",
    "    # 10% -> deixam igual (implicitly: remaining & ~rand10)\n",
    "\n",
    "    # posições não-mascaradas não entram no loss (=-100)\n",
    "    labels[~mask_positions] = -100\n",
    "    return input_ids, labels, mask_positions\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Dataset + DataLoader\n",
    "# ---------------------------\n",
    "class BertPretrainDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        a, b, nsp_label = self.pairs[idx]\n",
    "        enc = encode_pair(a, b)\n",
    "        # aplica MLM no input_ids\n",
    "        ids, labels, mask_pos = apply_mlm_masking(enc[\"input_ids\"].clone())\n",
    "        item = {\n",
    "            \"input_ids\": ids,\n",
    "            \"token_type_ids\": enc[\"token_type_ids\"],\n",
    "            \"attention_mask\": enc[\"attention_mask\"],\n",
    "            \"labels\": labels,  # para MLM\n",
    "            \"next_sentence_label\": torch.tensor(nsp_label, dtype=torch.long)\n",
    "        }\n",
    "        return item\n",
    "\n",
    "dataset = BertPretrainDataset(pairs)\n",
    "split = int(0.9 * len(dataset))\n",
    "train_ds, val_ds = torch.utils.data.random_split(dataset, [split, len(dataset)-split])\n",
    "\n",
    "BATCH = 8\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Modelo (MLM + NSP) e otimizador\n",
    "# ---------------------------\n",
    "model = BertForPreTraining.from_pretrained(\"bert-base-uncased\").to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Loop de treino curto (didático)\n",
    "# ---------------------------\n",
    "EPOCHS = 1\n",
    "model.train()\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    running = 0.0\n",
    "    for step, batch in enumerate(train_loader, 1):\n",
    "        batch = {k: v.to(device) for k,v in batch.items()}\n",
    "        optimizer.zero_grad()\n",
    "        out = model(**batch)  # loss = MLM + NSP\n",
    "        loss = out.loss\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        running += loss.item()\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"[epoch {epoch} step {step:03d}] loss={running/20:.4f}\")\n",
    "            running = 0.0\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Funções de inspeção: MLM top-k e NSP probs\n",
    "# ---------------------------\n",
    "@torch.no_grad()\n",
    "def inspect_mlm(tokenizer, model, a, b, topk=5):\n",
    "    model.eval()\n",
    "    enc = encode_pair(a, b)\n",
    "    # força UM [MASK] manualmente para demonstrar (na primeira palavra de B se possível)\n",
    "    ids = enc[\"input_ids\"].clone()\n",
    "    # procurar um token \"previstável\" em B (token_type_id==1) que não seja especial\n",
    "    ttypes = enc[\"token_type_ids\"]\n",
    "    chosen_idx = None\n",
    "    for i in range(ids.size(0)):\n",
    "        if (ttypes[i] == 1) and (ids[i] not in {CLS_ID, SEP_ID, PAD_ID}):\n",
    "            chosen_idx = i; break\n",
    "    if chosen_idx is None:\n",
    "        # fallback: primeiro token não-especial\n",
    "        for i in range(ids.size(0)):\n",
    "            if ids[i] not in {CLS_ID, SEP_ID, PAD_ID}:\n",
    "                chosen_idx = i; break\n",
    "    original = ids[chosen_idx].item()\n",
    "    ids[chosen_idx] = MASK_ID\n",
    "\n",
    "    batch = {\n",
    "        \"input_ids\": ids.unsqueeze(0).to(device),\n",
    "        \"token_type_ids\": enc[\"token_type_ids\"].unsqueeze(0).to(device),\n",
    "        \"attention_mask\": enc[\"attention_mask\"].unsqueeze(0).to(device),\n",
    "    }\n",
    "    out = model(**batch)\n",
    "    logits = out.prediction_logits[0, chosen_idx]  # (V,)\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    vals, idxs = torch.topk(probs, k=topk)\n",
    "    toks = [tokenizer.decode([i]) for i in idxs.tolist()]\n",
    "    return {\n",
    "        \"masked_position\": chosen_idx,\n",
    "        \"original_token\": tokenizer.decode([original]),\n",
    "        \"topk\": list(zip(toks, [float(v) for v in vals]))\n",
    "    }\n",
    "\n",
    "@torch.no_grad()\n",
    "def inspect_nsp(tokenizer, model, a, b):\n",
    "    model.eval()\n",
    "    enc = encode_pair(a, b)\n",
    "    batch = {\n",
    "        \"input_ids\": enc[\"input_ids\"].unsqueeze(0).to(device),\n",
    "        \"token_type_ids\": enc[\"token_type_ids\"].unsqueeze(0).to(device),\n",
    "        \"attention_mask\": enc[\"attention_mask\"].unsqueeze(0).to(device),\n",
    "    }\n",
    "    out = model(**batch)\n",
    "    # out.seq_relationship_logits: (B, 2) -> [IsNext, NotNext]\n",
    "    logits = out.seq_relationship_logits[0]\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    return {\"IsNext\": float(probs[0]), \"NotNext\": float(probs[1])}\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Testes: ver predições após o treino curto\n",
    "# ---------------------------\n",
    "tests = [\n",
    "    (\"the cat sat on the mat.\", \"it [MASK] out the window.\"),\n",
    "    (\"paris is the capital of france.\", \"the eiffel tower is in paris.\"),\n",
    "    (\"deep learning changed natural language processing.\", \"bert learns bidirectional context.\"),\n",
    "    (\"paris is the capital of france.\", \"masked language modeling is powerful.\"),  # NotNext provável\n",
    "]\n",
    "\n",
    "print(\"\\n=== INSPEÇÃO DE MLM (top-5 para um [MASK]) ===\")\n",
    "for a, b in tests:\n",
    "    r = inspect_mlm(tokenizer, model, a, b, topk=5)\n",
    "    print(f\"\\nA: {a}\\nB: {b}\")\n",
    "    print(f\"  posição mascarada: {r['masked_position']}\")\n",
    "    print(f\"  token original (se disponível): {r['original_token']!r}\")\n",
    "    for tok, p in r[\"topk\"]:\n",
    "        print(f\"   -> {tok:<12} p={p:.4f}\")\n",
    "\n",
    "print(\"\\n=== INSPEÇÃO DE NSP (probabilidades) ===\")\n",
    "for a, b in tests:\n",
    "    p = inspect_nsp(tokenizer, model, a, b)\n",
    "    print(f\"\\nA: {a}\\nB: {b}\")\n",
    "    print(f\"  P(IsNext)={p['IsNext']:.3f}  |  P(NotNext)={p['NotNext']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7df5a",
   "metadata": {
    "id": "c8b7df5a"
   },
   "source": [
    "# 5.5 — Fine-Tuning do BERT e o papel do token `[CLS]`\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/bert_ft_tasks.png\" width=\"50%%\">\n",
    "\n",
    "Fonte: Devlin et al. (2018)\n",
    "\n",
    "Após o pré-treinamento, o BERT é uma poderosa **base de conhecimento linguístico geral**, mas ainda **não sabe realizar tarefas específicas** (como classificar sentimentos ou responder perguntas).  \n",
    "O **fine-tuning** é o processo que adapta esse conhecimento para **tarefas supervisionadas específicas**.\n",
    "\n",
    "---\n",
    "\n",
    "## Conceito de Fine-Tuning\n",
    "\n",
    "O *fine-tuning* consiste em:\n",
    "\n",
    "1. **Reaproveitar os pesos do modelo pré-treinado**, que já aprenderam relações semânticas e sintáticas da linguagem.  \n",
    "2. **Acrescentar uma pequena camada de saída** (geralmente linear) adaptada à tarefa desejada.  \n",
    "3. **Treinar o modelo completo novamente**, mas em um **novo conjunto de dados rotulado**, com uma **taxa de aprendizado menor** — para ajustar suavemente os pesos sem “destruir” o conhecimento linguístico aprendido.\n",
    "\n",
    "Essa abordagem faz parte do paradigma de **transfer learning**:\n",
    "- o pré-treinamento fornece **conhecimento geral** sobre linguagem;\n",
    "- o fine-tuning **especializa** esse conhecimento para um contexto ou tarefa.\n",
    "\n",
    "---\n",
    "\n",
    "## Como o Fine-Tuning é Feito\n",
    "\n",
    "O processo segue o mesmo pipeline básico:\n",
    "\n",
    "> Texto → Tokenização → Embeddings → Camadas do BERT → Saída Adaptada → Função de Perda\n",
    "\n",
    "Dependendo da tarefa, usamos diferentes **estruturas de saída**:\n",
    "\n",
    "| Tipo de Tarefa | Saída Esperada | Cabeça Adicional | Exemplo |\n",
    "|----------------|----------------|------------------|----------|\n",
    "| Classificação de Sentença | 1 vetor (logits) | Linear + Softmax | Análise de Sentimento |\n",
    "| Classificação de Token | 1 vetor por token | Linear + Softmax | NER, POS Tagging |\n",
    "| Perguntas e Respostas | Vetores de início e fim | Linear (dupla saída) | SQuAD |\n",
    "| Similaridade entre sentenças | 2 embeddings | Camada de similaridade (cosine) | STS |\n",
    "\n",
    "---\n",
    "\n",
    "## O Papel do Token `[CLS]`\n",
    "\n",
    "O token especial `[CLS]` (*classification token*) é adicionado **no início de toda sequência**.  \n",
    "Durante o pré-treinamento, ele é associado à tarefa **Next Sentence Prediction (NSP)**, ou seja, o modelo já aprendeu a representar **o significado global da sentença ou do par de sentenças** nele.\n",
    "\n",
    "Por isso, no *fine-tuning* para tarefas de **classificação**, usamos **somente o vetor final de `[CLS]`** como representação da entrada completa.\n",
    "\n",
    "### Exemplo:\n",
    "\n",
    "> Entrada: [CLS] O filme foi excelente ! [SEP]\n",
    "\n",
    "O BERT processa todos os tokens por 12 camadas de atenção.  \n",
    "Ao final, o vetor correspondente a `[CLS]` contém uma **representação contextual global** do significado da frase.\n",
    "\n",
    "> Esse vetor é passado para uma **camada linear de classificação** que gera os logits finais (ex: positivo / negativo).\n",
    "\n",
    "Matematicamente:\n",
    "\n",
    "$$\n",
    "\\text{logits} = W \\cdot h_{[CLS]} + b\n",
    "$$\n",
    "\n",
    "onde:\n",
    "- $h_{[CLS]}$ é o embedding final do token `[CLS]`;  \n",
    "- $W$ e $b$ são parâmetros da nova camada linear.\n",
    "\n",
    "---\n",
    "\n",
    "## Fine-Tuning em Diferentes Tarefas\n",
    "\n",
    "### (a) Classificação de Sentenças\n",
    "- Entrada: `[CLS] sentença [SEP]`\n",
    "- Saída: vetor `[CLS]` → camada linear → softmax.\n",
    "\n",
    "### (b) Classificação de Tokens (ex: NER)\n",
    "- Entrada: `[CLS] frase [SEP]`\n",
    "- Saída: vetor contextual **de cada token**, passando cada um por uma camada linear.\n",
    "\n",
    "### (c) Perguntas e Respostas\n",
    "- Entrada: `[CLS] pergunta [SEP] contexto [SEP]`\n",
    "- Saída: duas camadas lineares preveem índices de início e fim no contexto.\n",
    "\n",
    "---\n",
    "\n",
    "## Treinamento Suave (Small Learning Rate)\n",
    "\n",
    "Durante o *fine-tuning*, usamos:\n",
    "- **taxas de aprendizado pequenas (ex: 2e-5 a 5e-5)**;\n",
    "- **poucas épocas (2–4)**;\n",
    "- **batch sizes pequenos (16–32)**;\n",
    "- **métodos de regularização leves** (como dropout).\n",
    "\n",
    "A ideia é **ajustar levemente** o modelo, mantendo a “gramática geral” da linguagem que o BERT já aprendeu.\n",
    "\n",
    "---\n",
    "\n",
    "## Visualização Conceitual\n",
    "\n",
    "<pre>\n",
    "[Texto de Entrada] → [Tokenização]\n",
    "          ↓\n",
    "     [CLS]  token1  token2  ...  [SEP]\n",
    "          ↓\n",
    "     Embeddings + Posições\n",
    "          ↓\n",
    "      Camadas BERT\n",
    "          ↓\n",
    "      Vetor [CLS]  ← representa a sentença\n",
    "          ↓\n",
    "   Camada Linear (Nova)\n",
    "          ↓\n",
    "   Saída final (ex: sentimento positivo)\n",
    "</pre>\n",
    "\n",
    "O BERT já aprendeu “como o idioma funciona”; o fine-tuning ensina “como resolver o seu problema específico”.\n",
    "    \n",
    "- O token [CLS] é o resumo semântico da sentença — ele condensa, em um vetor, as informações que fluíram por toda a rede de atenção.\n",
    "    \n",
    "- Essa adaptação é tão eficiente que, muitas vezes, basta menos de 1 hora de treino para atingir desempenho de ponta em diversas tarefas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64620b30",
   "metadata": {
    "id": "64620b30"
   },
   "source": [
    "## Como o `[CLS]` é atualizado durante o Fine-Tuning\n",
    "\n",
    "O token especial `[CLS]` é adicionado **no início da sequência** de entrada:\n",
    "\n",
    "> [CLS] O filme foi ótimo [SEP]\n",
    "\n",
    "Durante o **forward pass** do BERT:\n",
    "\n",
    "1. Ele recebe um embedding inicial aprendido (como qualquer palavra).\n",
    "2. Passa por todas as camadas do Transformer — o `[CLS]` “observa” todas as outras palavras via *self-attention*.\n",
    "3. O vetor final do `[CLS]` (geralmente de 768 dimensões) é interpretado como o **resumo contextual da sentença**.\n",
    "4. Esse vetor é então enviado a uma camada linear + *softmax* para produzir as probabilidades das classes:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\text{Softmax}(W_{cls} \\cdot h_{cls} + b)\n",
    "$$\n",
    "\n",
    "onde \\( h_{cls} \\) é o embedding final do `[CLS]`.\n",
    "\n",
    "---\n",
    "\n",
    "### A Função de Custo e o Gradiente\n",
    "\n",
    "Para uma tarefa de classificação binária, usamos a **entropia cruzada**:\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = - \\sum_i y_i \\log(\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "Durante o **backpropagation**, o gradiente da perda em relação a \\( h_{cls} \\) é:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial h_{cls}} = W_{cls}^\\top (\\hat{y} - y)\n",
    "$$\n",
    "\n",
    "Esse gradiente é propagado de volta, atualizando:\n",
    "- o vetor `[CLS]`;\n",
    "- as projeções da atenção e camadas feedforward;\n",
    "- e até mesmo os embeddings iniciais.\n",
    "\n",
    "Assim, o `[CLS]` aprende a **codificar padrões discriminativos** úteis para a tarefa.\n",
    "\n",
    "---\n",
    "\n",
    "### Intuição\n",
    "\n",
    "Imagine duas frases:\n",
    "\n",
    "| Sentença | Rótulo |\n",
    "|-----------|---------|\n",
    "| “O filme foi maravilhoso!” | 1 (positivo) |\n",
    "| “O filme foi péssimo.” | 0 (negativo) |\n",
    "\n",
    "Inicialmente, os vetores `[CLS]` dessas frases são aleatórios ou neutros.  \n",
    "Após algumas iterações:\n",
    "\n",
    "- O `[CLS]` das frases **positivas** é “puxado” para uma região do espaço vetorial associada a altas probabilidades de classe 1.\n",
    "- O `[CLS]` das frases **negativas** é empurrado para outra região, favorecendo a classe 0.\n",
    "\n",
    "O espaço vetorial se organiza assim:\n",
    "\n",
    "Espaço vetorial após fine-tuning\n",
    "\n",
    "<pre>\n",
    "↑ Classe 1 (positivo)\n",
    "│\n",
    "│      o    o   o\n",
    "│        o\n",
    "│\n",
    "│\n",
    "│\n",
    "│     x\n",
    "│  x     x\n",
    "└────────────────────→ Classe 0 (negativo)\n",
    "</pre>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Exemplo Numérico Simplificado\n",
    "\n",
    "O exemplo abaixo mostra **como o gradiente atua no vetor `[CLS]`**.\n",
    "\n",
    "- h_cls = torch.tensor([0.2, 0.1, 0.4])   # embedding [CLS]\n",
    "- W_cls = torch.tensor([[ 0.5, -0.3, 0.1],\n",
    "- [-0.2,  0.4, 0.6]])   # pesos do classificador\n",
    "- b = torch.tensor([0.0, 0.0])\n",
    "\n",
    "A saída antes do ajuste pode ser algo como:\n",
    "\n",
    "> tensor([0.63, 0.37])   # predição: classe 0\n",
    "\n",
    "Se o rótulo verdadeiro é 1, a perda:\n",
    "\n",
    "$$\n",
    "L = -\\log(0.37)\n",
    "$$\n",
    "\n",
    "gera um gradiente que:\n",
    "\n",
    "- diminui a confiança na classe 0;\n",
    "- aumenta as direções em $ h_{cls} $ que favorecem a classe 1.\n",
    "\n",
    "Após algumas iterações, o vetor `[CLS]` é ajustado de modo que:\n",
    "\n",
    "$ Softmax(W_cls ⋅ h_cls) ≈ [0.1, 0.9] $\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretação Final\n",
    "\n",
    "Depois do *fine-tuning*:\n",
    "- O vetor `[CLS]` é um **resumo contextual** ajustado à tarefa.\n",
    "- A camada linear \\( W_{cls} \\) aprende um **hiperplano de decisão** que separa `[CLS]` por classe.\n",
    "- Por isso, podemos usar apenas os vetores `[CLS]` (sem o resto do BERT) para visualizar como o modelo organiza o espaço semântico — o que faremos a seguir com **t-SNE/UMAP**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb51354",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1761098037894,
     "user": {
      "displayName": "Bruno Magalhaes Nogueira",
      "userId": "18320277366917905276"
     },
     "user_tz": 240
    },
    "id": "2eb51354",
    "outputId": "de67b153-bff5-4e5d-8e03-cf066988af6f"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Vetor [CLS] e pesos iniciais (3 dimensões → 2 classes)\n",
    "h_cls = torch.tensor([0.2, 0.1, 0.4], requires_grad=True)\n",
    "W_cls = torch.tensor([[ 0.5, -0.3, 0.1],\n",
    "                      [-0.2,  0.4, 0.6]], requires_grad=True)\n",
    "b = torch.tensor([0.0, 0.0], requires_grad=True)\n",
    "\n",
    "# Forward pass\n",
    "logits = W_cls @ h_cls + b\n",
    "probs = F.softmax(logits, dim=0)\n",
    "print(\"Probabilidades iniciais:\", probs.detach().numpy())\n",
    "\n",
    "# Rótulo verdadeiro: classe 1 (positiva)\n",
    "target = torch.tensor([0., 1.])\n",
    "\n",
    "# Perda (entropia cruzada)\n",
    "loss = -torch.sum(target * torch.log(probs))\n",
    "print(\"Perda inicial:\", loss.item())\n",
    "\n",
    "# Backprop\n",
    "loss.backward()\n",
    "\n",
    "print(\"\\nGradiente em relação a h_cls:\", h_cls.grad)\n",
    "print(\"Gradiente em relação a W_cls:\", W_cls.grad)\n",
    "\n",
    "# Atualiza manualmente (1 passo de SGD)\n",
    "lr = 0.5\n",
    "with torch.no_grad():\n",
    "    h_cls -= lr * h_cls.grad\n",
    "    W_cls -= lr * W_cls.grad\n",
    "\n",
    "logits_new = W_cls @ h_cls + b\n",
    "probs_new = F.softmax(logits_new, dim=0)\n",
    "print(\"\\nProbabilidades após atualização:\", probs_new.detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba8c6f",
   "metadata": {
    "id": "afba8c6f"
   },
   "source": [
    "## 5.6 — Fine-tuning do BERT na prática (Classificação de Sentenças)\n",
    "\n",
    "Nesta seção, vamos **ajustar** (fine-tune) um BERT pré-treinado para uma tarefa supervisionada de **classificação de sentenças** (sentimento).  \n",
    "Usaremos o modelo `BertForSequenceClassification`, que adiciona automaticamente uma **cabeça linear** sobre o vetor do **token `[CLS]`** (na prática, o \"pooled output\" = `tanh(W * h_[CLS] + b)`).\n",
    "\n",
    "### Pipeline\n",
    "\n",
    "1. **Carregar dados** (GLUE/SST-2; se indisponível, usamos um fallback em memória).\n",
    "2. **Tokenizar** com `BertTokenizerFast` (`[CLS] ... [SEP]` automaticamente).\n",
    "3. **Instanciar o modelo** `BertForSequenceClassification(num_labels=2)`.\n",
    "4. **Treinar** com `Trainer` (taxa pequena, poucas épocas).\n",
    "5. **Avaliar** (accuracy, F1) e **inspecionar previsões**.\n",
    "\n",
    "> Intuição: durante o fine-tuning, o vetor contextual do `[CLS]` passa por uma camada linear + softmax.  \n",
    "> A perda supervisionada **empurra** o embedding do `[CLS]` para organizar o espaço semântico de modo a separar as classes (positivo/negativo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1bc75e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "executionInfo": {
     "elapsed": 7835,
     "status": "error",
     "timestamp": 1761098403882,
     "user": {
      "displayName": "Bruno Magalhaes Nogueira",
      "userId": "18320277366917905276"
     },
     "user_tz": 240
    },
    "id": "0e1bc75e",
    "outputId": "5916b8ff-2ba4-4e02-9dc7-a2a0e73942ad"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BERT Fine-tuning — Classificação (SST-2 com fallback) + SANEAMENTO ULTRARROBUSTO\n",
    "# ============================================================\n",
    "import os, random, math, inspect\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# ---------------------------\n",
    "# 0) Setup determinístico\n",
    "# ---------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# ---------------------------\n",
    "# 1) (Colab) instalar libs\n",
    "# ---------------------------\n",
    "try:\n",
    "    import google.colab  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip -q install -U \"transformers>=4.39\" \"datasets>=2.14\" \"accelerate>=0.28\" \"evaluate>=0.4\"\n",
    "\n",
    "# ---------------------------\n",
    "# 2) Imports principais\n",
    "# ---------------------------\n",
    "# import transformers\n",
    "from transformers import (\n",
    "    BertTokenizerFast, BertForSequenceClassification,\n",
    "    Trainer, TrainingArguments\n",
    ")\n",
    "print(\"transformers:\", transformers.__version__)\n",
    "\n",
    "# Helper: TrainingArguments compatível\n",
    "def build_training_arguments(**kwargs) -> TrainingArguments:\n",
    "    sig = inspect.signature(TrainingArguments.__init__)\n",
    "    allowed = set(sig.parameters.keys()); allowed.discard(\"self\")\n",
    "    filtered = {k: v for k, v in kwargs.items() if k in allowed}\n",
    "    dropped = [k for k in kwargs if k not in allowed]\n",
    "    if dropped:\n",
    "        print(\"[Aviso] parâmetros ignorados:\", dropped)\n",
    "    return TrainingArguments(**filtered)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) Dataset: GLUE/SST-2 → fallback\n",
    "# ---------------------------\n",
    "USE_FALLBACK = False\n",
    "train_texts, train_labels = [], []\n",
    "val_texts,   val_labels   = [], []\n",
    "\n",
    "try:\n",
    "    from datasets import load_dataset\n",
    "    glue = load_dataset(\"glue\", \"sst2\")\n",
    "    train_texts = glue[\"train\"][\"sentence\"]\n",
    "    train_labels= glue[\"train\"][\"label\"]\n",
    "    val_texts   = glue[\"validation\"][\"sentence\"]\n",
    "    val_labels  = glue[\"validation\"][\"label\"]\n",
    "    print(f\"GLUE/SST-2 carregado: train={len(train_texts)}  val={len(val_texts)}\")\n",
    "except Exception as e:\n",
    "    print(\"[AVISO] Falha ao carregar GLUE/SST-2:\", repr(e))\n",
    "    USE_FALLBACK = True\n",
    "    train_pairs = [\n",
    "        (\"i loved the movie, it was fantastic and touching.\", 1),\n",
    "        (\"what a terrible waste of time.\", 0),\n",
    "        (\"an excellent script and strong performances.\", 1),\n",
    "        (\"the film is boring and predictable.\", 0),\n",
    "        (\"absolutely wonderful and inspiring!\", 1),\n",
    "        (\"bad acting and poor dialogue.\", 0),\n",
    "        (\"smart, funny, and well paced.\", 1),\n",
    "        (\"i hated every minute of it.\", 0),\n",
    "        (\"a delightful surprise with great music.\", 1),\n",
    "        (\"the plot makes no sense at all.\", 0),\n",
    "        (\"remarkably good for a low budget.\", 1),\n",
    "        (\"painfully slow and unoriginal.\", 0),\n",
    "    ]\n",
    "    random.shuffle(train_pairs)\n",
    "    train_texts = [t for t,_ in train_pairs]\n",
    "    train_labels= [y for _,y in train_pairs]\n",
    "    val_pairs = [\n",
    "        (\"wonderful direction and amazing visuals.\", 1),\n",
    "        (\"awful script and worse execution.\", 0),\n",
    "        (\"i really enjoyed this film.\", 1),\n",
    "        (\"it was not enjoyable at all.\", 0),\n",
    "    ]\n",
    "    val_texts  = [t for t,_ in val_pairs]\n",
    "    val_labels = [y for _,y in val_pairs]\n",
    "    print(f\"Fallback: train={len(train_texts)}  val={len(val_texts)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# 4) SANEAMENTO ULTRARROBUSTO\n",
    "# ---------------------------\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def _is_nan(x):\n",
    "    try:\n",
    "        return bool(np.isnan(x))  # cobre floats numpy e python\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def _to_plain_str(x):\n",
    "    # bytes → str\n",
    "    if isinstance(x, (bytes, bytearray)):\n",
    "        try:\n",
    "            x = x.decode(\"utf-8\", \"ignore\")\n",
    "        except Exception:\n",
    "            x = str(x)\n",
    "    # numpy types / outros\n",
    "    if isinstance(x, (np.generic,)):\n",
    "        x = x.item()\n",
    "    # dict comum com chave 'text' ou 'sentence'\n",
    "    if isinstance(x, dict):\n",
    "        for k in (\"text\", \"sentence\", \"content\"):\n",
    "            if k in x and isinstance(x[k], (str, bytes, bytearray)):\n",
    "                return _to_plain_str(x[k])\n",
    "        # último recurso: string da representação\n",
    "        return str(x)\n",
    "    # número → str\n",
    "    if isinstance(x, (int, float, np.integer, np.floating)) and not _is_nan(x):\n",
    "        return str(x)\n",
    "    # strings “normais”\n",
    "    if isinstance(x, str):\n",
    "        return x\n",
    "    # iteráveis de strings → junta\n",
    "    if isinstance(x, Iterable) and not isinstance(x, (str, bytes, bytearray)):\n",
    "        # achata e junta com espaço\n",
    "        flat = []\n",
    "        for item in x:\n",
    "            s = _to_plain_str(item)\n",
    "            if s is not None and s.strip():\n",
    "                flat.append(s.strip())\n",
    "        return \" \".join(flat) if flat else None\n",
    "    # fallback\n",
    "    try:\n",
    "        return str(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def clean_xy(texts, labels, max_bad_print=5, name=\"train\"):\n",
    "    X, y = [], []\n",
    "    bad_samples = []\n",
    "    # Se vier numpy array / pandas Series, transforma\n",
    "    if hasattr(texts, \"tolist\"):\n",
    "        texts = texts.tolist()\n",
    "    if hasattr(labels, \"tolist\"):\n",
    "        labels = labels.tolist()\n",
    "\n",
    "    for t, l in zip(texts, labels):\n",
    "        # remover None/NaN\n",
    "        if t is None:\n",
    "            bad_samples.append((\"None\", t)); continue\n",
    "        if _is_nan(t):\n",
    "            bad_samples.append((\"NaN\", t)); continue\n",
    "\n",
    "        s = _to_plain_str(t)\n",
    "        if s is None:\n",
    "            bad_samples.append((\"unconvertible\", t)); continue\n",
    "        s = s.strip()\n",
    "        if not s:\n",
    "            bad_samples.append((\"empty after strip\", t)); continue\n",
    "\n",
    "        try:\n",
    "            lbl = int(l)\n",
    "        except Exception:\n",
    "            # alguns datasets retornam np.int64 etc.\n",
    "            try:\n",
    "                lbl = int(np.array(l).item())\n",
    "            except Exception:\n",
    "                bad_samples.append((\"bad label\", (t, l))); continue\n",
    "\n",
    "        X.append(s); y.append(lbl)\n",
    "\n",
    "    if bad_samples:\n",
    "        print(f\"[{name}] {len(bad_samples)} amostra(s) removida(s) por formato inválido.\")\n",
    "        for i, (reason, sample) in enumerate(bad_samples[:max_bad_print], 1):\n",
    "            print(f\"  #{i} motivo={reason}  exemplo={repr(sample)[:120]}\")\n",
    "\n",
    "    return X, y\n",
    "\n",
    "train_texts, train_labels = clean_xy(train_texts, train_labels, name=\"train\")\n",
    "val_texts,   val_labels   = clean_xy(val_texts,   val_labels,   name=\"val\")\n",
    "\n",
    "print(f\"Textos saneados: train={len(train_texts)}  val={len(val_texts)}\")\n",
    "assert len(train_texts) == len(train_labels) and len(val_texts) == len(val_labels)\n",
    "\n",
    "# checagem final (se ainda falhar, imprime tipos “estranhos”)\n",
    "def _debug_types(name, xs, n=5):\n",
    "    weird = [(i, type(x).__name__, repr(x)[:80]) for i, x in enumerate(xs) if not isinstance(x, str)]\n",
    "    if weird:\n",
    "        print(f\"[DEBUG] {name}: itens não-string após saneamento:\", weird[:n])\n",
    "\n",
    "_debug_types(\"train_texts\", train_texts)\n",
    "_debug_types(\"val_texts\",   val_texts)\n",
    "\n",
    "# ---------------------------\n",
    "# 5) Tokenizer e tokenização\n",
    "# ---------------------------\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "MAX_LEN = 128\n",
    "\n",
    "def tokenize_batch(texts):\n",
    "    # segurança extra: garante list[str]\n",
    "    assert isinstance(texts, (list, tuple)), \"tokenize_batch espera list/tuple de strings.\"\n",
    "    assert all(isinstance(t, str) for t in texts), \"tokenize_batch recebeu itens não-string.\"\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_enc = tokenize_batch(train_texts)\n",
    "val_enc   = tokenize_batch(val_texts)\n",
    "\n",
    "# ---------------------------\n",
    "# 6) Dataset PyTorch\n",
    "# ---------------------------\n",
    "class TorchTextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels    = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: v[idx] for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "train_ds = TorchTextDataset(train_enc, train_labels)\n",
    "val_ds   = TorchTextDataset(val_enc,   val_labels)\n",
    "\n",
    "# ---------------------------\n",
    "# 7) Modelo (usa pooled_output = [CLS])\n",
    "# ---------------------------\n",
    "num_labels = 2\n",
    "model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels).to(device)\n",
    "\n",
    "# ---------------------------\n",
    "# 8) Métricas\n",
    "# ---------------------------\n",
    "try:\n",
    "    import evaluate\n",
    "    acc_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric  = evaluate.load(\"f1\")\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        r1 = acc_metric.compute(predictions=preds, references=labels)\n",
    "        r2 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "        return {\"accuracy\": r1[\"accuracy\"], \"f1\": r2[\"f1\"]}\n",
    "except Exception:\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        acc = (preds == labels).mean()\n",
    "        return {\"accuracy\": float(acc)}\n",
    "\n",
    "# ---------------------------\n",
    "# 9) Treinamento com Trainer\n",
    "# ---------------------------\n",
    "EPOCHS = 2 if not USE_FALLBACK else 4\n",
    "BATCH  = 16 if not USE_FALLBACK else 8\n",
    "\n",
    "args = build_training_arguments(\n",
    "    output_dir=\"bert-ft-sst2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    per_device_train_batch_size=BATCH,\n",
    "    per_device_eval_batch_size=BATCH,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    seed=SEED,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\n=== Iniciando fine-tuning do BERT ===\")\n",
    "train_out = trainer.train()\n",
    "eval_out  = trainer.evaluate()\n",
    "print(\"\\nResultados de validação:\", eval_out)\n",
    "\n",
    "# ---------------------------\n",
    "# 10) Teste prático — previsões e inspeção\n",
    "# ---------------------------\n",
    "def tokenize_one(text):\n",
    "    return tokenizer(\n",
    "        text, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "def predict(texts):\n",
    "    model.eval()\n",
    "    assert isinstance(texts, (list, tuple)), \"predict espera list/tuple de strings.\"\n",
    "    enc = tokenizer(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(**enc)\n",
    "        probs = torch.softmax(out.logits, dim=-1).cpu().numpy()\n",
    "        preds = probs.argmax(axis=-1)\n",
    "    return preds, probs\n",
    "\n",
    "samples = [\n",
    "    \"i absolutely loved this movie!\",\n",
    "    \"this was a complete waste of time.\",\n",
    "    \"the performances are strong and convincing.\",\n",
    "    \"the plot is weak and the pacing is terrible.\",\n",
    "]\n",
    "\n",
    "preds, probs = predict(samples)\n",
    "label_names = [\"negative\", \"positive\"]\n",
    "print(\"\\n=== Amostras de previsão ===\")\n",
    "for s, p, pr in zip(samples, preds, probs):\n",
    "    print(f\"- {s}\\n  -> pred: {label_names[p]}  probs={pr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81373235",
   "metadata": {
    "id": "81373235"
   },
   "outputs": [],
   "source": [
    "# Para inspecionar manualmente o vetor [CLS] (pooled_output):\n",
    "# with torch.no_grad():\n",
    "#     enc = tokenize_one(\"a great movie.\").to(device)\n",
    "#     outputs = model.bert(**enc, return_dict=True)\n",
    "#     pooled = outputs.pooler_output\n",
    "#     print(\"pooled_output shape:\", pooled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a9312d",
   "metadata": {
    "id": "48a9312d"
   },
   "source": [
    "# 5.7 BERT em tarefas de *Question Answering*\n",
    "\n",
    "No *Question Answering* (QA) — como em *SQuAD (Stanford Question Answering Dataset)* —  \n",
    "o modelo deve **encontrar o trecho exato da resposta** dentro de um texto dado.\n",
    "\n",
    "---\n",
    "\n",
    "## Estrutura de Entrada\n",
    "\n",
    "O input do BERT é a **concatenação** da *pergunta* e do *contexto*:\n",
    "\n",
    "```text\n",
    "[CLS] Quem descobriu o Brasil? [SEP] Pedro Álvares Cabral descobriu o Brasil em 1500. [SEP]\n",
    "```\n",
    "\n",
    "- `[CLS]` → marcador de início (como sempre)  \n",
    "- `[SEP]` → separa a pergunta do contexto  \n",
    "- cada token (pergunta + contexto) recebe *token embeddings*, *segment embeddings* (A = pergunta, B = contexto) e *position embeddings*.\n",
    "\n",
    "---\n",
    "\n",
    "## O que o BERT aprende a prever\n",
    "\n",
    "O modelo de QA **não gera texto**.  \n",
    "Ele **prediz dois índices** dentro da sequência de tokens do contexto:\n",
    "\n",
    "1. **Start token** → onde a resposta começa.  \n",
    "2. **End token** → onde a resposta termina.\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "```text\n",
    "Tokens: [CLS] Quem descobriu o Brasil ? [SEP] Pedro Álvares Cabral descobriu o Brasil em 1500 . [SEP]\n",
    "Index:   0     1     2          3      4   5    6      7       8          9  10    11   12  13   14\n",
    "\n",
    "Resposta correta: \"Pedro Álvares Cabral\"\n",
    "→ start = 5, end = 8\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Saídas do modelo\n",
    "\n",
    "O BERT retorna **um vetor por token** (como sempre).  \n",
    "Para QA, adicionamos **duas camadas lineares** sobre esses vetores:\n",
    "\n",
    "$begin:math:display$\n",
    "\\\\begin{align}\n",
    "\\\\text{StartLogits} &= W_{start} \\\\cdot H + b_{start} \\\\\\\\\n",
    "\\\\text{EndLogits}   &= W_{end}   \\\\cdot H + b_{end}\n",
    "\\\\end{align}\n",
    "$end:math:display$\n",
    "\n",
    "onde $begin:math:text$ H $end:math:text$ é a matriz $begin:math:text$(n_{tokens}, d_{model})$end:math:text$ com as representações finais.\n",
    "\n",
    "- `start_logits`: pontua cada token como *início possível da resposta*  \n",
    "- `end_logits`: pontua cada token como *fim possível da resposta*  \n",
    "\n",
    "O modelo escolhe o par `(start, end)` com a soma dos logits mais alta.\n",
    "\n",
    "---\n",
    "\n",
    "## Exemplo conceitual\n",
    "\n",
    "Suponha que a saída de *start_logits* e *end_logits* seja:\n",
    "\n",
    "| Token | Start logit | End logit |\n",
    "|:------|-------------:|----------:|\n",
    "| `[CLS]` | -5.3 | -5.0 |\n",
    "| `Pedro` | **7.2** | 0.5 |\n",
    "| `Álvares` | 5.8 | 6.1 |\n",
    "| `Cabral` | 0.8 | **7.5** |\n",
    "| `descobriu` | -0.4 | -2.1 |\n",
    "\n",
    "O melhor par `(start=Pedro, end=Cabral)` forma a resposta:\n",
    "```\n",
    "Pedro Álvares Cabral\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Função de custo\n",
    "\n",
    "Durante o treino, temos rótulos reais `start_true` e `end_true`.\n",
    "\n",
    "A perda é a soma das entropias cruzadas independentes:\n",
    "\n",
    "$begin:math:display$\n",
    "\\\\mathcal{L} = CE(\\\\hat{y}_{start}, y_{start}) + CE(\\\\hat{y}_{end}, y_{end})\n",
    "$end:math:display$\n",
    "\n",
    "Essa perda ajusta todos os vetores de saída (não só o `[CLS]`),  \n",
    "fazendo com que as representações do início e do fim da resposta se tornem mais distintas.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpretação das saídas\n",
    "\n",
    "No final:\n",
    "\n",
    "- cada token do contexto tem uma pontuação de “probabilidade de início/fim”;\n",
    "- o `[CLS]` continua existindo (geralmente usado para *no-answer* em datasets como SQuAD 2.0);\n",
    "- o modelo **não gera texto**, apenas **aponta spans** dentro do contexto original.\n",
    "- o `[CLS]` é usado apenas como referência global (ou para no-answer),\n",
    "- o foco está nas representações **token a token** do contexto,\n",
    "- a saída são **dois vetores de logits** (start e end), que identificam o *span* da resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802da796",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423,
     "referenced_widgets": [
      "2bb58d5cf7b447e6aea0efd3ceb17cc9",
      "e3d9b6bcac514e208a5de295459e4e82",
      "739d793cd7ed4b7c980b4726eb586688",
      "57a841e98b1a4b388429a8b99ef8fc13",
      "db0067410e9b46c29d2f00e787d66586",
      "2e8eede453074a4e9b1e3d9e34f5a13f",
      "d42591a3531c47b28564b911a24b43b2",
      "71dfc9da17a94c8ebb96eea243a3ffd8",
      "e52ea32d91324cd39e5e5f3c4260b2ac",
      "dbffa55020c9477db7492c8e5ea2c1c6",
      "7eede9e5b914428495f56bd7f0e5d6a6",
      "d53b10dfe3a24cab9b95b96e41671c4e",
      "e61a3eda8913455d8c982eae4d6864bf",
      "7d80ab8a915245b595b40b7b123798e2",
      "1618737a92a34c5aabc7a4e865167dae",
      "1cf90921bf0f4a09869733afba8c0f98",
      "f663a9e56ad647569443006a07a80d89",
      "25899c292f1f4089a6c5cef76c52031e",
      "c6db1c0737d2479ba5fb052e5fa9c311",
      "2ac14f1fdaf4483b9ddfa0d321f0aa53",
      "9497e8b203254022abb8350ac26720cc",
      "e8fd1f2cd81f49f29d6688d8076a4271",
      "dc082d1619874edaaff5c24954fd5f4d",
      "3031420fb5514c4ebd8c401de386403f",
      "81e4340ba5814cc4b3c4b741ba060b7f",
      "49b7526dc12946f4ae27ea8b0a634a47",
      "19dadcfba05b424d9cfb53d3c4748ccd",
      "903594938b8c4fed8424dbb6d8c8998e",
      "d352b819c3b84d59959c3c132e10190e",
      "4452728e4fe84954b535552f45d1500f",
      "d3f36bb955c44b608965cec35700827b",
      "bcbfb19589da444da5795cd81a4a31fb",
      "ba2dc3997a9b4da3a81b3498bbb8d483",
      "c8724a42d1f940bd877c9ba8598ff456",
      "1199ef72f11a47f9b0b968692c117976",
      "770d968149f04d8cb08894a3902940ec",
      "805120224642475e890dcb05d1ad10bf",
      "2c626019735c4d60b05cf1b60fd09879",
      "b966dc100d974a3cb8ec91eb4675237e",
      "5441efb3b2cc48e18fbfd7131d052cf1",
      "4bdb81895bb3490c82be36fa2814c535",
      "86306779935048fc9c12c747ec48b456",
      "cac6cf22a05d4a31bfe70fa2653087e8",
      "c4297591a4104a1189ff549c2b1fa6f0",
      "cb983b49df994889bf4d954e68fe86d2",
      "efcf9ebd5f054f02816b86c0da1b4609",
      "961352789ab04706974e96cb3484e064",
      "9af8ade79922485b80c5cabb8337c27a",
      "86fb1a4260c24e1684684fbba9f11330",
      "0a859f3849354a17b736e29a83d6b9de",
      "b5908ad3733c4c82a3f9be26e1d77822",
      "520ec4bf4e0c40aab100fe5f645d8819",
      "f44bad4c018647f7bf13e28f63de9638",
      "24c99c0d75784cfa8cf5599eebfb43fa",
      "a69b279ab3294d2d91fdb49279a89516"
     ]
    },
    "executionInfo": {
     "elapsed": 28567,
     "status": "ok",
     "timestamp": 1761098270846,
     "user": {
      "displayName": "Bruno Magalhaes Nogueira",
      "userId": "18320277366917905276"
     },
     "user_tz": 240
    },
    "id": "802da796",
    "outputId": "e905fb9c-dc50-40f3-81be-d7c28d6a4272"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
    "\n",
    "# 1) Modelo já fine-tuned em SQuAD\n",
    "MODEL_NAME = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n",
    "# Alternativa mais leve:\n",
    "# MODEL_NAME = \"distilbert-base-uncased-distilled-squad\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "model = BertForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device).eval()\n",
    "\n",
    "# 2) Exemplo de pergunta e contexto\n",
    "question = \"Who discovered Brazil?\"\n",
    "context = (\n",
    "    \"Pedro Álvares Cabral discovered Brazil in the year 1500 during a Portuguese expedition. \"\n",
    "    \"He is considered one of the key figures in the Age of Discovery.\"\n",
    ")\n",
    "\n",
    "# 3) Tokenização com offsets (para mapear tokens no texto original)\n",
    "enc = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length=384,\n",
    "    return_offsets_mapping=True\n",
    ")\n",
    "enc = {k: v.to(device) for k, v in enc.items()}\n",
    "offsets = enc[\"offset_mapping\"][0].tolist()\n",
    "ttypes = enc[\"token_type_ids\"][0].tolist()\n",
    "\n",
    "# 4) Forward\n",
    "with torch.no_grad():\n",
    "    outputs = model(**{k: v for k, v in enc.items() if k != \"offset_mapping\"})\n",
    "start_logits, end_logits = outputs.start_logits[0], outputs.end_logits[0]\n",
    "\n",
    "# 5) Filtrar apenas tokens do contexto (segment=1)\n",
    "context_mask = torch.tensor([1 if t == 1 else 0 for t in ttypes], device=device, dtype=torch.bool)\n",
    "start_logits = start_logits.masked_fill(~context_mask, -1e9)\n",
    "end_logits = end_logits.masked_fill(~context_mask, -1e9)\n",
    "\n",
    "# 6) Selecionar melhor par (start, end)\n",
    "best_start = torch.argmax(start_logits).item()\n",
    "best_end = torch.argmax(end_logits).item()\n",
    "if best_end < best_start:\n",
    "    best_end = best_start\n",
    "\n",
    "# 7) Reconstruir texto a partir dos offsets\n",
    "start_char, _ = offsets[best_start]\n",
    "_, end_char = offsets[best_end]\n",
    "answer = context[start_char:end_char]\n",
    "\n",
    "print(\"Pergunta:\", question)\n",
    "print(\"Melhor resposta:\", repr(answer))\n",
    "print(f\"(start={best_start}, end={best_end})\")\n",
    "\n",
    "# 8) Mostrar top-k spans\n",
    "def topk_spans(start_logits, end_logits, offsets, context, k=5, max_len=30):\n",
    "    s, e = start_logits.cpu().numpy(), end_logits.cpu().numpy()\n",
    "    top_s, top_e = np.argsort(s)[::-1][:k*5], np.argsort(e)[::-1][:k*5]\n",
    "    spans = []\n",
    "    for i in top_s:\n",
    "        for j in top_e:\n",
    "            if j < i or (j - i + 1) > max_len:\n",
    "                continue\n",
    "            score = s[i] + e[j]\n",
    "            sc, ec = offsets[i][0], offsets[j][1]\n",
    "            spans.append((score, context[sc:ec]))\n",
    "    spans.sort(key=lambda x: x[0], reverse=True)\n",
    "    return spans[:k]\n",
    "\n",
    "print(\"\\nTop-5 spans mais prováveis:\")\n",
    "for score, span in topk_spans(start_logits, end_logits, offsets, context):\n",
    "    print(f\"score={score:6.2f} | {span}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9ec382",
   "metadata": {
    "id": "df9ec382"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env-misc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "007e14a7b0484fe382ce6ea6553b33b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "065320bead224e0b828b63f3977832c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "066bafd1cda54fd39d09c8b15d93cd68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06b4567b458c4b34b0c6cf14ecd5e140": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "09e7cf75322044d091f285323f73bbd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0a859f3849354a17b736e29a83d6b9de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1199ef72f11a47f9b0b968692c117976": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b966dc100d974a3cb8ec91eb4675237e",
      "placeholder": "​",
      "style": "IPY_MODEL_5441efb3b2cc48e18fbfd7131d052cf1",
      "value": "config.json: 100%"
     }
    },
    "1618737a92a34c5aabc7a4e865167dae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9497e8b203254022abb8350ac26720cc",
      "placeholder": "​",
      "style": "IPY_MODEL_e8fd1f2cd81f49f29d6688d8076a4271",
      "value": " 232k/232k [00:00&lt;00:00, 17.1MB/s]"
     }
    },
    "19644b37b47b4f07a6af33388066b7da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1988766bcef54cbabbe03969118338a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f55646981f254a7e9889d9f4cf6b952c",
       "IPY_MODEL_7854e03c883941ed895f3d057ae77e4a",
       "IPY_MODEL_ec4a4b4f274b46179c5755f0b6334f1f"
      ],
      "layout": "IPY_MODEL_065320bead224e0b828b63f3977832c1"
     }
    },
    "19dadcfba05b424d9cfb53d3c4748ccd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b501e21dade4541a8cff13d5d0d6fe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1cf90921bf0f4a09869733afba8c0f98": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1df2713322fa47d5807a94337b49158e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_458e077f1d8d4293a6f69ba7841a69a8",
      "placeholder": "​",
      "style": "IPY_MODEL_f7a44c6b89d24a1ea15a66bf484deadb",
      "value": "vocab.txt: 100%"
     }
    },
    "2169b309fa0b4a7ea0b2d169eca9304d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8512fe2d0390420cacc9860a34948d1f",
       "IPY_MODEL_969e02b73e28418c9e46d660932e0335",
       "IPY_MODEL_602fe170d0fa4a9e8289340d389d01be"
      ],
      "layout": "IPY_MODEL_60649f63928e40a4b4d92364744aa925"
     }
    },
    "24c99c0d75784cfa8cf5599eebfb43fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "25899c292f1f4089a6c5cef76c52031e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ac14f1fdaf4483b9ddfa0d321f0aa53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2b263c6d8ec9435283999ce0a769fa3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2bb58d5cf7b447e6aea0efd3ceb17cc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e3d9b6bcac514e208a5de295459e4e82",
       "IPY_MODEL_739d793cd7ed4b7c980b4726eb586688",
       "IPY_MODEL_57a841e98b1a4b388429a8b99ef8fc13"
      ],
      "layout": "IPY_MODEL_db0067410e9b46c29d2f00e787d66586"
     }
    },
    "2c626019735c4d60b05cf1b60fd09879": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e8eede453074a4e9b1e3d9e34f5a13f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3031420fb5514c4ebd8c401de386403f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_903594938b8c4fed8424dbb6d8c8998e",
      "placeholder": "​",
      "style": "IPY_MODEL_d352b819c3b84d59959c3c132e10190e",
      "value": "tokenizer.json: 100%"
     }
    },
    "32713cd38eb64597b895db034a020abd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36b96b84c0ea4c04bfbe00eb41f0b759": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39fcdc2adc974156ab9b3cf0d0b5659b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7da5c879db4145c18381605bc913ef6b",
      "placeholder": "​",
      "style": "IPY_MODEL_6417f89546094943b76c4928f6051dd4",
      "value": "config.json: 100%"
     }
    },
    "4434341001c74f5f980b7af282d405b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_885c4ec9ea464e1589760cb496e95365",
       "IPY_MODEL_bcf881141cd045b5b78f469894f3a993",
       "IPY_MODEL_49b33a35dbaa4d80acc8df3c9e283dc3"
      ],
      "layout": "IPY_MODEL_5ad0adf354a54c3aa37d3dc7c5ffb519"
     }
    },
    "4452728e4fe84954b535552f45d1500f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "456eaaf0079740729e22e7ee14521e52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "458e077f1d8d4293a6f69ba7841a69a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "472e7ef2a53c424aa111c6d05c5194dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "49b33a35dbaa4d80acc8df3c9e283dc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_472e7ef2a53c424aa111c6d05c5194dd",
      "placeholder": "​",
      "style": "IPY_MODEL_007e14a7b0484fe382ce6ea6553b33b0",
      "value": " 466k/466k [00:00&lt;00:00, 2.00MB/s]"
     }
    },
    "49b7526dc12946f4ae27ea8b0a634a47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcbfb19589da444da5795cd81a4a31fb",
      "placeholder": "​",
      "style": "IPY_MODEL_ba2dc3997a9b4da3a81b3498bbb8d483",
      "value": " 466k/466k [00:00&lt;00:00, 43.3MB/s]"
     }
    },
    "4bdb81895bb3490c82be36fa2814c535": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "520ec4bf4e0c40aab100fe5f645d8819": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53a6e3de432747788dbc5b6c5d47723f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5441efb3b2cc48e18fbfd7131d052cf1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55c5edfa16c04c4a98caf74c1672aa6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_39fcdc2adc974156ab9b3cf0d0b5659b",
       "IPY_MODEL_fe62a5de99e84ba488eccd06cc2d43e5",
       "IPY_MODEL_b4d4097ad5e9423b9db70cccba6abbc1"
      ],
      "layout": "IPY_MODEL_19644b37b47b4f07a6af33388066b7da"
     }
    },
    "57a841e98b1a4b388429a8b99ef8fc13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbffa55020c9477db7492c8e5ea2c1c6",
      "placeholder": "​",
      "style": "IPY_MODEL_7eede9e5b914428495f56bd7f0e5d6a6",
      "value": " 48.0/48.0 [00:00&lt;00:00, 5.23kB/s]"
     }
    },
    "5ad0adf354a54c3aa37d3dc7c5ffb519": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "602fe170d0fa4a9e8289340d389d01be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_becd85b9d0ab425883d03d128bb15730",
      "placeholder": "​",
      "style": "IPY_MODEL_1b501e21dade4541a8cff13d5d0d6fe4",
      "value": " 48.0/48.0 [00:00&lt;00:00, 5.37kB/s]"
     }
    },
    "60649f63928e40a4b4d92364744aa925": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61735386d9a54e8a99accf6822cd9527": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61e02de3deaf4b0881b293e913bf71e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6417f89546094943b76c4928f6051dd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64a04f0530a34c91b780bbd05664f041": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7a2aca84a2f4478e8c7203a1ce8b4466",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d79af1bcdb3b4d068df10fc4802b0627",
      "value": 231508
     }
    },
    "69bd57449c334d12871ef164851ff772": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71dfc9da17a94c8ebb96eea243a3ffd8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "739d793cd7ed4b7c980b4726eb586688": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71dfc9da17a94c8ebb96eea243a3ffd8",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e52ea32d91324cd39e5e5f3c4260b2ac",
      "value": 48
     }
    },
    "770d968149f04d8cb08894a3902940ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4bdb81895bb3490c82be36fa2814c535",
      "max": 443,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86306779935048fc9c12c747ec48b456",
      "value": 443
     }
    },
    "7854e03c883941ed895f3d057ae77e4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61735386d9a54e8a99accf6822cd9527",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fb6be34bbace468fbe71a00cf962a61c",
      "value": 440449768
     }
    },
    "7a2aca84a2f4478e8c7203a1ce8b4466": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d80ab8a915245b595b40b7b123798e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6db1c0737d2479ba5fb052e5fa9c311",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2ac14f1fdaf4483b9ddfa0d321f0aa53",
      "value": 231508
     }
    },
    "7da5c879db4145c18381605bc913ef6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eede9e5b914428495f56bd7f0e5d6a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "805120224642475e890dcb05d1ad10bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cac6cf22a05d4a31bfe70fa2653087e8",
      "placeholder": "​",
      "style": "IPY_MODEL_c4297591a4104a1189ff549c2b1fa6f0",
      "value": " 443/443 [00:00&lt;00:00, 34.1kB/s]"
     }
    },
    "81e4340ba5814cc4b3c4b741ba060b7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4452728e4fe84954b535552f45d1500f",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d3f36bb955c44b608965cec35700827b",
      "value": 466062
     }
    },
    "8512fe2d0390420cacc9860a34948d1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f1ad27e141a341289dd794df04f2aef8",
      "placeholder": "​",
      "style": "IPY_MODEL_b0ec1fc39a6a40239e859ab9f87d0535",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "86306779935048fc9c12c747ec48b456": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "86fb1a4260c24e1684684fbba9f11330": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "885c4ec9ea464e1589760cb496e95365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e8ef2549b3b461f883ccfdcc1e85a4b",
      "placeholder": "​",
      "style": "IPY_MODEL_96e3382567704b6fb358c252be3fed07",
      "value": "tokenizer.json: 100%"
     }
    },
    "8e8ef2549b3b461f883ccfdcc1e85a4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "903594938b8c4fed8424dbb6d8c8998e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90cdc87113a74f72884c662448e5bf88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9497e8b203254022abb8350ac26720cc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "961352789ab04706974e96cb3484e064": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_520ec4bf4e0c40aab100fe5f645d8819",
      "max": 1340622760,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f44bad4c018647f7bf13e28f63de9638",
      "value": 1340622760
     }
    },
    "969e02b73e28418c9e46d660932e0335": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53a6e3de432747788dbc5b6c5d47723f",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_32713cd38eb64597b895db034a020abd",
      "value": 48
     }
    },
    "96e3382567704b6fb358c252be3fed07": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9af8ade79922485b80c5cabb8337c27a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24c99c0d75784cfa8cf5599eebfb43fa",
      "placeholder": "​",
      "style": "IPY_MODEL_a69b279ab3294d2d91fdb49279a89516",
      "value": " 1.34G/1.34G [00:23&lt;00:00, 66.7MB/s]"
     }
    },
    "9f2fb9e052d44359bb62a87f1ca5f6f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5568ae260d74f5e89c2ba83b238d11d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a69b279ab3294d2d91fdb49279a89516": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0ec1fc39a6a40239e859ab9f87d0535": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b4d4097ad5e9423b9db70cccba6abbc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61e02de3deaf4b0881b293e913bf71e8",
      "placeholder": "​",
      "style": "IPY_MODEL_066bafd1cda54fd39d09c8b15d93cd68",
      "value": " 570/570 [00:00&lt;00:00, 49.0kB/s]"
     }
    },
    "b5908ad3733c4c82a3f9be26e1d77822": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b6fbaf4655c741cf861ff7769840986d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b966dc100d974a3cb8ec91eb4675237e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9f33343020549599d4dbb329ad5e26c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1df2713322fa47d5807a94337b49158e",
       "IPY_MODEL_64a04f0530a34c91b780bbd05664f041",
       "IPY_MODEL_c040ffe8cb9542b0bb3e6e835e021021"
      ],
      "layout": "IPY_MODEL_06b4567b458c4b34b0c6cf14ecd5e140"
     }
    },
    "ba2dc3997a9b4da3a81b3498bbb8d483": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bcbfb19589da444da5795cd81a4a31fb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcf881141cd045b5b78f469894f3a993": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_456eaaf0079740729e22e7ee14521e52",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_09e7cf75322044d091f285323f73bbd3",
      "value": 466062
     }
    },
    "becd85b9d0ab425883d03d128bb15730": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c040ffe8cb9542b0bb3e6e835e021021": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f2fb9e052d44359bb62a87f1ca5f6f8",
      "placeholder": "​",
      "style": "IPY_MODEL_b6fbaf4655c741cf861ff7769840986d",
      "value": " 232k/232k [00:00&lt;00:00, 15.9MB/s]"
     }
    },
    "c4297591a4104a1189ff549c2b1fa6f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6db1c0737d2479ba5fb052e5fa9c311": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8724a42d1f940bd877c9ba8598ff456": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1199ef72f11a47f9b0b968692c117976",
       "IPY_MODEL_770d968149f04d8cb08894a3902940ec",
       "IPY_MODEL_805120224642475e890dcb05d1ad10bf"
      ],
      "layout": "IPY_MODEL_2c626019735c4d60b05cf1b60fd09879"
     }
    },
    "cac6cf22a05d4a31bfe70fa2653087e8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb983b49df994889bf4d954e68fe86d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_efcf9ebd5f054f02816b86c0da1b4609",
       "IPY_MODEL_961352789ab04706974e96cb3484e064",
       "IPY_MODEL_9af8ade79922485b80c5cabb8337c27a"
      ],
      "layout": "IPY_MODEL_86fb1a4260c24e1684684fbba9f11330"
     }
    },
    "d11c374301394ce9b913c2d57d850dea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d352b819c3b84d59959c3c132e10190e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3f36bb955c44b608965cec35700827b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d42591a3531c47b28564b911a24b43b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d53b10dfe3a24cab9b95b96e41671c4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e61a3eda8913455d8c982eae4d6864bf",
       "IPY_MODEL_7d80ab8a915245b595b40b7b123798e2",
       "IPY_MODEL_1618737a92a34c5aabc7a4e865167dae"
      ],
      "layout": "IPY_MODEL_1cf90921bf0f4a09869733afba8c0f98"
     }
    },
    "d79af1bcdb3b4d068df10fc4802b0627": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "db0067410e9b46c29d2f00e787d66586": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbffa55020c9477db7492c8e5ea2c1c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc082d1619874edaaff5c24954fd5f4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3031420fb5514c4ebd8c401de386403f",
       "IPY_MODEL_81e4340ba5814cc4b3c4b741ba060b7f",
       "IPY_MODEL_49b7526dc12946f4ae27ea8b0a634a47"
      ],
      "layout": "IPY_MODEL_19dadcfba05b424d9cfb53d3c4748ccd"
     }
    },
    "e3d9b6bcac514e208a5de295459e4e82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e8eede453074a4e9b1e3d9e34f5a13f",
      "placeholder": "​",
      "style": "IPY_MODEL_d42591a3531c47b28564b911a24b43b2",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "e52ea32d91324cd39e5e5f3c4260b2ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e61a3eda8913455d8c982eae4d6864bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f663a9e56ad647569443006a07a80d89",
      "placeholder": "​",
      "style": "IPY_MODEL_25899c292f1f4089a6c5cef76c52031e",
      "value": "vocab.txt: 100%"
     }
    },
    "e8fd1f2cd81f49f29d6688d8076a4271": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec4a4b4f274b46179c5755f0b6334f1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_36b96b84c0ea4c04bfbe00eb41f0b759",
      "placeholder": "​",
      "style": "IPY_MODEL_a5568ae260d74f5e89c2ba83b238d11d",
      "value": " 440M/440M [00:18&lt;00:00, 23.5MB/s]"
     }
    },
    "efcf9ebd5f054f02816b86c0da1b4609": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a859f3849354a17b736e29a83d6b9de",
      "placeholder": "​",
      "style": "IPY_MODEL_b5908ad3733c4c82a3f9be26e1d77822",
      "value": "model.safetensors: 100%"
     }
    },
    "f1ad27e141a341289dd794df04f2aef8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f44bad4c018647f7bf13e28f63de9638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f55646981f254a7e9889d9f4cf6b952c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90cdc87113a74f72884c662448e5bf88",
      "placeholder": "​",
      "style": "IPY_MODEL_69bd57449c334d12871ef164851ff772",
      "value": "model.safetensors: 100%"
     }
    },
    "f663a9e56ad647569443006a07a80d89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7a44c6b89d24a1ea15a66bf484deadb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fb6be34bbace468fbe71a00cf962a61c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe62a5de99e84ba488eccd06cc2d43e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d11c374301394ce9b913c2d57d850dea",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2b263c6d8ec9435283999ce0a769fa3d",
      "value": 570
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
