{"cells":[{"cell_type":"code","source":["# !pip install transformers==4.57.1"],"metadata":{"id":"v5pELG5FoMx2","executionInfo":{"status":"ok","timestamp":1761098195795,"user_tz":240,"elapsed":16,"user":{"displayName":"Bruno Magalhaes Nogueira","userId":"18320277366917905276"}}},"id":"v5pELG5FoMx2","execution_count":7,"outputs":[]},{"cell_type":"markdown","id":"0c2a0453","metadata":{"id":"0c2a0453"},"source":["# 5.1 - Introdução ao BERT: Pré-treinamento e Arquitetura\n","\n","Na aula anterior, exploramos detalhadamente o **Transformer**, arquitetura proposta no artigo *Attention is All You Need (Vaswani et al., 2017)*.  \n","Vimos como o modelo substitui as recorrências por **atenção auto-regressiva**, resultando em paralelização e aprendizado mais eficiente de dependências de longo alcance.\n","\n","O **BERT (Bidirectional Encoder Representations from Transformers)**, proposto por **Devlin et al. (2018)**, é um passo além dessa ideia.  \n","Ele se baseia **exclusivamente na parte do encoder do Transformer**, mas introduz um novo paradigma: **aprendizado de representações de linguagem profundas e bidirecionais**, usando **pré-treinamento auto-supervisionado**.\n","\n","<br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/bert_pt_ft.png\" width=\"50%%\">\n","\n","Fonte: Devlin et al. (2018)\n","\n","---\n","\n","## Por que BERT?\n","\n","Antes do BERT, os modelos de linguagem típicos (como GPT-1 ou ELMo) processavam texto **em apenas uma direção**:\n","\n","- Modelos *left-to-right* (como GPT): preveem o próximo token a partir dos anteriores.  \n","- Modelos *right-to-left* (como LM reversos): preveem o token anterior.  \n","- ELMo (2018) combinava duas redes LSTM unidirecionais, mas de forma ainda limitada.\n","\n","Essas abordagens **não capturavam o contexto completo** de uma palavra em sua sentença, já que a representação dependia apenas do passado ou do futuro, mas não dos dois **ao mesmo tempo**.\n","\n","O BERT resolve isso ao:\n","- Treinar **bidirecionalmente**, olhando para a **sentença inteira**;  \n","- Usar um esquema de pré-treinamento **auto-supervisionado** (sem rótulos humanos);  \n","- E depois **ajustar** o modelo (*fine-tuning*) para tarefas específicas de NLP.\n","\n","---\n","\n","## Transfer Learning em NLP\n","\n","Assim como o *ImageNet* revolucionou a visão computacional com o conceito de **pré-treinamento + fine-tuning**, o BERT trouxe essa revolução para o **Processamento de Linguagem Natural (PLN)**.\n","\n","O processo segue duas fases:\n","\n","1. **Pré-treinamento (Pretraining)**  \n","   - O modelo aprende conhecimento linguístico geral a partir de **grandes corpora** (Wikipedia + BooksCorpus).  \n","   - Duas tarefas auto-supervisionadas são usadas:\n","     - **Masked Language Modeling (MLM)**: prever palavras mascaradas no texto.  \n","     - **Next Sentence Prediction (NSP)**: prever se uma sentença B segue naturalmente uma sentença A.\n","\n","2. **Ajuste fino (Fine-tuning)**  \n","   - O modelo é adaptado para uma tarefa específica: classificação, QA, NER, etc.  \n","   - Os mesmos pesos são reutilizados, e apenas algumas camadas finais são ajustadas.\n","\n","Essa combinação tornou o BERT um **modelo universal de linguagem**, facilmente adaptável a diversas tarefas de NLP.\n","\n","---\n","\n","## Intuição: O que o BERT aprende?\n","\n","Durante o pré-treinamento, o BERT **aprende as relações contextuais** entre as palavras:\n","- Como palavras diferentes se associam em frases;  \n","- Que estrutura sintática e semântica definem o sentido;  \n","- Que palavras são prováveis em determinados contextos.\n","\n","Com isso, ele gera **embeddings contextuais**, ou seja, o vetor de uma palavra depende da **sentença em que ela aparece**.\n","\n","> Exemplo:  \n","> - Em “Ele foi ao **banco** sacar dinheiro”, “banco” → instituição financeira.  \n","> - Em “Ela sentou no **banco** do parque”, “banco” → assento.  \n",">\n","> O BERT gera embeddings diferentes para cada uso.\n","\n","---\n","\n","## Arquitetura Geral\n","\n","<br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/bert_size_architecture.png\" width=\"50%%\">\n","\n","Fonte: [Huggingface](https://huggingface.co/blog/bert-101)\n","\n","O BERT baseia-se **no encoder do Transformer**, repetido *N* vezes.  \n","Cada camada contém:\n","\n","1. **Multi-Head Self-Attention**  \n","   - Permite que cada token atenda a todos os outros tokens da sentença, em ambas as direções.  \n","   - É aqui que o “Bidirectional” de BERT acontece.\n","\n","2. **Feed-Forward Network (FFN)**  \n","   - Aplica transformações não lineares em cada posição, aprendendo representações mais ricas.\n","\n","3. **Residual Connections + Layer Normalization**  \n","   - Facilitam o fluxo de gradientes e a estabilidade do treinamento.\n","\n","---\n","\n","## Configurações originais\n","\n","| Modelo | Camadas (L) | Heads | Dimensão (`d_model`) | Dim. Feedforward | Parâmetros |\n","|:--------|:------------:|:------:|:--------------------:|:----------------:|:-----------:|\n","| **BERT Base** | 12 | 12 | 768 | 3072 | 110M |\n","| **BERT Large** | 24 | 16 | 1024 | 4096 | 340M |\n","\n","---\n","\n","## Entrada do BERT\n","\n","O BERT processa o texto em forma de tokens especiais:\n","\n","- **[CLS]** → marca o início da sequência (usado para classificação).  \n","- **[SEP]** → separa sentenças (usado em tarefas de pares).  \n","- **[MASK]** → substitui tokens que o modelo deve prever.\n","\n","> Exemplo:  \n","> Entrada: `[CLS] O gato [MASK] no tapete [SEP]`  \n","> Saída: prever a palavra “dormiu”."]},{"cell_type":"markdown","id":"ac0df512","metadata":{"id":"ac0df512"},"source":["# 5.2 - Objetivos de Pré-Treinamento do BERT\n","\n","O sucesso do BERT vem de seu **pré-treinamento auto-supervisionado** em larga escala.  \n","Ele não usa rótulos humanos: aprende diretamente com **texto cru**, aplicando duas tarefas artificiais que forçam o modelo a entender a estrutura e o sentido da linguagem.\n","\n","Essas duas tarefas são:\n","\n","1. **Masked Language Modeling (MLM)**  \n","2. **Next Sentence Prediction (NSP)**\n","\n","Vamos entender cada uma delas com muito detalhe.\n","\n","---\n","\n","## 5.2.1. Masked Language Modeling (MLM)\n","\n","O objetivo do **MLM** é ensinar o modelo a *prever palavras faltantes* (ou mascaradas) a partir do contexto.\n","\n","### Intuição\n","\n","Imagine a seguinte frase:\n","\n","> “O cachorro **[MASK]** o carteiro.”\n","\n","O modelo deve prever a palavra mais provável para **[MASK]**, considerando **todas as palavras** da sentença — tanto antes quanto depois.\n","\n","Dessa forma, o BERT aprende **representações bidirecionais**, já que olha para a esquerda e para a direita ao mesmo tempo.\n","\n","---\n","\n","### Como o processo funciona\n","\n","1. **Tokenização e inserção de tokens especiais**  \n","   O texto é dividido em *subtokens* (usando WordPiece) e recebe marcadores especiais:\n","\n","> [CLS] O cachorro [MASK] o carteiro [SEP]\n","\n","\n","2. **Escolha aleatória dos tokens a mascarar**  \n","Em cada sequência, **15% dos tokens** são selecionados para mascaramento.\n","\n","3. **Substituições aplicadas (segundo o paper original):**\n","- 80% → substituídos por `[MASK]`  \n","  > Ex: “O cachorro **[MASK]** o carteiro”\n","- 10% → substituídos por uma palavra **aleatória**  \n","  > Ex: “O cachorro **comeu** o carteiro”  \n","- 10% → **mantidos iguais**, mas ainda contam como alvos de predição  \n","  > Ex: “O cachorro **mordeu** o carteiro”\n","\n","Isso força o modelo a não se apoiar apenas no token `[MASK]` e a construir **representações contextuais robustas**.\n","\n","---\n","\n","### Exemplo Prático\n","\n","Entrada:\n","\n","> [CLS] O cachorro [MASK] o carteiro [SEP]\n","\n","Saída esperada:\n","\n","> [CLS] O cachorro mordeu o carteiro [SEP]\n","\n","Durante o treinamento, o modelo gera uma distribuição de probabilidade sobre todo o vocabulário e tenta **maximizar a probabilidade do token correto**.\n","\n","---\n","\n","### Resultado\n","\n","Ao final do pré-treino, o BERT aprende vetores de embeddings altamente contextuais:\n","- A palavra “mordeu” está associada a “cachorro” e “carteiro”.\n","- Se a mesma palavra aparecer em outro contexto (“Ele **mordeu** a língua”), o vetor muda, refletindo o novo sentido.\n","\n","---\n","\n","## 5.2.2. Next Sentence Prediction (NSP)\n","\n","Além de entender palavras, o BERT também precisa compreender **relações entre sentenças**.  \n","Essa é a função do **Next Sentence Prediction (NSP)**.\n","\n","---\n","\n","### Intuição\n","\n","O NSP ensina o modelo a entender **coerência e continuidade textual**.\n","\n","Ele recebe **dois segmentos de texto (A e B)** e precisa responder:\n","\n","> “A sentença B realmente vem depois da sentença A no texto original?”\n","\n","---\n","\n","### Como o processo funciona\n","\n","Durante o pré-treinamento:\n","\n","- 50% dos pares (A,B) são **verdadeiros** → B realmente segue A.  \n","- 50% dos pares são **falsos** → B vem de uma parte aleatória do corpus.\n","\n","O modelo deve classificar entre:\n","\n","| Rótulo | Significado | Exemplo |\n","|:-------|:-------------|:---------|\n","| `IsNext` | B segue A | A: “Ele pegou o guarda-chuva.”<br>B: “Saiu para a rua.” |\n","| `NotNext` | B é aleatória | A: “Ele pegou o guarda-chuva.”<br>B: “O bolo estava delicioso.” |\n","\n","---\n","\n","### Entrada típica do BERT para NSP\n","\n","O modelo recebe os dois segmentos concatenados, separados por tokens especiais:\n","\n","> [CLS] Ele pegou o guarda-chuva. [SEP] Saiu para a rua. [SEP]\n","\n","Além disso, ele adiciona **embeddings segmentais** (também chamados *token type embeddings*), que indicam se cada token pertence à sentença A ou B.\n","\n","| Tipo de embedding | Função |\n","|:------------------|:--------|\n","| **Token embeddings** | Representa cada palavra ou subtoken. |\n","| **Segment embeddings** | Indicam a qual sentença o token pertence (A ou B). |\n","| **Positional embeddings** | Indicam a posição de cada token na sequência. |\n","\n","O vetor final de entrada de cada token é a **soma** desses três componentes.\n","\n","---\n","\n","### Exemplo Prático\n","\n","Entrada:\n","\n","> [CLS] O cachorro latiu. [SEP] O carteiro correu. [SEP]\n","\n","Rótulo: `IsNext`\n","\n","Durante o pré-treino, o BERT aprende:\n","- Que “latiu” e “carteiro” ocorrem juntos com frequência;  \n","- Que há relação causal ou temporal entre as sentenças.\n","\n","Isso o prepara para tarefas posteriores como *Question Answering*, *Natural Language Inference* e *Paraphrase Detection*.\n","\n","---\n","\n","## Saída do Pré-Treinamento\n","\n","Durante o pré-treino, o BERT otimiza **duas funções de perda simultaneamente**:\n","\n","$$\n","\\mathcal{L} = \\mathcal{L}_{MLM} + \\mathcal{L}_{NSP}\n","$$\n","\n","- **$\\mathcal{L}_{MLM}$** → erro de predição das palavras mascaradas.  \n","- **$\\mathcal{L}_{NSP}$** → erro de classificação entre `IsNext` e `NotNext`.\n","\n","A combinação dessas perdas permite que o modelo aprenda tanto **relações locais (entre palavras)** quanto **globais (entre sentenças)**.\n","\n","---\n","\n","## Resumo Visual\n","\n","O BERT é, portanto, um **modelo de linguagem bidirecional e contextual**, treinado de forma auto-supervisionada, capaz de ser ajustado para praticamente qualquer tarefa de PLN.\n","\n","\n","<pre>\n","Entrada:\n","[CLS] A sentença A ... [SEP] sentença B ... [SEP]\n","\n","↓ Embeddings = Token + Segment + Position\n","\n","↓ Encoder do Transformer (12 camadas)\n","\n","↓\n","Saídas:\n"," - Vetores de cada token (para MLM)\n"," - Vetor [CLS] (para NSP)\n","</pre>"]},{"cell_type":"markdown","id":"5b1db883","metadata":{"id":"5b1db883"},"source":["# 5.3 Os três tipos de embeddings no BERT\n","\n","<br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/bert_embeddings.png\" width=\"50%%\">\n","\n","Fonte: Devlin et al. (2018)\n","\n","O BERT não usa apenas *word embeddings*.  \n","Cada token de entrada é representado pela **soma de três vetores** diferentes:\n","\n","$$\n","\\text{InputEmbedding}(t_i) = \\text{TokenEmb}(t_i) + \\text{SegmentEmb}(s_i) + \\text{PositionEmb}(p_i)\n","$$\n","\n","---\n","\n","## 5.3.1 Token Embeddings\n","São os embeddings “normais” de palavras, como nos modelos anteriores (Word2Vec, GloVe, etc).  \n","Cada palavra (ou subpalavra, no caso do BERT) é convertida em um vetor denso.\n","\n","Exemplo:\n","```text\n","[CLS] o filme foi ótimo [SEP]\n","```\n","\n","Os tokens podem ser:\n","```text\n","[CLS], o, fil, ##me, foi, ót, ##imo, [SEP]\n","```\n","\n","Cada um recebe um vetor aprendido — esses vetores formam a **base semântica** da frase.\n","\n","---\n","\n","## 5.3.2 Position Embeddings\n","Transformers não têm noção de ordem (eles não são recorrentes).  \n","Por isso, o BERT adiciona **positional embeddings fixos** que indicam a posição de cada token na sequência.\n","\n","Esses vetores são somados ao embedding de cada token e permitem que o modelo diferencie, por exemplo:\n","\n","```text\n","o cachorro mordeu o homem\n","o homem mordeu o cachorro\n","```\n","\n","Apesar das mesmas palavras, as posições diferentes mudam completamente o significado.\n","\n","---\n","\n","## 5.3.3 Segment (ou Sentence) Embeddings\n","\n","Durante o pré-treinamento, o BERT usa o **Next Sentence Prediction (NSP)**, que exige lidar com **pares de sentenças**.  \n","Para que o modelo saiba **qual token pertence a qual sentença**, o BERT adiciona embeddings de segmento:\n","\n","| Token | Segment Embedding |\n","|:-------|:-----------------:|\n","| `[CLS]` | A |\n","| `O` | A |\n","| `filme` | A |\n","| `foi` | A |\n","| `ótimo` | A |\n","| `[SEP]` | A |\n","| `Não` | B |\n","| `gostei` | B |\n","| `.` | B |\n","| `[SEP]` | B |\n","\n","→ Tokens da **primeira sentença** recebem `Segment A`  \n","→ Tokens da **segunda sentença** recebem `Segment B`\n","\n","Esses vetores de segmento são aprendidos junto com o resto da rede.\n","\n","---\n","\n","## 5.3.4 Combinação Final\n","Para cada token, o vetor final de entrada é a soma:\n","\n","$$\n","\\text{EmbeddingFinal}(t_i) =\n","\\text{TokenEmb}(t_i)\n","+ \\text{SegmentEmb}(s_i)\n","+ \\text{PositionEmb}(p_i)\n","$$\n","\n","\n","Essa combinação fornece ao modelo:\n","\n","- **significado** da palavra (Token),\n","- **ordem** na sequência (Position),\n","- **identificação** da sentença (Segment).\n","\n","Essa soma é o **ponto de partida do aprendizado contextual** no BERT.  \n","Os três tipos de embeddings são aprendidos (ou fixos, no caso posicional) e evoluem durante o pré-treinamento.\n","\n","---"]},{"cell_type":"markdown","id":"a14d12d7","metadata":{"id":"a14d12d7"},"source":["## 5.4 — BERT na prática: Masked Language Modeling (MLM) + Next Sentence Prediction (NSP)\n","\n","Nesta seção vamos **reproduzir em pequena escala** os objetivos de pré-treinamento do BERT usando `BertForPreTraining` (que já inclui as duas cabeças: **MLM** e **NSP**).\n","\n","### O que vamos fazer\n","\n","1. **Mini-corpus**: definimos algumas sentenças curtas (você pode substituir pelo seu conjunto).\n","2. **Pares para NSP**: criamos pares (A,B) rotulados:\n","   - `IsNext` quando B realmente segue A no texto original;\n","   - `NotNext` quando B é uma sentença aleatória.\n","3. **Tokenização**: `[CLS] A [SEP] B [SEP]`, com `token_type_ids` (A=0, B=1).\n","4. **Máscaras para MLM (80/10/10)** sobre ~15% dos tokens “previstáveis”.\n","5. **Treino curto**: otimizamos **uma única loss conjunta**:  \n","   $\\mathcal{L} = \\mathcal{L}_{MLM} + \\mathcal{L}_{NSP}$\n","6. **Inspeção de saídas**:\n","   - Top-k predições para `[MASK]`;\n","   - Probabilidades `IsNext/NotNext` do NSP para um par de teste.\n","\n","### Dicas\n","\n","- **MLM** força o BERT a aprender **contexto bidirecional** (olhando esquerda e direita).  \n","- **NSP** ensina **coerência entre sentenças** (embora trabalhos posteriores mostrem que remover NSP às vezes ajuda; aqui mantemos por fidelidade ao BERT original).  \n","- Em produção, corpora são massivos (Wikipedia + BooksCorpus). Aqui, **mini-setup** para visualização."]},{"cell_type":"code","execution_count":1,"id":"3ffd171d","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2169b309fa0b4a7ea0b2d169eca9304d","8512fe2d0390420cacc9860a34948d1f","969e02b73e28418c9e46d660932e0335","602fe170d0fa4a9e8289340d389d01be","60649f63928e40a4b4d92364744aa925","f1ad27e141a341289dd794df04f2aef8","b0ec1fc39a6a40239e859ab9f87d0535","53a6e3de432747788dbc5b6c5d47723f","32713cd38eb64597b895db034a020abd","becd85b9d0ab425883d03d128bb15730","1b501e21dade4541a8cff13d5d0d6fe4","b9f33343020549599d4dbb329ad5e26c","1df2713322fa47d5807a94337b49158e","64a04f0530a34c91b780bbd05664f041","c040ffe8cb9542b0bb3e6e835e021021","06b4567b458c4b34b0c6cf14ecd5e140","458e077f1d8d4293a6f69ba7841a69a8","f7a44c6b89d24a1ea15a66bf484deadb","7a2aca84a2f4478e8c7203a1ce8b4466","d79af1bcdb3b4d068df10fc4802b0627","9f2fb9e052d44359bb62a87f1ca5f6f8","b6fbaf4655c741cf861ff7769840986d","4434341001c74f5f980b7af282d405b7","885c4ec9ea464e1589760cb496e95365","bcf881141cd045b5b78f469894f3a993","49b33a35dbaa4d80acc8df3c9e283dc3","5ad0adf354a54c3aa37d3dc7c5ffb519","8e8ef2549b3b461f883ccfdcc1e85a4b","96e3382567704b6fb358c252be3fed07","456eaaf0079740729e22e7ee14521e52","09e7cf75322044d091f285323f73bbd3","472e7ef2a53c424aa111c6d05c5194dd","007e14a7b0484fe382ce6ea6553b33b0","55c5edfa16c04c4a98caf74c1672aa6c","39fcdc2adc974156ab9b3cf0d0b5659b","fe62a5de99e84ba488eccd06cc2d43e5","b4d4097ad5e9423b9db70cccba6abbc1","19644b37b47b4f07a6af33388066b7da","7da5c879db4145c18381605bc913ef6b","6417f89546094943b76c4928f6051dd4","d11c374301394ce9b913c2d57d850dea","2b263c6d8ec9435283999ce0a769fa3d","61e02de3deaf4b0881b293e913bf71e8","066bafd1cda54fd39d09c8b15d93cd68","1988766bcef54cbabbe03969118338a2","f55646981f254a7e9889d9f4cf6b952c","7854e03c883941ed895f3d057ae77e4a","ec4a4b4f274b46179c5755f0b6334f1f","065320bead224e0b828b63f3977832c1","90cdc87113a74f72884c662448e5bf88","69bd57449c334d12871ef164851ff772","61735386d9a54e8a99accf6822cd9527","fb6be34bbace468fbe71a00cf962a61c","36b96b84c0ea4c04bfbe00eb41f0b759","a5568ae260d74f5e89c2ba83b238d11d"]},"id":"3ffd171d","executionInfo":{"status":"ok","timestamp":1761096944201,"user_tz":240,"elapsed":49730,"user":{"displayName":"Bruno Magalhaes Nogueira","userId":"18320277366917905276"}},"outputId":"a6489dbe-a962-474c-c9c1-e5a8b0bf77cb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2169b309fa0b4a7ea0b2d169eca9304d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9f33343020549599d4dbb329ad5e26c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4434341001c74f5f980b7af282d405b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55c5edfa16c04c4a98caf74c1672aa6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1988766bcef54cbabbe03969118338a2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[epoch 1 step 020] loss=2.3180\n","[epoch 1 step 040] loss=0.7126\n","\n","=== INSPEÇÃO DE MLM (top-5 para um [MASK]) ===\n","\n","A: the cat sat on the mat.\n","B: it [MASK] out the window.\n","  posição mascarada: 9\n","  token original (se disponível): 'it'\n","   -> it           p=0.9989\n","   -> he           p=0.0002\n","   -> something    p=0.0001\n","   -> she          p=0.0001\n","   -> i            p=0.0001\n","\n","A: paris is the capital of france.\n","B: the eiffel tower is in paris.\n","  posição mascarada: 9\n","  token original (se disponível): 'the'\n","   -> the          p=1.0000\n","   -> paris        p=0.0000\n","   -> its          p=0.0000\n","   -> france       p=0.0000\n","   -> french       p=0.0000\n","\n","A: deep learning changed natural language processing.\n","B: bert learns bidirectional context.\n","  posição mascarada: 9\n","  token original (se disponível): 'bert'\n","   -> bert         p=0.9740\n","   -> modeling     p=0.0055\n","   -> apt          p=0.0034\n","   -> it           p=0.0019\n","   -> language     p=0.0014\n","\n","A: paris is the capital of france.\n","B: masked language modeling is powerful.\n","  posição mascarada: 9\n","  token original (se disponível): 'masked'\n","   -> masked       p=0.9999\n","   -> modeling     p=0.0001\n","   -> natural      p=0.0000\n","   -> mask         p=0.0000\n","   -> hidden       p=0.0000\n","\n","=== INSPEÇÃO DE NSP (probabilidades) ===\n","\n","A: the cat sat on the mat.\n","B: it [MASK] out the window.\n","  P(IsNext)=1.000  |  P(NotNext)=0.000\n","\n","A: paris is the capital of france.\n","B: the eiffel tower is in paris.\n","  P(IsNext)=1.000  |  P(NotNext)=0.000\n","\n","A: deep learning changed natural language processing.\n","B: bert learns bidirectional context.\n","  P(IsNext)=1.000  |  P(NotNext)=0.000\n","\n","A: paris is the capital of france.\n","B: masked language modeling is powerful.\n","  P(IsNext)=0.000  |  P(NotNext)=1.000\n"]}],"source":["# ===========================================\n","# BERT Pretraining Demo: MLM + NSP (didático)\n","# ===========================================\n","import math, random, torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from transformers import (\n","    BertTokenizerFast,\n","    BertForPreTraining,\n",")\n","\n","# ---------------------------\n","# 0) Setup\n","# ---------------------------\n","SEED = 7\n","random.seed(SEED); torch.manual_seed(SEED)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Device:\", device)\n","\n","# ---------------------------\n","# 1) Mini-corpus (edite à vontade)\n","#    Cada \"documento\" é uma lista de sentenças em ordem.\n","# ---------------------------\n","documents = [\n","    [\n","        \"the cat sat on the mat.\",\n","        \"it looked out the window.\",\n","        \"then it jumped down.\",\n","        \"the dog barked loudly.\"\n","    ],\n","    [\n","        \"deep learning changed natural language processing.\",\n","        \"transformers enable parallel training.\",\n","        \"bert learns bidirectional context.\",\n","        \"masked language modeling is powerful.\"\n","    ],\n","    [\n","        \"paris is the capital of france.\",\n","        \"the eiffel tower is in paris.\",\n","        \"tourists visit the louvre.\",\n","        \"french cuisine is famous.\"\n","    ],\n","]\n","\n","# ---------------------------\n","# 2) Gerar pares (A,B) para NSP\n","#    - 50% IsNext (B segue A no mesmo doc)\n","#    - 50% NotNext (B aleatória de outro lugar)\n","# ---------------------------\n","def build_nsp_pairs(docs, num_pairs=300):\n","    pairs = []\n","    for _ in range(num_pairs):\n","        doc = random.choice(docs)\n","        if len(doc) >= 2 and random.random() < 0.5:\n","            # IsNext: escolher A e B consecutivos no mesmo doc\n","            i = random.randint(0, len(doc) - 2)\n","            A, B = doc[i], doc[i+1]\n","            label = 0  # IsNext\n","        else:\n","            # NotNext: A de um doc e B aleatória de outro doc\n","            docA = random.choice(docs)\n","            A = random.choice(docA)\n","            # garanta B de outro doc para ser (em geral) NotNext\n","            docB = random.choice([d for d in docs if d is not docA])\n","            B = random.choice(docB)\n","            label = 1  # NotNext\n","        pairs.append((A, B, label))\n","    return pairs\n","\n","pairs = build_nsp_pairs(documents, num_pairs=400)\n","\n","# ---------------------------\n","# 3) Tokenizer e encoding de pares\n","# ---------------------------\n","tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n","\n","MAX_LEN = 64\n","def encode_pair(a, b):\n","    enc = tokenizer(\n","        a, b,\n","        add_special_tokens=True,\n","        max_length=MAX_LEN,\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors=\"pt\"\n","    )\n","    # enc: input_ids, token_type_ids, attention_mask\n","    return {k: v.squeeze(0) for k, v in enc.items()}\n","\n","# ---------------------------\n","# 4) MLM: selecionar posições a mascarar (15%) e aplicar 80/10/10\n","#    - ignorar especiais [CLS]/[SEP]/PAD na seleção\n","# ---------------------------\n","CLS_ID = tokenizer.cls_token_id\n","SEP_ID = tokenizer.sep_token_id\n","PAD_ID = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n","MASK_ID = tokenizer.mask_token_id\n","\n","def apply_mlm_masking(input_ids, mlm_prob=0.15):\n","    labels = input_ids.clone()\n","\n","    # candidatos \"previstáveis\" (não especiais)\n","    special_ids = {CLS_ID, SEP_ID, PAD_ID}\n","    can_mask = torch.ones_like(input_ids, dtype=torch.bool)\n","    for sid in special_ids:\n","        can_mask &= (input_ids != sid)\n","\n","    # amostra binária de quais posições mascarar\n","    probs = torch.full(input_ids.shape, mlm_prob, device=input_ids.device)\n","    mask_positions = (torch.bernoulli(probs).bool()) & can_mask\n","\n","    # 80% -> [MASK]\n","    mask80 = mask_positions & (torch.rand_like(input_ids, dtype=torch.float) < 0.8)\n","    input_ids[mask80] = MASK_ID\n","\n","    # 10% -> token aleatório\n","    # (onde foi selecionado p/ máscara mas não entrou no 80%)\n","    remaining = mask_positions & (~mask80)\n","    rand10 = remaining & (torch.rand_like(input_ids, dtype=torch.float) < 0.5)\n","    vocab_size = tokenizer.vocab_size\n","    random_tokens = torch.randint(low=0, high=vocab_size, size=input_ids.shape, device=input_ids.device)\n","    input_ids[rand10] = random_tokens[rand10]\n","\n","    # 10% -> deixam igual (implicitly: remaining & ~rand10)\n","\n","    # posições não-mascaradas não entram no loss (=-100)\n","    labels[~mask_positions] = -100\n","    return input_ids, labels, mask_positions\n","\n","# ---------------------------\n","# 5) Dataset + DataLoader\n","# ---------------------------\n","class BertPretrainDataset(Dataset):\n","    def __init__(self, pairs):\n","        self.pairs = pairs\n","    def __len__(self):\n","        return len(self.pairs)\n","    def __getitem__(self, idx):\n","        a, b, nsp_label = self.pairs[idx]\n","        enc = encode_pair(a, b)\n","        # aplica MLM no input_ids\n","        ids, labels, mask_pos = apply_mlm_masking(enc[\"input_ids\"].clone())\n","        item = {\n","            \"input_ids\": ids,\n","            \"token_type_ids\": enc[\"token_type_ids\"],\n","            \"attention_mask\": enc[\"attention_mask\"],\n","            \"labels\": labels,  # para MLM\n","            \"next_sentence_label\": torch.tensor(nsp_label, dtype=torch.long)\n","        }\n","        return item\n","\n","dataset = BertPretrainDataset(pairs)\n","split = int(0.9 * len(dataset))\n","train_ds, val_ds = torch.utils.data.random_split(dataset, [split, len(dataset)-split])\n","\n","BATCH = 8\n","train_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True)\n","val_loader   = DataLoader(val_ds,   batch_size=BATCH, shuffle=False)\n","\n","# ---------------------------\n","# 6) Modelo (MLM + NSP) e otimizador\n","# ---------------------------\n","model = BertForPreTraining.from_pretrained(\"bert-base-uncased\").to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n","\n","# ---------------------------\n","# 7) Loop de treino curto (didático)\n","# ---------------------------\n","EPOCHS = 1\n","model.train()\n","for epoch in range(1, EPOCHS+1):\n","    running = 0.0\n","    for step, batch in enumerate(train_loader, 1):\n","        batch = {k: v.to(device) for k,v in batch.items()}\n","        optimizer.zero_grad()\n","        out = model(**batch)  # loss = MLM + NSP\n","        loss = out.loss\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","        optimizer.step()\n","        running += loss.item()\n","\n","        if step % 20 == 0:\n","            print(f\"[epoch {epoch} step {step:03d}] loss={running/20:.4f}\")\n","            running = 0.0\n","\n","# ---------------------------\n","# 8) Funções de inspeção: MLM top-k e NSP probs\n","# ---------------------------\n","@torch.no_grad()\n","def inspect_mlm(tokenizer, model, a, b, topk=5):\n","    model.eval()\n","    enc = encode_pair(a, b)\n","    # força UM [MASK] manualmente para demonstrar (na primeira palavra de B se possível)\n","    ids = enc[\"input_ids\"].clone()\n","    # procurar um token \"previstável\" em B (token_type_id==1) que não seja especial\n","    ttypes = enc[\"token_type_ids\"]\n","    chosen_idx = None\n","    for i in range(ids.size(0)):\n","        if (ttypes[i] == 1) and (ids[i] not in {CLS_ID, SEP_ID, PAD_ID}):\n","            chosen_idx = i; break\n","    if chosen_idx is None:\n","        # fallback: primeiro token não-especial\n","        for i in range(ids.size(0)):\n","            if ids[i] not in {CLS_ID, SEP_ID, PAD_ID}:\n","                chosen_idx = i; break\n","    original = ids[chosen_idx].item()\n","    ids[chosen_idx] = MASK_ID\n","\n","    batch = {\n","        \"input_ids\": ids.unsqueeze(0).to(device),\n","        \"token_type_ids\": enc[\"token_type_ids\"].unsqueeze(0).to(device),\n","        \"attention_mask\": enc[\"attention_mask\"].unsqueeze(0).to(device),\n","    }\n","    out = model(**batch)\n","    logits = out.prediction_logits[0, chosen_idx]  # (V,)\n","    probs = torch.softmax(logits, dim=-1)\n","    vals, idxs = torch.topk(probs, k=topk)\n","    toks = [tokenizer.decode([i]) for i in idxs.tolist()]\n","    return {\n","        \"masked_position\": chosen_idx,\n","        \"original_token\": tokenizer.decode([original]),\n","        \"topk\": list(zip(toks, [float(v) for v in vals]))\n","    }\n","\n","@torch.no_grad()\n","def inspect_nsp(tokenizer, model, a, b):\n","    model.eval()\n","    enc = encode_pair(a, b)\n","    batch = {\n","        \"input_ids\": enc[\"input_ids\"].unsqueeze(0).to(device),\n","        \"token_type_ids\": enc[\"token_type_ids\"].unsqueeze(0).to(device),\n","        \"attention_mask\": enc[\"attention_mask\"].unsqueeze(0).to(device),\n","    }\n","    out = model(**batch)\n","    # out.seq_relationship_logits: (B, 2) -> [IsNext, NotNext]\n","    logits = out.seq_relationship_logits[0]\n","    probs = torch.softmax(logits, dim=-1)\n","    return {\"IsNext\": float(probs[0]), \"NotNext\": float(probs[1])}\n","\n","# ---------------------------\n","# 9) Testes: ver predições após o treino curto\n","# ---------------------------\n","tests = [\n","    (\"the cat sat on the mat.\", \"it [MASK] out the window.\"),\n","    (\"paris is the capital of france.\", \"the eiffel tower is in paris.\"),\n","    (\"deep learning changed natural language processing.\", \"bert learns bidirectional context.\"),\n","    (\"paris is the capital of france.\", \"masked language modeling is powerful.\"),  # NotNext provável\n","]\n","\n","print(\"\\n=== INSPEÇÃO DE MLM (top-5 para um [MASK]) ===\")\n","for a, b in tests:\n","    r = inspect_mlm(tokenizer, model, a, b, topk=5)\n","    print(f\"\\nA: {a}\\nB: {b}\")\n","    print(f\"  posição mascarada: {r['masked_position']}\")\n","    print(f\"  token original (se disponível): {r['original_token']!r}\")\n","    for tok, p in r[\"topk\"]:\n","        print(f\"   -> {tok:<12} p={p:.4f}\")\n","\n","print(\"\\n=== INSPEÇÃO DE NSP (probabilidades) ===\")\n","for a, b in tests:\n","    p = inspect_nsp(tokenizer, model, a, b)\n","    print(f\"\\nA: {a}\\nB: {b}\")\n","    print(f\"  P(IsNext)={p['IsNext']:.3f}  |  P(NotNext)={p['NotNext']:.3f}\")"]},{"cell_type":"markdown","id":"c8b7df5a","metadata":{"id":"c8b7df5a"},"source":["# 5.5 — Fine-Tuning do BERT e o papel do token `[CLS]`\n","\n","<br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/bert_ft_tasks.png\" width=\"50%%\">\n","\n","Fonte: Devlin et al. (2018)\n","\n","Após o pré-treinamento, o BERT é uma poderosa **base de conhecimento linguístico geral**, mas ainda **não sabe realizar tarefas específicas** (como classificar sentimentos ou responder perguntas).  \n","O **fine-tuning** é o processo que adapta esse conhecimento para **tarefas supervisionadas específicas**.\n","\n","---\n","\n","## Conceito de Fine-Tuning\n","\n","O *fine-tuning* consiste em:\n","\n","1. **Reaproveitar os pesos do modelo pré-treinado**, que já aprenderam relações semânticas e sintáticas da linguagem.  \n","2. **Acrescentar uma pequena camada de saída** (geralmente linear) adaptada à tarefa desejada.  \n","3. **Treinar o modelo completo novamente**, mas em um **novo conjunto de dados rotulado**, com uma **taxa de aprendizado menor** — para ajustar suavemente os pesos sem “destruir” o conhecimento linguístico aprendido.\n","\n","Essa abordagem faz parte do paradigma de **transfer learning**:\n","- o pré-treinamento fornece **conhecimento geral** sobre linguagem;\n","- o fine-tuning **especializa** esse conhecimento para um contexto ou tarefa.\n","\n","---\n","\n","## Como o Fine-Tuning é Feito\n","\n","O processo segue o mesmo pipeline básico:\n","\n","> Texto → Tokenização → Embeddings → Camadas do BERT → Saída Adaptada → Função de Perda\n","\n","Dependendo da tarefa, usamos diferentes **estruturas de saída**:\n","\n","| Tipo de Tarefa | Saída Esperada | Cabeça Adicional | Exemplo |\n","|----------------|----------------|------------------|----------|\n","| Classificação de Sentença | 1 vetor (logits) | Linear + Softmax | Análise de Sentimento |\n","| Classificação de Token | 1 vetor por token | Linear + Softmax | NER, POS Tagging |\n","| Perguntas e Respostas | Vetores de início e fim | Linear (dupla saída) | SQuAD |\n","| Similaridade entre sentenças | 2 embeddings | Camada de similaridade (cosine) | STS |\n","\n","---\n","\n","## O Papel do Token `[CLS]`\n","\n","O token especial `[CLS]` (*classification token*) é adicionado **no início de toda sequência**.  \n","Durante o pré-treinamento, ele é associado à tarefa **Next Sentence Prediction (NSP)**, ou seja, o modelo já aprendeu a representar **o significado global da sentença ou do par de sentenças** nele.\n","\n","Por isso, no *fine-tuning* para tarefas de **classificação**, usamos **somente o vetor final de `[CLS]`** como representação da entrada completa.\n","\n","### Exemplo:\n","\n","> Entrada: [CLS] O filme foi excelente ! [SEP]\n","\n","O BERT processa todos os tokens por 12 camadas de atenção.  \n","Ao final, o vetor correspondente a `[CLS]` contém uma **representação contextual global** do significado da frase.\n","\n","> Esse vetor é passado para uma **camada linear de classificação** que gera os logits finais (ex: positivo / negativo).\n","\n","Matematicamente:\n","\n","$$\n","\\text{logits} = W \\cdot h_{[CLS]} + b\n","$$\n","\n","onde:\n","- $h_{[CLS]}$ é o embedding final do token `[CLS]`;  \n","- $W$ e $b$ são parâmetros da nova camada linear.\n","\n","---\n","\n","## Fine-Tuning em Diferentes Tarefas\n","\n","### (a) Classificação de Sentenças\n","- Entrada: `[CLS] sentença [SEP]`\n","- Saída: vetor `[CLS]` → camada linear → softmax.\n","\n","### (b) Classificação de Tokens (ex: NER)\n","- Entrada: `[CLS] frase [SEP]`\n","- Saída: vetor contextual **de cada token**, passando cada um por uma camada linear.\n","\n","### (c) Perguntas e Respostas\n","- Entrada: `[CLS] pergunta [SEP] contexto [SEP]`\n","- Saída: duas camadas lineares preveem índices de início e fim no contexto.\n","\n","---\n","\n","## Treinamento Suave (Small Learning Rate)\n","\n","Durante o *fine-tuning*, usamos:\n","- **taxas de aprendizado pequenas (ex: 2e-5 a 5e-5)**;\n","- **poucas épocas (2–4)**;\n","- **batch sizes pequenos (16–32)**;\n","- **métodos de regularização leves** (como dropout).\n","\n","A ideia é **ajustar levemente** o modelo, mantendo a “gramática geral” da linguagem que o BERT já aprendeu.\n","\n","---\n","\n","## Visualização Conceitual\n","\n","<pre>\n","[Texto de Entrada] → [Tokenização]\n","          ↓\n","     [CLS]  token1  token2  ...  [SEP]\n","          ↓\n","     Embeddings + Posições\n","          ↓\n","      Camadas BERT\n","          ↓\n","      Vetor [CLS]  ← representa a sentença\n","          ↓\n","   Camada Linear (Nova)\n","          ↓\n","   Saída final (ex: sentimento positivo)\n","</pre>\n","\n","O BERT já aprendeu “como o idioma funciona”; o fine-tuning ensina “como resolver o seu problema específico”.\n","    \n","- O token [CLS] é o resumo semântico da sentença — ele condensa, em um vetor, as informações que fluíram por toda a rede de atenção.\n","    \n","- Essa adaptação é tão eficiente que, muitas vezes, basta menos de 1 hora de treino para atingir desempenho de ponta em diversas tarefas."]},{"cell_type":"markdown","id":"64620b30","metadata":{"id":"64620b30"},"source":["## Como o `[CLS]` é atualizado durante o Fine-Tuning\n","\n","O token especial `[CLS]` é adicionado **no início da sequência** de entrada:\n","\n","> [CLS] O filme foi ótimo [SEP]\n","\n","Durante o **forward pass** do BERT:\n","\n","1. Ele recebe um embedding inicial aprendido (como qualquer palavra).\n","2. Passa por todas as camadas do Transformer — o `[CLS]` “observa” todas as outras palavras via *self-attention*.\n","3. O vetor final do `[CLS]` (geralmente de 768 dimensões) é interpretado como o **resumo contextual da sentença**.\n","4. Esse vetor é então enviado a uma camada linear + *softmax* para produzir as probabilidades das classes:\n","\n","$$\n","\\hat{y} = \\text{Softmax}(W_{cls} \\cdot h_{cls} + b)\n","$$\n","\n","onde \\( h_{cls} \\) é o embedding final do `[CLS]`.\n","\n","---\n","\n","### A Função de Custo e o Gradiente\n","\n","Para uma tarefa de classificação binária, usamos a **entropia cruzada**:\n","\n","$$\n","\\mathcal{L} = - \\sum_i y_i \\log(\\hat{y}_i)\n","$$\n","\n","Durante o **backpropagation**, o gradiente da perda em relação a \\( h_{cls} \\) é:\n","\n","$$\n","\\frac{\\partial \\mathcal{L}}{\\partial h_{cls}} = W_{cls}^\\top (\\hat{y} - y)\n","$$\n","\n","Esse gradiente é propagado de volta, atualizando:\n","- o vetor `[CLS]`;\n","- as projeções da atenção e camadas feedforward;\n","- e até mesmo os embeddings iniciais.\n","\n","Assim, o `[CLS]` aprende a **codificar padrões discriminativos** úteis para a tarefa.\n","\n","---\n","\n","### Intuição\n","\n","Imagine duas frases:\n","\n","| Sentença | Rótulo |\n","|-----------|---------|\n","| “O filme foi maravilhoso!” | 1 (positivo) |\n","| “O filme foi péssimo.” | 0 (negativo) |\n","\n","Inicialmente, os vetores `[CLS]` dessas frases são aleatórios ou neutros.  \n","Após algumas iterações:\n","\n","- O `[CLS]` das frases **positivas** é “puxado” para uma região do espaço vetorial associada a altas probabilidades de classe 1.\n","- O `[CLS]` das frases **negativas** é empurrado para outra região, favorecendo a classe 0.\n","\n","O espaço vetorial se organiza assim:\n","\n","Espaço vetorial após fine-tuning\n","\n","<pre>\n","↑ Classe 1 (positivo)\n","│\n","│      o    o   o\n","│        o\n","│\n","│\n","│\n","│     x\n","│  x     x\n","└────────────────────→ Classe 0 (negativo)\n","</pre>\n","\n","\n","---\n","\n","### Exemplo Numérico Simplificado\n","\n","O exemplo abaixo mostra **como o gradiente atua no vetor `[CLS]`**.\n","\n","- h_cls = torch.tensor([0.2, 0.1, 0.4])   # embedding [CLS]\n","- W_cls = torch.tensor([[ 0.5, -0.3, 0.1],\n","- [-0.2,  0.4, 0.6]])   # pesos do classificador\n","- b = torch.tensor([0.0, 0.0])\n","\n","A saída antes do ajuste pode ser algo como:\n","\n","> tensor([0.63, 0.37])   # predição: classe 0\n","\n","Se o rótulo verdadeiro é 1, a perda:\n","\n","$$\n","L = -\\log(0.37)\n","$$\n","\n","gera um gradiente que:\n","\n","- diminui a confiança na classe 0;\n","- aumenta as direções em $ h_{cls} $ que favorecem a classe 1.\n","\n","Após algumas iterações, o vetor `[CLS]` é ajustado de modo que:\n","\n","$ Softmax(W_cls ⋅ h_cls) ≈ [0.1, 0.9] $\n","\n","---\n","\n","### Interpretação Final\n","\n","Depois do *fine-tuning*:\n","- O vetor `[CLS]` é um **resumo contextual** ajustado à tarefa.\n","- A camada linear \\( W_{cls} \\) aprende um **hiperplano de decisão** que separa `[CLS]` por classe.\n","- Por isso, podemos usar apenas os vetores `[CLS]` (sem o resto do BERT) para visualizar como o modelo organiza o espaço semântico — o que faremos a seguir com **t-SNE/UMAP**."]},{"cell_type":"code","execution_count":2,"id":"2eb51354","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2eb51354","executionInfo":{"status":"ok","timestamp":1761098037894,"user_tz":240,"elapsed":36,"user":{"displayName":"Bruno Magalhaes Nogueira","userId":"18320277366917905276"}},"outputId":"de67b153-bff5-4e5d-8e03-cf066988af6f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Probabilidades iniciais: [0.46754572 0.5324543 ]\n","Perda inicial: 0.6302582025527954\n","\n","Gradiente em relação a h_cls: tensor([ 0.3273, -0.3273, -0.2338])\n","Gradiente em relação a W_cls: tensor([[ 0.0935,  0.0468,  0.1870],\n","        [-0.0935, -0.0468, -0.1870]])\n","\n","Probabilidades após atualização: [0.37053224 0.6294677 ]\n"]}],"source":["import torch\n","import torch.nn.functional as F\n","\n","# Vetor [CLS] e pesos iniciais (3 dimensões → 2 classes)\n","h_cls = torch.tensor([0.2, 0.1, 0.4], requires_grad=True)\n","W_cls = torch.tensor([[ 0.5, -0.3, 0.1],\n","                      [-0.2,  0.4, 0.6]], requires_grad=True)\n","b = torch.tensor([0.0, 0.0], requires_grad=True)\n","\n","# Forward pass\n","logits = W_cls @ h_cls + b\n","probs = F.softmax(logits, dim=0)\n","print(\"Probabilidades iniciais:\", probs.detach().numpy())\n","\n","# Rótulo verdadeiro: classe 1 (positiva)\n","target = torch.tensor([0., 1.])\n","\n","# Perda (entropia cruzada)\n","loss = -torch.sum(target * torch.log(probs))\n","print(\"Perda inicial:\", loss.item())\n","\n","# Backprop\n","loss.backward()\n","\n","print(\"\\nGradiente em relação a h_cls:\", h_cls.grad)\n","print(\"Gradiente em relação a W_cls:\", W_cls.grad)\n","\n","# Atualiza manualmente (1 passo de SGD)\n","lr = 0.5\n","with torch.no_grad():\n","    h_cls -= lr * h_cls.grad\n","    W_cls -= lr * W_cls.grad\n","\n","logits_new = W_cls @ h_cls + b\n","probs_new = F.softmax(logits_new, dim=0)\n","print(\"\\nProbabilidades após atualização:\", probs_new.detach().numpy())"]},{"cell_type":"markdown","id":"afba8c6f","metadata":{"id":"afba8c6f"},"source":["## 5.6 — Fine-tuning do BERT na prática (Classificação de Sentenças)\n","\n","Nesta seção, vamos **ajustar** (fine-tune) um BERT pré-treinado para uma tarefa supervisionada de **classificação de sentenças** (sentimento).  \n","Usaremos o modelo `BertForSequenceClassification`, que adiciona automaticamente uma **cabeça linear** sobre o vetor do **token `[CLS]`** (na prática, o \"pooled output\" = `tanh(W * h_[CLS] + b)`).\n","\n","### Pipeline\n","\n","1. **Carregar dados** (GLUE/SST-2; se indisponível, usamos um fallback em memória).\n","2. **Tokenizar** com `BertTokenizerFast` (`[CLS] ... [SEP]` automaticamente).\n","3. **Instanciar o modelo** `BertForSequenceClassification(num_labels=2)`.\n","4. **Treinar** com `Trainer` (taxa pequena, poucas épocas).\n","5. **Avaliar** (accuracy, F1) e **inspecionar previsões**.\n","\n","> Intuição: durante o fine-tuning, o vetor contextual do `[CLS]` passa por uma camada linear + softmax.  \n","> A perda supervisionada **empurra** o embedding do `[CLS]` para organizar o espaço semântico de modo a separar as classes (positivo/negativo)."]},{"cell_type":"code","execution_count":10,"id":"0e1bc75e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":304},"id":"0e1bc75e","executionInfo":{"status":"error","timestamp":1761098403882,"user_tz":240,"elapsed":7835,"user":{"displayName":"Bruno Magalhaes Nogueira","userId":"18320277366917905276"}},"outputId":"5916b8ff-2ba4-4e02-9dc7-a2a0e73942ad"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: cuda\n"]},{"output_type":"error","ename":"ValueError","evalue":"pyarrow.lib.IpcReadOptions size changed, may indicate binary incompatibility. Expected 112 from C header, got 104 from PyObject","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-56975982.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# ---------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# import transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m from transformers import (\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mBertTokenizerFast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2315\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2347\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2343\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2344\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2346\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2347\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_datasets_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"4.2.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mReadInstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowBasedBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBuilderConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneratorBasedBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_reader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marrow_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mArrowWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptimizedTypedSequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata_files\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcurrent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthread_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/parquet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# flake8: noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_parquet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     raise ImportError(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyarrow/_parquet.pyx\u001b[0m in \u001b[0;36minit pyarrow._parquet\u001b[0;34m()\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: pyarrow.lib.IpcReadOptions size changed, may indicate binary incompatibility. Expected 112 from C header, got 104 from PyObject"]}],"source":["# ============================================================\n","# BERT Fine-tuning — Classificação (SST-2 com fallback) + SANEAMENTO ULTRARROBUSTO\n","# ============================================================\n","import os, random, math, inspect\n","import numpy as np\n","import torch\n","\n","# ---------------------------\n","# 0) Setup determinístico\n","# ---------------------------\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(\"Device:\", device)\n","\n","# ---------------------------\n","# 1) (Colab) instalar libs\n","# ---------------------------\n","try:\n","    import google.colab  # type: ignore\n","    IN_COLAB = True\n","except Exception:\n","    IN_COLAB = False\n","\n","if IN_COLAB:\n","    !pip -q install -U \"transformers>=4.39\" \"datasets>=2.14\" \"accelerate>=0.28\" \"evaluate>=0.4\"\n","\n","# ---------------------------\n","# 2) Imports principais\n","# ---------------------------\n","# import transformers\n","from transformers import (\n","    BertTokenizerFast, BertForSequenceClassification,\n","    Trainer, TrainingArguments\n",")\n","print(\"transformers:\", transformers.__version__)\n","\n","# Helper: TrainingArguments compatível\n","def build_training_arguments(**kwargs) -> TrainingArguments:\n","    sig = inspect.signature(TrainingArguments.__init__)\n","    allowed = set(sig.parameters.keys()); allowed.discard(\"self\")\n","    filtered = {k: v for k, v in kwargs.items() if k in allowed}\n","    dropped = [k for k in kwargs if k not in allowed]\n","    if dropped:\n","        print(\"[Aviso] parâmetros ignorados:\", dropped)\n","    return TrainingArguments(**filtered)\n","\n","# ---------------------------\n","# 3) Dataset: GLUE/SST-2 → fallback\n","# ---------------------------\n","USE_FALLBACK = False\n","train_texts, train_labels = [], []\n","val_texts,   val_labels   = [], []\n","\n","try:\n","    from datasets import load_dataset\n","    glue = load_dataset(\"glue\", \"sst2\")\n","    train_texts = glue[\"train\"][\"sentence\"]\n","    train_labels= glue[\"train\"][\"label\"]\n","    val_texts   = glue[\"validation\"][\"sentence\"]\n","    val_labels  = glue[\"validation\"][\"label\"]\n","    print(f\"GLUE/SST-2 carregado: train={len(train_texts)}  val={len(val_texts)}\")\n","except Exception as e:\n","    print(\"[AVISO] Falha ao carregar GLUE/SST-2:\", repr(e))\n","    USE_FALLBACK = True\n","    train_pairs = [\n","        (\"i loved the movie, it was fantastic and touching.\", 1),\n","        (\"what a terrible waste of time.\", 0),\n","        (\"an excellent script and strong performances.\", 1),\n","        (\"the film is boring and predictable.\", 0),\n","        (\"absolutely wonderful and inspiring!\", 1),\n","        (\"bad acting and poor dialogue.\", 0),\n","        (\"smart, funny, and well paced.\", 1),\n","        (\"i hated every minute of it.\", 0),\n","        (\"a delightful surprise with great music.\", 1),\n","        (\"the plot makes no sense at all.\", 0),\n","        (\"remarkably good for a low budget.\", 1),\n","        (\"painfully slow and unoriginal.\", 0),\n","    ]\n","    random.shuffle(train_pairs)\n","    train_texts = [t for t,_ in train_pairs]\n","    train_labels= [y for _,y in train_pairs]\n","    val_pairs = [\n","        (\"wonderful direction and amazing visuals.\", 1),\n","        (\"awful script and worse execution.\", 0),\n","        (\"i really enjoyed this film.\", 1),\n","        (\"it was not enjoyable at all.\", 0),\n","    ]\n","    val_texts  = [t for t,_ in val_pairs]\n","    val_labels = [y for _,y in val_pairs]\n","    print(f\"Fallback: train={len(train_texts)}  val={len(val_texts)}\")\n","\n","# ---------------------------\n","# 4) SANEAMENTO ULTRARROBUSTO\n","# ---------------------------\n","from collections.abc import Iterable\n","\n","def _is_nan(x):\n","    try:\n","        return bool(np.isnan(x))  # cobre floats numpy e python\n","    except Exception:\n","        return False\n","\n","def _to_plain_str(x):\n","    # bytes → str\n","    if isinstance(x, (bytes, bytearray)):\n","        try:\n","            x = x.decode(\"utf-8\", \"ignore\")\n","        except Exception:\n","            x = str(x)\n","    # numpy types / outros\n","    if isinstance(x, (np.generic,)):\n","        x = x.item()\n","    # dict comum com chave 'text' ou 'sentence'\n","    if isinstance(x, dict):\n","        for k in (\"text\", \"sentence\", \"content\"):\n","            if k in x and isinstance(x[k], (str, bytes, bytearray)):\n","                return _to_plain_str(x[k])\n","        # último recurso: string da representação\n","        return str(x)\n","    # número → str\n","    if isinstance(x, (int, float, np.integer, np.floating)) and not _is_nan(x):\n","        return str(x)\n","    # strings “normais”\n","    if isinstance(x, str):\n","        return x\n","    # iteráveis de strings → junta\n","    if isinstance(x, Iterable) and not isinstance(x, (str, bytes, bytearray)):\n","        # achata e junta com espaço\n","        flat = []\n","        for item in x:\n","            s = _to_plain_str(item)\n","            if s is not None and s.strip():\n","                flat.append(s.strip())\n","        return \" \".join(flat) if flat else None\n","    # fallback\n","    try:\n","        return str(x)\n","    except Exception:\n","        return None\n","\n","def clean_xy(texts, labels, max_bad_print=5, name=\"train\"):\n","    X, y = [], []\n","    bad_samples = []\n","    # Se vier numpy array / pandas Series, transforma\n","    if hasattr(texts, \"tolist\"):\n","        texts = texts.tolist()\n","    if hasattr(labels, \"tolist\"):\n","        labels = labels.tolist()\n","\n","    for t, l in zip(texts, labels):\n","        # remover None/NaN\n","        if t is None:\n","            bad_samples.append((\"None\", t)); continue\n","        if _is_nan(t):\n","            bad_samples.append((\"NaN\", t)); continue\n","\n","        s = _to_plain_str(t)\n","        if s is None:\n","            bad_samples.append((\"unconvertible\", t)); continue\n","        s = s.strip()\n","        if not s:\n","            bad_samples.append((\"empty after strip\", t)); continue\n","\n","        try:\n","            lbl = int(l)\n","        except Exception:\n","            # alguns datasets retornam np.int64 etc.\n","            try:\n","                lbl = int(np.array(l).item())\n","            except Exception:\n","                bad_samples.append((\"bad label\", (t, l))); continue\n","\n","        X.append(s); y.append(lbl)\n","\n","    if bad_samples:\n","        print(f\"[{name}] {len(bad_samples)} amostra(s) removida(s) por formato inválido.\")\n","        for i, (reason, sample) in enumerate(bad_samples[:max_bad_print], 1):\n","            print(f\"  #{i} motivo={reason}  exemplo={repr(sample)[:120]}\")\n","\n","    return X, y\n","\n","train_texts, train_labels = clean_xy(train_texts, train_labels, name=\"train\")\n","val_texts,   val_labels   = clean_xy(val_texts,   val_labels,   name=\"val\")\n","\n","print(f\"Textos saneados: train={len(train_texts)}  val={len(val_texts)}\")\n","assert len(train_texts) == len(train_labels) and len(val_texts) == len(val_labels)\n","\n","# checagem final (se ainda falhar, imprime tipos “estranhos”)\n","def _debug_types(name, xs, n=5):\n","    weird = [(i, type(x).__name__, repr(x)[:80]) for i, x in enumerate(xs) if not isinstance(x, str)]\n","    if weird:\n","        print(f\"[DEBUG] {name}: itens não-string após saneamento:\", weird[:n])\n","\n","_debug_types(\"train_texts\", train_texts)\n","_debug_types(\"val_texts\",   val_texts)\n","\n","# ---------------------------\n","# 5) Tokenizer e tokenização\n","# ---------------------------\n","MODEL_NAME = \"bert-base-uncased\"\n","tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n","MAX_LEN = 128\n","\n","def tokenize_batch(texts):\n","    # segurança extra: garante list[str]\n","    assert isinstance(texts, (list, tuple)), \"tokenize_batch espera list/tuple de strings.\"\n","    assert all(isinstance(t, str) for t in texts), \"tokenize_batch recebeu itens não-string.\"\n","    return tokenizer(\n","        texts,\n","        padding=\"max_length\",\n","        truncation=True,\n","        max_length=MAX_LEN,\n","        return_tensors=\"pt\"\n","    )\n","\n","train_enc = tokenize_batch(train_texts)\n","val_enc   = tokenize_batch(val_texts)\n","\n","# ---------------------------\n","# 6) Dataset PyTorch\n","# ---------------------------\n","class TorchTextDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels    = labels\n","    def __len__(self):\n","        return len(self.labels)\n","    def __getitem__(self, idx):\n","        item = {k: v[idx] for k, v in self.encodings.items()}\n","        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n","        return item\n","\n","train_ds = TorchTextDataset(train_enc, train_labels)\n","val_ds   = TorchTextDataset(val_enc,   val_labels)\n","\n","# ---------------------------\n","# 7) Modelo (usa pooled_output = [CLS])\n","# ---------------------------\n","num_labels = 2\n","model = BertForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=num_labels).to(device)\n","\n","# ---------------------------\n","# 8) Métricas\n","# ---------------------------\n","try:\n","    import evaluate\n","    acc_metric = evaluate.load(\"accuracy\")\n","    f1_metric  = evaluate.load(\"f1\")\n","    def compute_metrics(eval_pred):\n","        logits, labels = eval_pred\n","        preds = np.argmax(logits, axis=-1)\n","        r1 = acc_metric.compute(predictions=preds, references=labels)\n","        r2 = f1_metric.compute(predictions=preds, references=labels, average=\"weighted\")\n","        return {\"accuracy\": r1[\"accuracy\"], \"f1\": r2[\"f1\"]}\n","except Exception:\n","    def compute_metrics(eval_pred):\n","        logits, labels = eval_pred\n","        preds = np.argmax(logits, axis=-1)\n","        acc = (preds == labels).mean()\n","        return {\"accuracy\": float(acc)}\n","\n","# ---------------------------\n","# 9) Treinamento com Trainer\n","# ---------------------------\n","EPOCHS = 2 if not USE_FALLBACK else 4\n","BATCH  = 16 if not USE_FALLBACK else 8\n","\n","args = build_training_arguments(\n","    output_dir=\"bert-ft-sst2\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"no\",\n","    report_to=\"none\",\n","    learning_rate=2e-5,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=BATCH,\n","    per_device_eval_batch_size=BATCH,\n","    num_train_epochs=EPOCHS,\n","    fp16=torch.cuda.is_available(),\n","    seed=SEED,\n","    logging_steps=50,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_ds,\n","    eval_dataset=val_ds,\n","    compute_metrics=compute_metrics,\n",")\n","\n","print(\"\\n=== Iniciando fine-tuning do BERT ===\")\n","train_out = trainer.train()\n","eval_out  = trainer.evaluate()\n","print(\"\\nResultados de validação:\", eval_out)\n","\n","# ---------------------------\n","# 10) Teste prático — previsões e inspeção\n","# ---------------------------\n","def tokenize_one(text):\n","    return tokenizer(\n","        text, padding=\"max_length\", truncation=True, max_length=MAX_LEN, return_tensors=\"pt\"\n","    )\n","\n","def predict(texts):\n","    model.eval()\n","    assert isinstance(texts, (list, tuple)), \"predict espera list/tuple de strings.\"\n","    enc = tokenizer(texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\").to(device)\n","    with torch.no_grad():\n","        out = model(**enc)\n","        probs = torch.softmax(out.logits, dim=-1).cpu().numpy()\n","        preds = probs.argmax(axis=-1)\n","    return preds, probs\n","\n","samples = [\n","    \"i absolutely loved this movie!\",\n","    \"this was a complete waste of time.\",\n","    \"the performances are strong and convincing.\",\n","    \"the plot is weak and the pacing is terrible.\",\n","]\n","\n","preds, probs = predict(samples)\n","label_names = [\"negative\", \"positive\"]\n","print(\"\\n=== Amostras de previsão ===\")\n","for s, p, pr in zip(samples, preds, probs):\n","    print(f\"- {s}\\n  -> pred: {label_names[p]}  probs={pr}\")"]},{"cell_type":"code","execution_count":null,"id":"81373235","metadata":{"id":"81373235"},"outputs":[],"source":["# Para inspecionar manualmente o vetor [CLS] (pooled_output):\n","# with torch.no_grad():\n","#     enc = tokenize_one(\"a great movie.\").to(device)\n","#     outputs = model.bert(**enc, return_dict=True)\n","#     pooled = outputs.pooler_output\n","#     print(\"pooled_output shape:\", pooled.shape)"]},{"cell_type":"markdown","id":"48a9312d","metadata":{"id":"48a9312d"},"source":["# 5.7 BERT em tarefas de *Question Answering*\n","\n","No *Question Answering* (QA) — como em *SQuAD (Stanford Question Answering Dataset)* —  \n","o modelo deve **encontrar o trecho exato da resposta** dentro de um texto dado.\n","\n","---\n","\n","## Estrutura de Entrada\n","\n","O input do BERT é a **concatenação** da *pergunta* e do *contexto*:\n","\n","```text\n","[CLS] Quem descobriu o Brasil? [SEP] Pedro Álvares Cabral descobriu o Brasil em 1500. [SEP]\n","```\n","\n","- `[CLS]` → marcador de início (como sempre)  \n","- `[SEP]` → separa a pergunta do contexto  \n","- cada token (pergunta + contexto) recebe *token embeddings*, *segment embeddings* (A = pergunta, B = contexto) e *position embeddings*.\n","\n","---\n","\n","## O que o BERT aprende a prever\n","\n","O modelo de QA **não gera texto**.  \n","Ele **prediz dois índices** dentro da sequência de tokens do contexto:\n","\n","1. **Start token** → onde a resposta começa.  \n","2. **End token** → onde a resposta termina.\n","\n","Exemplo:\n","\n","```text\n","Tokens: [CLS] Quem descobriu o Brasil ? [SEP] Pedro Álvares Cabral descobriu o Brasil em 1500 . [SEP]\n","Index:   0     1     2          3      4   5    6      7       8          9  10    11   12  13   14\n","\n","Resposta correta: \"Pedro Álvares Cabral\"\n","→ start = 5, end = 8\n","```\n","\n","---\n","\n","## Saídas do modelo\n","\n","O BERT retorna **um vetor por token** (como sempre).  \n","Para QA, adicionamos **duas camadas lineares** sobre esses vetores:\n","\n","$begin:math:display$\n","\\\\begin{align}\n","\\\\text{StartLogits} &= W_{start} \\\\cdot H + b_{start} \\\\\\\\\n","\\\\text{EndLogits}   &= W_{end}   \\\\cdot H + b_{end}\n","\\\\end{align}\n","$end:math:display$\n","\n","onde $begin:math:text$ H $end:math:text$ é a matriz $begin:math:text$(n_{tokens}, d_{model})$end:math:text$ com as representações finais.\n","\n","- `start_logits`: pontua cada token como *início possível da resposta*  \n","- `end_logits`: pontua cada token como *fim possível da resposta*  \n","\n","O modelo escolhe o par `(start, end)` com a soma dos logits mais alta.\n","\n","---\n","\n","## Exemplo conceitual\n","\n","Suponha que a saída de *start_logits* e *end_logits* seja:\n","\n","| Token | Start logit | End logit |\n","|:------|-------------:|----------:|\n","| `[CLS]` | -5.3 | -5.0 |\n","| `Pedro` | **7.2** | 0.5 |\n","| `Álvares` | 5.8 | 6.1 |\n","| `Cabral` | 0.8 | **7.5** |\n","| `descobriu` | -0.4 | -2.1 |\n","\n","O melhor par `(start=Pedro, end=Cabral)` forma a resposta:\n","```\n","Pedro Álvares Cabral\n","```\n","\n","---\n","\n","## Função de custo\n","\n","Durante o treino, temos rótulos reais `start_true` e `end_true`.\n","\n","A perda é a soma das entropias cruzadas independentes:\n","\n","$begin:math:display$\n","\\\\mathcal{L} = CE(\\\\hat{y}_{start}, y_{start}) + CE(\\\\hat{y}_{end}, y_{end})\n","$end:math:display$\n","\n","Essa perda ajusta todos os vetores de saída (não só o `[CLS]`),  \n","fazendo com que as representações do início e do fim da resposta se tornem mais distintas.\n","\n","---\n","\n","## Interpretação das saídas\n","\n","No final:\n","\n","- cada token do contexto tem uma pontuação de “probabilidade de início/fim”;\n","- o `[CLS]` continua existindo (geralmente usado para *no-answer* em datasets como SQuAD 2.0);\n","- o modelo **não gera texto**, apenas **aponta spans** dentro do contexto original.\n","- o `[CLS]` é usado apenas como referência global (ou para no-answer),\n","- o foco está nas representações **token a token** do contexto,\n","- a saída são **dois vetores de logits** (start e end), que identificam o *span* da resposta."]},{"cell_type":"code","execution_count":8,"id":"802da796","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423,"referenced_widgets":["2bb58d5cf7b447e6aea0efd3ceb17cc9","e3d9b6bcac514e208a5de295459e4e82","739d793cd7ed4b7c980b4726eb586688","57a841e98b1a4b388429a8b99ef8fc13","db0067410e9b46c29d2f00e787d66586","2e8eede453074a4e9b1e3d9e34f5a13f","d42591a3531c47b28564b911a24b43b2","71dfc9da17a94c8ebb96eea243a3ffd8","e52ea32d91324cd39e5e5f3c4260b2ac","dbffa55020c9477db7492c8e5ea2c1c6","7eede9e5b914428495f56bd7f0e5d6a6","d53b10dfe3a24cab9b95b96e41671c4e","e61a3eda8913455d8c982eae4d6864bf","7d80ab8a915245b595b40b7b123798e2","1618737a92a34c5aabc7a4e865167dae","1cf90921bf0f4a09869733afba8c0f98","f663a9e56ad647569443006a07a80d89","25899c292f1f4089a6c5cef76c52031e","c6db1c0737d2479ba5fb052e5fa9c311","2ac14f1fdaf4483b9ddfa0d321f0aa53","9497e8b203254022abb8350ac26720cc","e8fd1f2cd81f49f29d6688d8076a4271","dc082d1619874edaaff5c24954fd5f4d","3031420fb5514c4ebd8c401de386403f","81e4340ba5814cc4b3c4b741ba060b7f","49b7526dc12946f4ae27ea8b0a634a47","19dadcfba05b424d9cfb53d3c4748ccd","903594938b8c4fed8424dbb6d8c8998e","d352b819c3b84d59959c3c132e10190e","4452728e4fe84954b535552f45d1500f","d3f36bb955c44b608965cec35700827b","bcbfb19589da444da5795cd81a4a31fb","ba2dc3997a9b4da3a81b3498bbb8d483","c8724a42d1f940bd877c9ba8598ff456","1199ef72f11a47f9b0b968692c117976","770d968149f04d8cb08894a3902940ec","805120224642475e890dcb05d1ad10bf","2c626019735c4d60b05cf1b60fd09879","b966dc100d974a3cb8ec91eb4675237e","5441efb3b2cc48e18fbfd7131d052cf1","4bdb81895bb3490c82be36fa2814c535","86306779935048fc9c12c747ec48b456","cac6cf22a05d4a31bfe70fa2653087e8","c4297591a4104a1189ff549c2b1fa6f0","cb983b49df994889bf4d954e68fe86d2","efcf9ebd5f054f02816b86c0da1b4609","961352789ab04706974e96cb3484e064","9af8ade79922485b80c5cabb8337c27a","86fb1a4260c24e1684684fbba9f11330","0a859f3849354a17b736e29a83d6b9de","b5908ad3733c4c82a3f9be26e1d77822","520ec4bf4e0c40aab100fe5f645d8819","f44bad4c018647f7bf13e28f63de9638","24c99c0d75784cfa8cf5599eebfb43fa","a69b279ab3294d2d91fdb49279a89516"]},"id":"802da796","executionInfo":{"status":"ok","timestamp":1761098270846,"user_tz":240,"elapsed":28567,"user":{"displayName":"Bruno Magalhaes Nogueira","userId":"18320277366917905276"}},"outputId":"e905fb9c-dc50-40f3-81be-d7c28d6a4272"},"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bb58d5cf7b447e6aea0efd3ceb17cc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d53b10dfe3a24cab9b95b96e41671c4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc082d1619874edaaff5c24954fd5f4d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8724a42d1f940bd877c9ba8598ff456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb983b49df994889bf4d954e68fe86d2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Pergunta: Who discovered Brazil?\n","Melhor resposta: 'Pedro Álvares Cabral'\n","(start=6, end=11)\n","\n","Top-5 spans mais prováveis:\n","score= 16.33 | Pedro Álvares Cabral\n","score= 10.16 | Pedro Álvares Cabral discovered Brazil in the year 1500 during a Portuguese\n","score= 10.06 | Pedro Álvares Cabral discovered Brazil in the year 1500 during a Portuguese expedition\n","score=  9.22 | Cabral\n","score=  8.54 | Pedro Álvares Cabral discovered Brazil in the year 1500\n"]}],"source":["import torch\n","import numpy as np\n","from transformers import BertTokenizerFast, BertForQuestionAnswering\n","\n","# 1) Modelo já fine-tuned em SQuAD\n","MODEL_NAME = \"bert-large-uncased-whole-word-masking-finetuned-squad\"\n","# Alternativa mais leve:\n","# MODEL_NAME = \"distilbert-base-uncased-distilled-squad\"\n","\n","tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n","model = BertForQuestionAnswering.from_pretrained(MODEL_NAME)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device).eval()\n","\n","# 2) Exemplo de pergunta e contexto\n","question = \"Who discovered Brazil?\"\n","context = (\n","    \"Pedro Álvares Cabral discovered Brazil in the year 1500 during a Portuguese expedition. \"\n","    \"He is considered one of the key figures in the Age of Discovery.\"\n",")\n","\n","# 3) Tokenização com offsets (para mapear tokens no texto original)\n","enc = tokenizer(\n","    question,\n","    context,\n","    return_tensors=\"pt\",\n","    truncation=True,\n","    max_length=384,\n","    return_offsets_mapping=True\n",")\n","enc = {k: v.to(device) for k, v in enc.items()}\n","offsets = enc[\"offset_mapping\"][0].tolist()\n","ttypes = enc[\"token_type_ids\"][0].tolist()\n","\n","# 4) Forward\n","with torch.no_grad():\n","    outputs = model(**{k: v for k, v in enc.items() if k != \"offset_mapping\"})\n","start_logits, end_logits = outputs.start_logits[0], outputs.end_logits[0]\n","\n","# 5) Filtrar apenas tokens do contexto (segment=1)\n","context_mask = torch.tensor([1 if t == 1 else 0 for t in ttypes], device=device, dtype=torch.bool)\n","start_logits = start_logits.masked_fill(~context_mask, -1e9)\n","end_logits = end_logits.masked_fill(~context_mask, -1e9)\n","\n","# 6) Selecionar melhor par (start, end)\n","best_start = torch.argmax(start_logits).item()\n","best_end = torch.argmax(end_logits).item()\n","if best_end < best_start:\n","    best_end = best_start\n","\n","# 7) Reconstruir texto a partir dos offsets\n","start_char, _ = offsets[best_start]\n","_, end_char = offsets[best_end]\n","answer = context[start_char:end_char]\n","\n","print(\"Pergunta:\", question)\n","print(\"Melhor resposta:\", repr(answer))\n","print(f\"(start={best_start}, end={best_end})\")\n","\n","# 8) Mostrar top-k spans\n","def topk_spans(start_logits, end_logits, offsets, context, k=5, max_len=30):\n","    s, e = start_logits.cpu().numpy(), end_logits.cpu().numpy()\n","    top_s, top_e = np.argsort(s)[::-1][:k*5], np.argsort(e)[::-1][:k*5]\n","    spans = []\n","    for i in top_s:\n","        for j in top_e:\n","            if j < i or (j - i + 1) > max_len:\n","                continue\n","            score = s[i] + e[j]\n","            sc, ec = offsets[i][0], offsets[j][1]\n","            spans.append((score, context[sc:ec]))\n","    spans.sort(key=lambda x: x[0], reverse=True)\n","    return spans[:k]\n","\n","print(\"\\nTop-5 spans mais prováveis:\")\n","for score, span in topk_spans(start_logits, end_logits, offsets, context):\n","    print(f\"score={score:6.2f} | {span}\")"]},{"cell_type":"markdown","id":"df9ec382","metadata":{"id":"df9ec382"},"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2169b309fa0b4a7ea0b2d169eca9304d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8512fe2d0390420cacc9860a34948d1f","IPY_MODEL_969e02b73e28418c9e46d660932e0335","IPY_MODEL_602fe170d0fa4a9e8289340d389d01be"],"layout":"IPY_MODEL_60649f63928e40a4b4d92364744aa925"}},"8512fe2d0390420cacc9860a34948d1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1ad27e141a341289dd794df04f2aef8","placeholder":"​","style":"IPY_MODEL_b0ec1fc39a6a40239e859ab9f87d0535","value":"tokenizer_config.json: 100%"}},"969e02b73e28418c9e46d660932e0335":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_53a6e3de432747788dbc5b6c5d47723f","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_32713cd38eb64597b895db034a020abd","value":48}},"602fe170d0fa4a9e8289340d389d01be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_becd85b9d0ab425883d03d128bb15730","placeholder":"​","style":"IPY_MODEL_1b501e21dade4541a8cff13d5d0d6fe4","value":" 48.0/48.0 [00:00&lt;00:00, 5.37kB/s]"}},"60649f63928e40a4b4d92364744aa925":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1ad27e141a341289dd794df04f2aef8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0ec1fc39a6a40239e859ab9f87d0535":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"53a6e3de432747788dbc5b6c5d47723f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32713cd38eb64597b895db034a020abd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"becd85b9d0ab425883d03d128bb15730":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b501e21dade4541a8cff13d5d0d6fe4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9f33343020549599d4dbb329ad5e26c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1df2713322fa47d5807a94337b49158e","IPY_MODEL_64a04f0530a34c91b780bbd05664f041","IPY_MODEL_c040ffe8cb9542b0bb3e6e835e021021"],"layout":"IPY_MODEL_06b4567b458c4b34b0c6cf14ecd5e140"}},"1df2713322fa47d5807a94337b49158e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_458e077f1d8d4293a6f69ba7841a69a8","placeholder":"​","style":"IPY_MODEL_f7a44c6b89d24a1ea15a66bf484deadb","value":"vocab.txt: 100%"}},"64a04f0530a34c91b780bbd05664f041":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a2aca84a2f4478e8c7203a1ce8b4466","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d79af1bcdb3b4d068df10fc4802b0627","value":231508}},"c040ffe8cb9542b0bb3e6e835e021021":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f2fb9e052d44359bb62a87f1ca5f6f8","placeholder":"​","style":"IPY_MODEL_b6fbaf4655c741cf861ff7769840986d","value":" 232k/232k [00:00&lt;00:00, 15.9MB/s]"}},"06b4567b458c4b34b0c6cf14ecd5e140":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"458e077f1d8d4293a6f69ba7841a69a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7a44c6b89d24a1ea15a66bf484deadb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7a2aca84a2f4478e8c7203a1ce8b4466":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d79af1bcdb3b4d068df10fc4802b0627":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9f2fb9e052d44359bb62a87f1ca5f6f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6fbaf4655c741cf861ff7769840986d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4434341001c74f5f980b7af282d405b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_885c4ec9ea464e1589760cb496e95365","IPY_MODEL_bcf881141cd045b5b78f469894f3a993","IPY_MODEL_49b33a35dbaa4d80acc8df3c9e283dc3"],"layout":"IPY_MODEL_5ad0adf354a54c3aa37d3dc7c5ffb519"}},"885c4ec9ea464e1589760cb496e95365":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e8ef2549b3b461f883ccfdcc1e85a4b","placeholder":"​","style":"IPY_MODEL_96e3382567704b6fb358c252be3fed07","value":"tokenizer.json: 100%"}},"bcf881141cd045b5b78f469894f3a993":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_456eaaf0079740729e22e7ee14521e52","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_09e7cf75322044d091f285323f73bbd3","value":466062}},"49b33a35dbaa4d80acc8df3c9e283dc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_472e7ef2a53c424aa111c6d05c5194dd","placeholder":"​","style":"IPY_MODEL_007e14a7b0484fe382ce6ea6553b33b0","value":" 466k/466k [00:00&lt;00:00, 2.00MB/s]"}},"5ad0adf354a54c3aa37d3dc7c5ffb519":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e8ef2549b3b461f883ccfdcc1e85a4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96e3382567704b6fb358c252be3fed07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"456eaaf0079740729e22e7ee14521e52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09e7cf75322044d091f285323f73bbd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"472e7ef2a53c424aa111c6d05c5194dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"007e14a7b0484fe382ce6ea6553b33b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55c5edfa16c04c4a98caf74c1672aa6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39fcdc2adc974156ab9b3cf0d0b5659b","IPY_MODEL_fe62a5de99e84ba488eccd06cc2d43e5","IPY_MODEL_b4d4097ad5e9423b9db70cccba6abbc1"],"layout":"IPY_MODEL_19644b37b47b4f07a6af33388066b7da"}},"39fcdc2adc974156ab9b3cf0d0b5659b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7da5c879db4145c18381605bc913ef6b","placeholder":"​","style":"IPY_MODEL_6417f89546094943b76c4928f6051dd4","value":"config.json: 100%"}},"fe62a5de99e84ba488eccd06cc2d43e5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d11c374301394ce9b913c2d57d850dea","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b263c6d8ec9435283999ce0a769fa3d","value":570}},"b4d4097ad5e9423b9db70cccba6abbc1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_61e02de3deaf4b0881b293e913bf71e8","placeholder":"​","style":"IPY_MODEL_066bafd1cda54fd39d09c8b15d93cd68","value":" 570/570 [00:00&lt;00:00, 49.0kB/s]"}},"19644b37b47b4f07a6af33388066b7da":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7da5c879db4145c18381605bc913ef6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6417f89546094943b76c4928f6051dd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d11c374301394ce9b913c2d57d850dea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b263c6d8ec9435283999ce0a769fa3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"61e02de3deaf4b0881b293e913bf71e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"066bafd1cda54fd39d09c8b15d93cd68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1988766bcef54cbabbe03969118338a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f55646981f254a7e9889d9f4cf6b952c","IPY_MODEL_7854e03c883941ed895f3d057ae77e4a","IPY_MODEL_ec4a4b4f274b46179c5755f0b6334f1f"],"layout":"IPY_MODEL_065320bead224e0b828b63f3977832c1"}},"f55646981f254a7e9889d9f4cf6b952c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90cdc87113a74f72884c662448e5bf88","placeholder":"​","style":"IPY_MODEL_69bd57449c334d12871ef164851ff772","value":"model.safetensors: 100%"}},"7854e03c883941ed895f3d057ae77e4a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_61735386d9a54e8a99accf6822cd9527","max":440449768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fb6be34bbace468fbe71a00cf962a61c","value":440449768}},"ec4a4b4f274b46179c5755f0b6334f1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_36b96b84c0ea4c04bfbe00eb41f0b759","placeholder":"​","style":"IPY_MODEL_a5568ae260d74f5e89c2ba83b238d11d","value":" 440M/440M [00:18&lt;00:00, 23.5MB/s]"}},"065320bead224e0b828b63f3977832c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90cdc87113a74f72884c662448e5bf88":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69bd57449c334d12871ef164851ff772":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"61735386d9a54e8a99accf6822cd9527":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb6be34bbace468fbe71a00cf962a61c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"36b96b84c0ea4c04bfbe00eb41f0b759":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5568ae260d74f5e89c2ba83b238d11d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bb58d5cf7b447e6aea0efd3ceb17cc9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3d9b6bcac514e208a5de295459e4e82","IPY_MODEL_739d793cd7ed4b7c980b4726eb586688","IPY_MODEL_57a841e98b1a4b388429a8b99ef8fc13"],"layout":"IPY_MODEL_db0067410e9b46c29d2f00e787d66586"}},"e3d9b6bcac514e208a5de295459e4e82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e8eede453074a4e9b1e3d9e34f5a13f","placeholder":"​","style":"IPY_MODEL_d42591a3531c47b28564b911a24b43b2","value":"tokenizer_config.json: 100%"}},"739d793cd7ed4b7c980b4726eb586688":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_71dfc9da17a94c8ebb96eea243a3ffd8","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e52ea32d91324cd39e5e5f3c4260b2ac","value":48}},"57a841e98b1a4b388429a8b99ef8fc13":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dbffa55020c9477db7492c8e5ea2c1c6","placeholder":"​","style":"IPY_MODEL_7eede9e5b914428495f56bd7f0e5d6a6","value":" 48.0/48.0 [00:00&lt;00:00, 5.23kB/s]"}},"db0067410e9b46c29d2f00e787d66586":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e8eede453074a4e9b1e3d9e34f5a13f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d42591a3531c47b28564b911a24b43b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71dfc9da17a94c8ebb96eea243a3ffd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e52ea32d91324cd39e5e5f3c4260b2ac":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dbffa55020c9477db7492c8e5ea2c1c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eede9e5b914428495f56bd7f0e5d6a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d53b10dfe3a24cab9b95b96e41671c4e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e61a3eda8913455d8c982eae4d6864bf","IPY_MODEL_7d80ab8a915245b595b40b7b123798e2","IPY_MODEL_1618737a92a34c5aabc7a4e865167dae"],"layout":"IPY_MODEL_1cf90921bf0f4a09869733afba8c0f98"}},"e61a3eda8913455d8c982eae4d6864bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f663a9e56ad647569443006a07a80d89","placeholder":"​","style":"IPY_MODEL_25899c292f1f4089a6c5cef76c52031e","value":"vocab.txt: 100%"}},"7d80ab8a915245b595b40b7b123798e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6db1c0737d2479ba5fb052e5fa9c311","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ac14f1fdaf4483b9ddfa0d321f0aa53","value":231508}},"1618737a92a34c5aabc7a4e865167dae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9497e8b203254022abb8350ac26720cc","placeholder":"​","style":"IPY_MODEL_e8fd1f2cd81f49f29d6688d8076a4271","value":" 232k/232k [00:00&lt;00:00, 17.1MB/s]"}},"1cf90921bf0f4a09869733afba8c0f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f663a9e56ad647569443006a07a80d89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25899c292f1f4089a6c5cef76c52031e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6db1c0737d2479ba5fb052e5fa9c311":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ac14f1fdaf4483b9ddfa0d321f0aa53":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9497e8b203254022abb8350ac26720cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e8fd1f2cd81f49f29d6688d8076a4271":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc082d1619874edaaff5c24954fd5f4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3031420fb5514c4ebd8c401de386403f","IPY_MODEL_81e4340ba5814cc4b3c4b741ba060b7f","IPY_MODEL_49b7526dc12946f4ae27ea8b0a634a47"],"layout":"IPY_MODEL_19dadcfba05b424d9cfb53d3c4748ccd"}},"3031420fb5514c4ebd8c401de386403f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_903594938b8c4fed8424dbb6d8c8998e","placeholder":"​","style":"IPY_MODEL_d352b819c3b84d59959c3c132e10190e","value":"tokenizer.json: 100%"}},"81e4340ba5814cc4b3c4b741ba060b7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4452728e4fe84954b535552f45d1500f","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d3f36bb955c44b608965cec35700827b","value":466062}},"49b7526dc12946f4ae27ea8b0a634a47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcbfb19589da444da5795cd81a4a31fb","placeholder":"​","style":"IPY_MODEL_ba2dc3997a9b4da3a81b3498bbb8d483","value":" 466k/466k [00:00&lt;00:00, 43.3MB/s]"}},"19dadcfba05b424d9cfb53d3c4748ccd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"903594938b8c4fed8424dbb6d8c8998e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d352b819c3b84d59959c3c132e10190e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4452728e4fe84954b535552f45d1500f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3f36bb955c44b608965cec35700827b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bcbfb19589da444da5795cd81a4a31fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba2dc3997a9b4da3a81b3498bbb8d483":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8724a42d1f940bd877c9ba8598ff456":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1199ef72f11a47f9b0b968692c117976","IPY_MODEL_770d968149f04d8cb08894a3902940ec","IPY_MODEL_805120224642475e890dcb05d1ad10bf"],"layout":"IPY_MODEL_2c626019735c4d60b05cf1b60fd09879"}},"1199ef72f11a47f9b0b968692c117976":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b966dc100d974a3cb8ec91eb4675237e","placeholder":"​","style":"IPY_MODEL_5441efb3b2cc48e18fbfd7131d052cf1","value":"config.json: 100%"}},"770d968149f04d8cb08894a3902940ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bdb81895bb3490c82be36fa2814c535","max":443,"min":0,"orientation":"horizontal","style":"IPY_MODEL_86306779935048fc9c12c747ec48b456","value":443}},"805120224642475e890dcb05d1ad10bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cac6cf22a05d4a31bfe70fa2653087e8","placeholder":"​","style":"IPY_MODEL_c4297591a4104a1189ff549c2b1fa6f0","value":" 443/443 [00:00&lt;00:00, 34.1kB/s]"}},"2c626019735c4d60b05cf1b60fd09879":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b966dc100d974a3cb8ec91eb4675237e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5441efb3b2cc48e18fbfd7131d052cf1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bdb81895bb3490c82be36fa2814c535":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86306779935048fc9c12c747ec48b456":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cac6cf22a05d4a31bfe70fa2653087e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4297591a4104a1189ff549c2b1fa6f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb983b49df994889bf4d954e68fe86d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_efcf9ebd5f054f02816b86c0da1b4609","IPY_MODEL_961352789ab04706974e96cb3484e064","IPY_MODEL_9af8ade79922485b80c5cabb8337c27a"],"layout":"IPY_MODEL_86fb1a4260c24e1684684fbba9f11330"}},"efcf9ebd5f054f02816b86c0da1b4609":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a859f3849354a17b736e29a83d6b9de","placeholder":"​","style":"IPY_MODEL_b5908ad3733c4c82a3f9be26e1d77822","value":"model.safetensors: 100%"}},"961352789ab04706974e96cb3484e064":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_520ec4bf4e0c40aab100fe5f645d8819","max":1340622760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f44bad4c018647f7bf13e28f63de9638","value":1340622760}},"9af8ade79922485b80c5cabb8337c27a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_24c99c0d75784cfa8cf5599eebfb43fa","placeholder":"​","style":"IPY_MODEL_a69b279ab3294d2d91fdb49279a89516","value":" 1.34G/1.34G [00:23&lt;00:00, 66.7MB/s]"}},"86fb1a4260c24e1684684fbba9f11330":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0a859f3849354a17b736e29a83d6b9de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5908ad3733c4c82a3f9be26e1d77822":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"520ec4bf4e0c40aab100fe5f645d8819":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f44bad4c018647f7bf13e28f63de9638":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"24c99c0d75784cfa8cf5599eebfb43fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a69b279ab3294d2d91fdb49279a89516":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}