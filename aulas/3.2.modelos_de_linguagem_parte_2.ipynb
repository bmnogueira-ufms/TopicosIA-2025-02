{"cells":[{"cell_type":"markdown","id":"2fd7bd04","metadata":{"id":"2fd7bd04"},"source":["\n","# Modelos de Linguagem — **Parte 2**  \n","## Encoder–Decoder, Atenção e Fundamentos de Transformers\n","\n","### Objetivos\n","- Entender **por que** RNN/LSTM têm limitações e como a **Atenção** resolve isso.\n","- Implementar **atenção escalada** com NumPy e **interpretar** seus pesos.\n","- Diferenciar **self-attention**, **masked attention** (causal) e **encoder–decoder attention**.\n","- Compreender **Positional Encoding**, **Multi-Head Attention**, **FFN**, **LayerNorm** e **residuais**.\n","- Conectar esses blocos aos **objetivos de pré-treino** (MLM, CLM, Denoising) e às **arquiteturas** (BERT, GPT, T5).\n"]},{"cell_type":"markdown","id":"c8f6a938","metadata":{"id":"c8f6a938"},"source":["\n","## 1) Recapitulando RNN/LSTM e motivando a Atenção\n","\n","**RNN** processa token por token propagando um estado oculto. **LSTM** adiciona portas para reter/descartar informação.  \n","**Limitações que motivam a Atenção:**\n","1. **Dependências longas**: difícil associar tokens distantes.  \n","2. **Baixo paralelismo**: processamento sequencial (treino lento).  \n","3. **Gargalo de contexto** no seq2seq clássico: um **único vetor** resumindo toda a entrada.\n","\n","**Ideia-chave da Atenção**: em vez de depender de um único vetor ou de passos sequenciais, permita que cada posição **“olhe” diretamente** para **todas** as outras posições relevantes.\n"]},{"cell_type":"markdown","id":"01038753","metadata":{"id":"01038753"},"source":["\n","## 2) Encoder–Decoder clássico (com RNNs) — onde dói?\n","\n","<br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/encoder_decoder_2.png\" width=\"50%\">\n","\n","- **Encoder** lê a sequência de entrada e gera um **vetor de contexto** (estado final).  \n","- **Decoder** usa aquele vetor para gerar a saída, **um token por vez** (teacher forcing no treino, autoregressivo na inferência).\n","\n","**Dor**: o vetor de contexto **condensa tudo**; em frases longas, perde detalhes.  \n","**Solução histórica**: **Atenção** (Bahdanau/Luong) — o decoder pondera **diferentes partes do encoder** a cada passo.\n"]},{"cell_type":"markdown","id":"e41502fa","metadata":{"id":"e41502fa"},"source":["\n","## 3) Intuição da Atenção (ex.: tradução)\n","\n","Entrada (en): *\"The book is on the table\"*  \n","Saída (pt): *\"O livro está sobre a mesa\"*\n","\n","Ao gerar **\"mesa\"**, queremos **focar** em **\"table\"**, não tanto em **\"book\"**.  \n","A Atenção cria **pesos** que dizem **quanto** cada posição da entrada é relevante para a posição atual da saída.\n"]},{"cell_type":"markdown","id":"9185202d","metadata":{"id":"9185202d"},"source":["## 4) Da limitação do vetor fixo → à Atenção\n","\n","Até aqui vimos que:\n","- No **encoder–decoder clássico com RNN/LSTM**, toda a frase de entrada era “espremida” em um **único vetor de contexto**.\n","- Esse vetor servia como base para o decoder gerar **cada token da saída**.\n","- Problema: em frases longas, esse **resumo único** perde informação → o modelo esquece detalhes.\n","\n","### Ideia da Atenção\n","Em vez de confiar apenas em um vetor fixo, vamos permitir que o decoder, a cada passo, **escolha em quais partes da entrada prestar atenção**.  \n","Assim, a representação da saída em `t` não vem só de um vetor fixo, mas de uma **combinação ponderada** de todos os estados do encoder.\n","\n","### Como formalizamos isso?\n","1. Cada **palavra da entrada** gera três vetores diferentes:\n","   - **Query (Q)**: “o que estou procurando agora?”\n","   - **Key (K)**: “como posso ser encontrado?”\n","   - **Value (V)**: “qual informação entrego se for relevante?”\n","\n","   > Esses vetores são obtidos a partir dos embeddings, multiplicados por **matrizes de peso** aprendidas:  \n","   > `Q = X · W^Q`, `K = X · W^K`, `V = X · W^V`.\n","\n","2. Para cada **token alvo (query)**, calculamos sua **similaridade** com todos os **tokens fonte (keys)**:  \n","   - Produto escalar `Q · K^T` → mede quão forte é a correspondência entre consulta e chave.\n","\n","3. Normalizamos esses scores com **softmax** → viram probabilidades (somam 1).  \n","   - Se “mesa” busca correspondências, o softmax pode dar peso maior para “table” e menor para “book”.\n","\n","4. Finalmente, usamos esses pesos para **combinar os valores (V)** correspondentes → obtendo uma nova representação **contextualizada**.\n","\n","### Fórmula completa\n","$$\n","\\mathrm{Attention}(Q,K,V) = \\mathrm{softmax}\\!\\left(\\frac{QK^\\top}{\\sqrt{d_k}}\\right)V\n","$$\n","\n","- O termo $\\frac{1}{\\sqrt{d_k}}$ evita que os scores fiquem grandes demais em dimensões altas.\n","- Cada linha do softmax representa **como um token distribui sua atenção pelos outros**.\n","\n","### Exemplo\n","Frase de entrada: *“O livro está na mesa”*  \n","- Quando o decoder gera “table” → query se conecta fortemente à key de “mesa”.  \n","- O valor correspondente traz a informação semântica de “mesa”.  \n","- Assim, o modelo não depende mais de um único vetor: ele pode **puxar dinamicamente** a informação relevante de onde precisar.\n","\n","Esse é o núcleo da atenção: **aprender a focar nas partes certas da entrada, dinamicamente, a cada passo**.\n"]},{"cell_type":"markdown","id":"2952e6b3","metadata":{"id":"2952e6b3"},"source":["## Ok... Vamos com calma: Query, Key e Value em Mecanismos de Atenção\n","\n","### De onde vem a ideia?\n","O mecanismo de atenção foi criado para resolver um problema clássico em redes neurais para sequência (como RNNs e LSTMs):  \n","quando o texto é longo, o modelo tem dificuldade de **“lembrar”** o que veio antes.  \n","\n","A ideia da atenção é permitir que, em cada passo da geração, o modelo **olhe de volta** para toda a sequência de entrada e **decida o que é mais relevante** para o próximo passo.\n","\n","---\n","\n","### Intuição: perguntas e respostas\n","Imagine que você está traduzindo uma frase do inglês para o português.  \n","Quando chega no momento de traduzir a palavra **“bank”**, você precisa saber se “bank” é **banco de sentar** ou **banco financeiro**.  \n","\n","- Você olha para o resto da frase e pergunta: *“De que tipo de ‘bank’ estamos falando?”*  \n","- Para responder, você precisa ver o **contexto** das outras palavras.  \n","\n","É exatamente esse processo que o mecanismo de atenção formaliza, usando **Query, Key e Value**.\n","\n","---\n","\n","### O que são Query, Key e Value?\n","\n","> Intuição rápida: **Q** é a *pergunta* que uma posição faz ao contexto; **K** são *etiquetas/endereços* que cada posição oferece para ser encontrada; **V** é o *conteúdo* que será entregue se aquela posição for considerada relevante.\n","\n","São apenas **representações vetoriais** (obtidas por multiplicações de matrizes aprendidas) que assumem papéis diferentes:\n","\n","- **Query (Q)** → é a **pergunta** que a palavra atual está fazendo.  \n","  > Ex.: a palavra “bank” pergunta: “qual o meu sentido aqui?”\n","\n","- **Key (K)** → é a **etiqueta** que cada palavra da frase carrega, dizendo em que contextos ela pode ser relevante.  \n","  > Ex.: a palavra “money” carrega uma “chave” que sinaliza relação com contexto financeiro.\n","\n","- **Value (V)** → é a **informação de conteúdo** que pode ser usada se aquela palavra for escolhida como relevante.  \n","  > Ex.: a palavra “money” traz consigo um valor que descreve seu significado numérico/financeiro.\n","\n","---\n","\n","### Como funciona a mecânica?\n","1. Cada palavra é transformada em três vetores (Q, K, V) usando matrizes diferentes treináveis.  \n","   - Então, uma mesma palavra tem representações distintas dependendo do papel que está cumprindo.\n","\n","2. Para calcular **atenção**, o modelo:\n","   - Compara a **Query** da palavra-alvo com todas as **Keys** → isso gera um *score* de relevância.\n","   - Normaliza esses *scores* com **softmax** (para virarem pesos).\n","   - Usa esses pesos para combinar os **Values** → formando um vetor de contexto para a palavra-alvo.\n","\n","---\n","\n","### Exemplo simplificado\n","Frase: *“I went to the bank to deposit money”*  \n","\n","- Para a palavra **“bank”**:  \n","  - **Query** pergunta → “o que significa bank aqui?”.  \n","  - **Keys** das outras palavras:\n","    - “to” → chave de preposição, pouca ajuda.  \n","    - “deposit” → chave que indica ação financeira.  \n","    - “money” → chave que indica contexto monetário.  \n","  - O *score* de atenção será alto para “deposit” e “money”.  \n","\n","Assim, o **Value** dessas palavras pesa mais na construção do significado de “bank” → e o modelo entende que “bank” aqui é **banco financeiro**.\n","\n","---\n","\n","### Resumindo\n","- **Query**: pergunta da palavra atual.  \n","- **Key**: etiqueta de cada palavra que indica em quais contextos ela é relevante.  \n","- **Value**: informação que pode ser usada se a palavra for escolhida.  \n","- O mecanismo de atenção **casa Queries com Keys** para decidir quais Values importar."]},{"cell_type":"markdown","id":"e988758e","metadata":{"id":"e988758e"},"source":["## Query (Q), Key (K) e Value (V) — explicação detalhada\n","\n","---\n","\n","### De onde surgem Q, K e V?\n","\n","Dado um embedding por posição na sequência (matriz **X**), o Transformer aprende **três projeções lineares** diferentes:\n","\n","$$\n","Q = X W_Q,\\qquad K = X W_K,\\qquad V = X W_V\n","$$\n","\n","- $X \\in \\mathbb{R}^{L \\times d_{\\text{model}}}$ (L = comprimento da sequência)\n","- $W_Q, W_K \\in \\mathbb{R}^{d_{\\text{model}} \\times d_k}$, $W_V \\in \\mathbb{R}^{d_{\\text{model}} \\times d_v}$\n","- Resulta em $Q, K \\in \\mathbb{R}^{L \\times d_k}$ e $V \\in \\mathbb{R}^{L \\times d_v}$\n","\n","<br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/self-attention-matrix-calculation.png\" width=\"50%\">\n","\n","Fonte: https://jalammar.github.io/illustrated-transformer/\n","\n","> Por que **três** projeções?  \n","> Para **separar papéis**: “endereçar/buscar” (Q, K) e “transportar conteúdo” (V). O modelo pode aprender um *espaço de busca* (Q/K) diferente do *espaço de conteúdo* (V).\n","\n","---\n","\n","### O papel específico de cada um\n","\n","#### Query (Q) — *a pergunta da posição atual*\n","- Representa **o que essa posição precisa do contexto**.\n","- É comparada **contra todas as Keys** para descobrir onde há informação útil.\n","- Mental model: “estou na palavra *bank*; minha Query pergunta ‘qual o meu sentido aqui?’”.\n","\n","#### Key (K) — *a etiqueta/assinatura de cada posição*\n","- Descreve **em quais perguntas** essa posição deve ser considerada.\n","- Funciona como **endereço** para ser *match* com Queries.\n","- Mental model: a palavra *money* carrega uma Key com “cheiro” de finanças.\n","\n","#### Value (V) — *o conteúdo a ser entregue*\n","- É **a informação que realmente será combinada** para formar o contexto final.\n","- Se uma Key tem alto *match* com a Query, **o Value correspondente** entra com peso maior na composição.\n","- Mental model: o Value de *money* contém o conteúdo semântico “financeiro” útil para desambiguar *bank*.\n","\n","<br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/self_attention.png\" width=\"50%\">\n","\n","Fonte: https://jalammar.github.io/illustrated-transformer/\n","\n","---\n","\n","### Como Q, K e V interagem (o “cálculo da atenção”)\n","\n","1. **Similaridade** (relevância) entre cada Query e todas as Keys:\n","   $$\n","   S = \\frac{QK^\\top}{\\sqrt{d_k}}\n","   $$\n","   A divisão por $\\sqrt{d_k}$ estabiliza a escala dos *scores*, evitando *softmax* saturado e gradientes ruins.\n","\n","   <br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/self_attention_score.png\" width=\"50%\">\n","\n","Fonte: https://jalammar.github.io/illustrated-transformer/\n","\n","\n","2. **Normalização** para virar pesos de atenção:\n","   $$\n","   A = \\mathrm{softmax}(S)\\quad \\text{(por linha)}\n","   $$\n","  \n","  <br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/self-attention_softmax.png\" width=\"50%\">\n","\n","Fonte: https://jalammar.github.io/illustrated-transformer/\n","\n","3. **Combinação de conteúdos** (aplica pesos nos Values):\n","   $$\n","   \\text{Contexto} = A\\,V\n","   $$\n","\n","   <br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/self-attention-matrix-calculation-2.png\" width=\"50%\">\n","\n","Fonte: https://jalammar.github.io/illustrated-transformer/\n","\n","> Resultado: cada posição recebe um **vetor de contexto** que é uma **soma ponderada dos Values**, onde os pesos vêm de quanto sua Query combinou com as Keys alheias.\n","   <br/>\n","<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/self-attention-output.png\" width=\"50%\">\n","\n","Fonte: https://jalammar.github.io/illustrated-transformer/\n","\n","---\n","\n","### Onde Q/K/V são obtidos (autoatenção vs. atenção cruzada)\n","\n","- **Self-attention (autoatenção)**: Q, K e V são **derivados da mesma sequência** (mesmo $X$).  \n","  → Cada posição olha para **todas** as posições (às vezes com máscara causal).\n","\n","- **Cross-attention (encoder–decoder)**:  \n","  **Q** vem do **decoder**, enquanto **K** e **V** vêm do **encoder**.  \n","  → As Queries do que está sendo gerado consultam as Keys/Values da entrada codificada.\n","\n","---\n","\n","### Multi-head (por que várias cópias de Q/K/V?)\n","\n","Em atenção multi-cabeças, o modelo cria **múltiplos conjuntos** $(W_Q^{(h)}, W_K^{(h)}, W_V^{(h)})$ para cabeças $h=1..H$.  \n","Cada cabeça aprende:\n","- um **espaço de busca** (Q/K) próprio,\n","- e um **espaço de conteúdo** (V) próprio,\n","\n","permitindo capturar **relações complementares** (sintaxe, dependências longas, co-referência, etc.).  \n","As saídas das cabeças são **concatenadas** e projetadas novamente.\n","\n","---\n","\n","### Por que separar **Key** e **Value**?\n","\n","- **Desacoplamento “endereço vs. conteúdo”**:  \n","  é útil “localizar” itens (via Q↔K) num espaço e “transportar” informação (V) em outro.\n","- **Flexibilidade**: o que torna um token **relevante** nem sempre é o mesmo que deve ser **copiado/transportado**.  \n","  (Ex.: uma palavra pode ser um ótimo *indicador* de contexto, mas o conteúdo a combinar vem de outra distribuição semântica.)\n","\n","---\n","\n","### Dimensões e máscaras\n","\n","- Em lote e multi-head, formas comuns:\n","  - $Q, K, V \\in \\mathbb{R}^{B \\times H \\times L \\times d_k}$ (ou $d_v$ para V)\n","- **Máscaras** entram somando-se a $S$ antes do softmax:\n","  - **Padding mask**: ignora *pads*.  \n","  - **Causal mask** (no decoder): impede “olhar para o futuro”.\n","\n","---\n","\n","### Resumo\n","- **Q**: descreve *o que* a posição quer do contexto (**pergunta**).  \n","- **K**: descreve *quando/para quem* uma posição deve ser considerada (**endereço**).  \n","- **V**: fornece *o que será entregue* se aquela posição for escolhida (**conteúdo**).  \n","- **Atenção**: usa Q↔K para gerar pesos e **mistura V** conforme a relevância."]},{"cell_type":"code","execution_count":1,"id":"67cfa803","metadata":{"id":"67cfa803","outputId":"91684579-62be-4ce0-bc03-f38e3f057de0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758245645368,"user_tz":240,"elapsed":20,"user":{"displayName":"Bruno Magalhaes Nogueira","userId":"18320277366917905276"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["X shape: (1, 4, 6) \n","X =\n"," [[[-1.09  1.    0.28 -1.51 -0.58  1.65]\n","  [-2.43 -0.43  1.27 -0.87 -0.68 -0.09]\n","  [ 1.49 -0.64 -0.44 -0.43  2.21  2.19]\n","  [ 1.    0.39  0.74  1.49 -0.94  1.18]]]\n","\n","Q shape: (1, 4, 6) \n","Q =\n"," [[[ 1.17 -2.3  -1.31  4.44 -1.29  1.89]\n","  [ 2.82  1.52 -2.07  4.69 -4.49  0.06]\n","  [ 0.7   7.58  1.83 -0.27  5.66 -0.01]\n","  [-2.82 -1.22  2.34  1.53  3.32  0.42]]]\n","\n","K shape: (1, 4, 6) \n","K =\n"," [[[ 4.56 -0.43 -3.31  5.63 -5.47 -1.37]\n","  [ 4.16 -0.96 -3.55  5.78 -7.   -2.68]\n","  [ 0.5  -2.69  0.4  -2.36  5.15  4.06]\n","  [ 0.5  -2.99  1.05  1.02  1.41  2.66]]]\n","\n","V shape: (1, 4, 6) \n","V =\n"," [[[ 1.98  4.35  2.22 -0.07 -6.27  1.85]\n","  [ 2.1   0.23 -0.39  2.31 -5.28  8.29]\n","  [-1.53 -3.22  2.65 -0.56  1.69 -4.11]\n","  [ 2.24 -0.01 -1.55 -1.31  0.39 -6.4 ]]]\n","\n","Pesos de atenção (att) shape: (1, 4, 4) \n","att =\n"," [[[0.38 0.62 0.   0.  ]\n","  [0.08 0.92 0.   0.  ]\n","  [0.   0.   1.   0.  ]\n","  [0.   0.   0.92 0.08]]]\n","\n","Saída (out) shape: (1, 4, 6) \n","out =\n"," [[[ 2.05  1.78  0.59  1.41 -5.65  5.86]\n","  [ 2.09  0.55 -0.19  2.12 -5.36  7.79]\n","  [-1.53 -3.22  2.65 -0.56  1.69 -4.11]\n","  [-1.22 -2.96  2.31 -0.62  1.58 -4.3 ]]]\n"]}],"source":["\n","import numpy as np\n","\n","def softmax(x, axis=-1):\n","    \"\"\"Softmax estável numericamente.\"\"\"\n","    x = x - np.max(x, axis=axis, keepdims=True)\n","    e = np.exp(x)\n","    return e / np.sum(e, axis=axis, keepdims=True)\n","\n","def scaled_dot_product_attention(Q, K, V, mask=None):\n","    \"\"\"Implementação didática da atenção escalada por produto escalar.\n","\n","    Q: (B, Tq, d_k)\n","    K: (B, Tk, d_k)\n","    V: (B, Tk, d_v)\n","    mask: (B, Tq, Tk) booleana (True = posição mascarada)\n","    \"\"\"\n","    d_k = Q.shape[-1]\n","    scores = Q @ K.transpose(0, 2, 1) / np.sqrt(d_k)  # (B, Tq, Tk)\n","    if mask is not None:\n","        # coloca -inf (aprox -1e9) nas posições inválidas\n","        scores = np.where(mask, -1e9, scores)\n","    weights = softmax(scores, axis=-1)                # (B, Tq, Tk)\n","    return weights @ V, weights                       # saída: (B, Tq, d_v), pesos: (B, Tq, Tk)\n","\n","# Demonstração mínima\n","np.random.seed(123)\n","B, T, d = 1, 4, 6\n","X = np.round(np.random.randn(B, T, d), 2)  # \"embeddings\" de exemplo\n","\n","# Projeções lineares para Q, K, V (didático; pesos aleatórios fixos)\n","Wq = np.round(np.random.randn(d, d), 2)\n","Wk = np.round(np.random.randn(d, d), 2)\n","Wv = np.round(np.random.randn(d, d), 2)\n","\n","Q = np.round(X @ Wq, 2)\n","K = np.round(X @ Wk, 2)\n","V = np.round(X @ Wv, 2)\n","\n","print(\"X shape:\", X.shape, \"\\nX =\\n\", X)\n","print(\"\\nQ shape:\", Q.shape, \"\\nQ =\\n\", Q)\n","print(\"\\nK shape:\", K.shape, \"\\nK =\\n\", K)\n","print(\"\\nV shape:\", V.shape, \"\\nV =\\n\", V)\n","\n","out, att = scaled_dot_product_attention(Q, K, V, mask=None)\n","print(\"\\nPesos de atenção (att) shape:\", att.shape, \"\\natt =\\n\", np.round(att, 2))\n","print(\"\\nSaída (out) shape:\", out.shape, \"\\nout =\\n\", np.round(out, 2))\n"]},{"cell_type":"code","execution_count":8,"id":"315bef72","metadata":{"id":"315bef72","outputId":"3a20fca4-59c4-48bd-ca59-e1f2aef747c1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758246394651,"user_tz":240,"elapsed":84,"user":{"displayName":"Bruno Magalhaes Nogueira","userId":"18320277366917905276"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Entrada (encoder): ['o', 'livro', 'está', 'na', 'mesa']\n","Token alvo (decoder, passo t): table(?) \n","\n","FORMAS (shapes):\n","Q (decoder): (1, 1, 8) | K (encoder): (1, 5, 8) | V (encoder): (1, 5, 8) \n","\n","SCORES (antes do softmax) para cada token da ENTRADA (ordem = ['o', 'livro', 'está', 'na', 'mesa'] ):\n","[ 4.636 -3.248  5.583 -6.994 -4.55 ] \n","\n","PESOS DE ATENÇÃO (após softmax) – somam ~1 na linha:\n","[0.28 0.   0.72 0.   0.  ]\n","Soma: 0.9999999999999999 \n","\n","Ordem de relevância (do mais atendido ao menos):\n"," 1. token='está'  peso=0.720\n"," 2. token='o'  peso=0.280\n"," 3. token='livro'  peso=0.000\n"," 4. token='mesa'  peso=0.000\n"," 5. token='na'  peso=0.000\n","\n","SAÍDA CONTEXTUALIZADA (O) que o decoder usaria para prever o próximo token:\n","[ 6.042  4.388 -2.767  0.136  1.298 -1.439  1.153 -4.01 ]\n","\n","[Diagnóstico] Sem dividir por sqrt(d_k), os pesos (softmax) ficam:\n","[0.064 0.    0.936 0.    0.   ]  (pode saturar em d_k grandes)\n","\n","Resumo:\n","- Temos 1 consulta (decoder, para gerar 'table(?)') e 5 chaves/valores (encoder).\n","- Calculamos similaridade Q·K^T/√d_k, aplicamos softmax → isso diz QUANTO olhar para cada palavra da entrada.\n","- Com esses pesos, combinamos os VALORES (V) da entrada para construir uma representação contextualizada (O).\n","- O substitui o 'vetor fixo' do seq2seq clássico: agora o decoder puxa DINAMICAMENTE a informação relevante da entrada.\n"]}],"source":["# Demonstração passo a passo de ATENÇÃO (encoder–decoder) com matrizes pequenas e prints didáticos\n","import numpy as np\n","\n","np.set_printoptions(suppress=True, linewidth=120, precision=3)\n","\n","# 0) Sequências e tokens (exemplo de tradução simples)\n","src_tokens = [\"o\", \"livro\", \"está\", \"na\", \"mesa\"]   # entrada (encoder)\n","# passo atual do decoder (vamos supor que estamos para gerar \"table\" em inglês, consultando a entrada em pt)\n","tgt_step_token = \"table(?)\"  # \"palavra-alvo\" que o decoder está tentando gerar agora\n","\n","print(\"Entrada (encoder):\", src_tokens)\n","print(\"Token alvo (decoder, passo t):\", tgt_step_token, \"\\n\")\n","\n","# 1) Embeddings simples e pesos de projeção (didáticos, aleatórios mas fixos)\n","rng = np.random.default_rng(110)\n","d_model = 8   # dimensão \"do mundo\" (pequena pra caber na tela)\n","d_k = 8       # para simplificar, d_k = d_model\n","d_v = 8\n","\n","# embeddings da entrada (encoder) – 1 vetor por token\n","X_src = rng.normal(size=(1, len(src_tokens), d_model))\n","\n","# embedding do estado atual do decoder (p.ex., a palavra anterior + contexto do decoder)\n","# para a narrativa, vamos usar um vetor que representa \"o que estou tentando gerar\" (uma query)\n","y_t = rng.normal(size=(1, 1, d_model))\n","\n","# matrizes de projeção treináveis (aqui, só para demonstração)\n","WQ_dec = rng.normal(size=(d_model, d_k))  # Q vem do decoder\n","WK_enc = rng.normal(size=(d_model, d_k))  # K vem do encoder\n","WV_enc = rng.normal(size=(d_model, d_v))  # V vem do encoder\n","\n","# 2) Projeções: Q do decoder, K e V do encoder\n","Q = y_t @ WQ_dec           # (1, 1, d_k)\n","K = X_src @ WK_enc         # (1, T_src, d_k)\n","V = X_src @ WV_enc         # (1, T_src, d_v)\n","\n","print(\"FORMAS (shapes):\")\n","print(\"Q (decoder):\", Q.shape, \"| K (encoder):\", K.shape, \"| V (encoder):\", V.shape, \"\\n\")\n","\n","# 3) Scores de atenção (similaridade) entre a \"consulta\" do decoder (Q) e todas as \"chaves\" do encoder (K)\n","#    S = Q K^T / sqrt(d_k)  → aqui temos apenas 1 query (passo t do decoder), então S: (1, 1, T_src)\n","scores = (Q @ np.transpose(K, (0, 2, 1))) / np.sqrt(d_k)  # (1, 1, T_src)\n","\n","# 4) Softmax nos scores para virar distribuição de probabilidade sobre os tokens de entrada\n","def softmax(x, axis=-1):\n","    x = x - np.max(x, axis=axis, keepdims=True)  # estabilidade numérica\n","    e = np.exp(x)\n","    return e / np.sum(e, axis=axis, keepdims=True)\n","\n","attn_weights = softmax(scores, axis=-1)  # (1, 1, T_src)\n","\n","# 5) Combinação convexa dos VALORES (V): O = A · V  → saída contextualizada que o decoder usará para prever o próximo token\n","O = attn_weights @ V  # (1, 1, d_v)\n","\n","print(\"SCORES (antes do softmax) para cada token da ENTRADA (ordem =\", src_tokens, \"):\")\n","print(scores.reshape(-1), \"\\n\")\n","\n","print(\"PESOS DE ATENÇÃO (após softmax) – somam ~1 na linha:\")\n","print(np.round(attn_weights.reshape(-1), 3))\n","print(\"Soma:\", float(np.sum(attn_weights)), \"\\n\")\n","\n","# 6) Interpretabilidade: listar tokens de entrada por atenção decrescente (top-k)\n","top_idx = np.argsort(-attn_weights.reshape(-1))\n","print(\"Ordem de relevância (do mais atendido ao menos):\")\n","for rank, j in enumerate(top_idx.tolist(), start=1):\n","    print(f\"{rank:>2}. token='{src_tokens[j]}'  peso={attn_weights.reshape(-1)[j]:.3f}\")\n","\n","print(\"\\nSAÍDA CONTEXTUALIZADA (O) que o decoder usaria para prever o próximo token:\")\n","print(np.round(O.reshape(-1), 3))\n","\n","# 7) (Opcional) Efeito da normalização por sqrt(d_k):\n","scores_no_scale = (Q @ np.transpose(K, (0, 2, 1)))  # sem dividir por sqrt(d_k)\n","attn_no_scale = softmax(scores_no_scale, axis=-1)\n","print(\"\\n[Diagnóstico] Sem dividir por sqrt(d_k), os pesos (softmax) ficam:\")\n","print(np.round(attn_no_scale.reshape(-1), 3), \" (pode saturar em d_k grandes)\")\n","\n","# 8) Sanidade: verificar que a soma dos pesos é 1 (distribuição)\n","assert np.allclose(np.sum(attn_weights, axis=-1), 1.0, atol=1e-6), \"Softmax não somou 1 (algo errado).\"\n","\n","# 9) Resumo textual final (conectando com a narrativa)\n","print(\"\\nResumo:\")\n","print(f\"- Temos 1 consulta (decoder, para gerar '{tgt_step_token}') e {len(src_tokens)} chaves/valores (encoder).\")\n","print(\"- Calculamos similaridade Q·K^T/√d_k, aplicamos softmax → isso diz QUANTO olhar para cada palavra da entrada.\")\n","print(\"- Com esses pesos, combinamos os VALORES (V) da entrada para construir uma representação contextualizada (O).\")\n","print(\"- O substitui o 'vetor fixo' do seq2seq clássico: agora o decoder puxa DINAMICAMENTE a informação relevante da entrada.\")"]},{"cell_type":"markdown","id":"3d905471","metadata":{"id":"3d905471"},"source":["\n","### 4.1) Visualizando pesos de atenção com tokens (mini-demo)\n","\n","Vamos usar uma frase curta. Atribuiremos embeddings artificiais (aleatórios) apenas para **visualização**.  \n","**Objetivo**: ver a **matriz de atenção** (quem olha para quem).\n"]},{"cell_type":"code","execution_count":7,"id":"7f273636","metadata":{"id":"7f273636","outputId":"bfb696bb-2d81-4bae-85ca-2d8707ee5ec0","colab":{"base_uri":"https://localhost:8080/","height":511},"executionInfo":{"status":"ok","timestamp":1758246358007,"user_tz":240,"elapsed":345,"user":{"displayName":"Bruno Magalhaes Nogueira","userId":"18320277366917905276"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Matriz de atenção (linhas = tokens consultando; colunas = tokens atendidos):\n","\n","[[0.   0.   0.   1.  ]\n"," [0.77 0.   0.   0.23]\n"," [0.71 0.28 0.   0.  ]\n"," [0.1  0.9  0.   0.  ]]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 500x400 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def attention_heatmap(tokens, att_matrix, title=\"Pesos de Atenção\"):\n","    \"\"\"Mostra um heatmap simples dos pesos de atenção (T x T).\n","    tokens: lista de strings (tamanho T)\n","    att_matrix: (T, T) para um único exemplo/consulta\n","    \"\"\"\n","    plt.figure(figsize=(5,4))\n","    plt.imshow(att_matrix)\n","    plt.colorbar()\n","    plt.xticks(range(len(tokens)), tokens, rotation=45, ha='right')\n","    plt.yticks(range(len(tokens)), tokens)\n","    plt.title(title)\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Frase simples\n","tokens = [\"o\", \"livro\", \"está\", \"aqui\"]\n","T = len(tokens)\n","d = 8\n","\n","np.random.seed(7)\n","X = np.random.randn(1, T, d)  # embeddings aleatórios\n","Wq = np.random.randn(d, d); Wk = np.random.randn(d, d); Wv = np.random.randn(d, d)\n","Q = X @ Wq; K = X @ Wk; V = X @ Wv\n","\n","def softmax(x, axis=-1):\n","    x = x - np.max(x, axis=axis, keepdims=True)\n","    e = np.exp(x)\n","    return e / np.sum(e, axis=axis, keepdims=True)\n","\n","d_k = d\n","scores = (Q @ K.transpose(0,2,1)) / np.sqrt(d_k)   # (1, T, T)\n","weights = softmax(scores, axis=-1)[0]              # (T, T) – sem máscara\n","\n","print(\"Matriz de atenção (linhas = tokens consultando; colunas = tokens atendidos):\\n\")\n","print(np.round(weights, 2))\n","\n","attention_heatmap(tokens, weights, title=\"Self-Attention (sem máscara)\")\n"]},{"cell_type":"code","source":[],"metadata":{"id":"RNua6BEqnTE7"},"id":"RNua6BEqnTE7","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"env-misc","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}