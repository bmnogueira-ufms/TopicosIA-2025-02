{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f96154",
   "metadata": {},
   "source": [
    "# Transformers - Parte 1 (Encoder + Scaled Dot-Product Attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b054ab",
   "metadata": {},
   "source": [
    "## 1. Intuição rápida: a grande troca\n",
    "\n",
    "**Transformers** fazem uma troca fundamental: substituem *recorrência* e *convolução* por **atenção**.  \n",
    "Em vez de processar palavras em sequência (como RNNs) ou com janelas locais (como CNNs), o Transformer permite que cada posição **\"olhe\" diretamente** para **qualquer outra posição** da sequência — e **em paralelo**.\n",
    "\n",
    "**Vantagens práticas:**\n",
    "- **Paralelização** massiva no treino (processa toda a sequência de uma vez)\n",
    "- **Dependências longas** mais fáceis (um token pode \"puxar\" informação distante sem atravessar vários passos)\n",
    "- **Capacidade de compor relações** variadas quando usamos **múltiplas cabeças** (cada cabeça aprende um \"padrão\" diferente)\n",
    "\n",
    "---\n",
    "\n",
    "### Motivação e Gap (do artigo *Attention Is All You Need*)\n",
    "\n",
    "Antes dos Transformers, os modelos de transdução de sequência (como tradução automática, modelagem de linguagem etc.) eram dominados por **redes recorrentes** (RNNs, LSTMs, GRUs) ou **redes convolucionais** (CNNs). Embora eficazes, esses modelos apresentavam **limitações importantes**:\n",
    "\n",
    "- **Natureza sequencial do processamento**:  \n",
    "  Nas RNNs, cada passo depende do anterior. Isso impede a paralelização durante o treinamento dentro de uma mesma sequência, tornando o processo lento e custoso. Quanto mais longa a sequência, maior o problema de memória e tempo de treinamento.\n",
    "\n",
    "- **Dificuldade em capturar dependências longas**:  \n",
    "  CNNs e variantes como ConvS2S e ByteNet permitiram maior paralelização, mas a complexidade para relacionar dois tokens cresce com a distância entre eles (linear ou logarítmica). Isso torna mais difícil aprender dependências de longo alcance.\n",
    "\n",
    "- **Uso limitado de atenção**:  \n",
    "  Até então, mecanismos de atenção já eram usados em conjunto com RNNs, ajudando a modelar dependências distantes. Mas quase nunca eram aplicados de forma **independente** — ou seja, sem recorrer a camadas recorrentes ou convolucionais.\n",
    "\n",
    "**O gap identificado:**  \n",
    "Faltava uma arquitetura que conseguisse:  \n",
    "1. **Dispensar completamente a recorrência e a convolução**, mantendo (ou melhorando) a qualidade dos resultados.  \n",
    "2. **Aproveitar atenção de forma plena**, capturando dependências globais de forma direta e com custo constante (independente da distância entre tokens).  \n",
    "3. **Permitir paralelização massiva**, reduzindo drasticamente o tempo de treinamento.\n",
    "\n",
    "**A proposta do paper:**  \n",
    "O **Transformer**, baseado *apenas* em mecanismos de atenção (self-attention), que elimina recorrência e convolução, atinge **maior qualidade em tradução automática**, com muito mais paralelização e menor tempo de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6e1f63",
   "metadata": {},
   "source": [
    "## 2. Figura clássica do Transformer — explicação passo a passo (o que sai de cada pedaço)\n",
    "\n",
    "<br/>\n",
    "<img src=\"https://raw.githubusercontent.com/bmnogueira-ufms/TopicosIA-2025-02/main/images/transformers_architecture.png\" width=\"60%%\">\n",
    "\n",
    "Fonte: Paper Attention is all you need (Wasani et al., 2017)\n",
    "\n",
    "> **Mapa mental rápido (valores típicos do paper):**  \n",
    "> - Camadas: **N = 6** no encoder e **N = 6** no decoder  \n",
    "> - Dimensão do modelo: **d_model = 512**  \n",
    "> - Cabeças de atenção: **h = 8**, com **d_k = d_v = d_model / h = 64**  \n",
    "> - Feed-Forward interno: **d_ff = 2048**  \n",
    "> Essas escolhas aparecem na descrição oficial do modelo e na Seção 3 do artigo. \n",
    "\n",
    "**Convenções de forma (shapes):**  \n",
    "- **B** = batch size  \n",
    "- **n** = comprimento da sequência de entrada (source)  \n",
    "- **m** = comprimento da sequência de saída (target)  \n",
    "- **|V|** = tamanho do vocabulário  \n",
    "- Tensores são do tipo `(B, seq_len, dimensão)`, salvo indicação contrária.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1) Inputs → *Tokenização*\n",
    "**Entrada:** texto bruto (frases em linguagem natural).  \n",
    "**Saída:** tensores de *ids* inteiros `(B, n)` para o **source** e `(B, m)` para o **target** (no treino, o target é deslocado para a direita — *shifted right*).  \n",
    "**Intuição:** transformar palavras/subpalavras em índices para que possamos buscar vetores na tabela de embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2) *Input/Output Embedding*\n",
    "**Entrada:** ids `(B, n)` (source) e `(B, m)` (target).  \n",
    "**Operação:** tabelas de embeddings aprendidas (uma para entrada e outra para saída; no paper há compartilhamento de pesos com a projeção de saída).  \n",
    "**Saída:**  \n",
    "- **Encoder:** `E_src ∈ ℝ^{B×n×d_model}`  \n",
    "- **Decoder (pré-máscara):** `E_tgt ∈ ℝ^{B×m×d_model}`  \n",
    "**Intuição:** cada token vira um vetor denso em `d_model`; é o “espaço onde o modelo pensa”. O paper comenta embeddings aprendidos e o uso do *linear + softmax* no topo para prever o próximo token.  \n",
    "---\n",
    "\n",
    "### 2.3) **Positional Encoding (PE)** + soma aos embeddings\n",
    "**Entrada:** `E_src`, `E_tgt`.  \n",
    "**Operação:** adicionar encodings de posição (senoidais no paper) **elemento a elemento** aos embeddings.  \n",
    "**Saída:**  \n",
    "- **Encoder:** `X_src = E_src + PE_src  ∈ ℝ^{B×n×d_model}`  \n",
    "- **Decoder:** `X_tgt = E_tgt + PE_tgt  ∈ ℝ^{B×m×d_model}`  \n",
    "**Intuição:** como não há recorrência nem convolução, o modelo precisa “saber” a **ordem** dos tokens; PE injeta essa informação desde o início.  \n",
    "---\n",
    "\n",
    "### 2.4) **Encoder** (lado esquerdo da figura) — repetir **N** vezes\n",
    "Cada **bloco de encoder** tem **duas** subcamadas, com **residual + LayerNorm** após cada uma:\n",
    "\n",
    "#### 2.4.1) **Multi-Head Self-Attention** (MHA)\n",
    "**Entrada:** `X_src (ou a saída normalizada da subcamada anterior) ∈ ℝ^{B×n×d_model}`  \n",
    "**Operação:** projetar `Q, K, V` para cada cabeça (h no total), fazer atenção **self** (cada posição pode olhar **todas** as posições do source), concatenar cabeças e projetar de volta para `d_model`.  \n",
    "**Saída:** `H_attn ∈ ℝ^{B×n×d_model}` + (opcional) pesos de atenção por cabeça `α ∈ ℝ^{B×h×n×n}`  \n",
    "**Intuição:** cada posição mistura informação **global** do input; diferentes cabeças capturam **padrões complementares** (ex.: dependências de longo alcance, acordos gramaticais, etc.).  \n",
    "\n",
    "#### 2.4.2) **Add & Norm** (após a atenção)\n",
    "**Entrada:** *skip connection* `X_src` e `H_attn`.  \n",
    "**Saída:** `Y₁ = LayerNorm(X_src + Dropout(H_attn)) ∈ ℝ^{B×n×d_model}`  \n",
    "**Intuição:** preserva a informação original e estabiliza o treino (normalização no pós-soma). O paper especifica residual + LayerNorm após cada subcamada.  \n",
    "\n",
    "#### 2.4.3) **Feed-Forward position-wise (FFN)**\n",
    "**Entrada:** `Y₁`.  \n",
    "**Operação:** **duas** projeções lineares com não linearidade no meio, aplicadas **independentemente por posição**:  \n",
    "`FFN(x) = max(0, x W₁ + b₁) W₂ + b₂`  \n",
    "**Saída:** `H_ffn ∈ ℝ^{B×n×d_model}`  \n",
    "**Intuição:** após “misturar” contexto via atenção, o FFN transforma **cada vetor posição** para extrair/combinar características; pensa nisso como “MLP 1×1” por token.  \n",
    "\n",
    "#### 2.4.4) **Add & Norm** (após o FFN)\n",
    "**Entrada:** `Y₁` e `H_ffn`.  \n",
    "**Saída:** `Z = LayerNorm(Y₁ + Dropout(H_ffn)) ∈ ℝ^{B×n×d_model}`  \n",
    "**Intuição:** mantém o gradiente fluindo (residual) e padroniza estatísticas (LayerNorm). Esse `Z` vira a entrada da **próxima camada de encoder**; ao final da pilha (N×), obtemos a **memória do encoder**. \n",
    "\n",
    "> **Saída final do Encoder (memória):** `M_enc = Z ∈ ℝ^{B×n×d_model}`  \n",
    "> **Intuição:** uma representação rica do input, já contextualizada globalmente.\n",
    "\n",
    "---\n",
    "\n",
    "### 2.5) **Decoder** (lado direito) — repetir **N** vezes\n",
    "Cada **bloco de decoder** tem **três** subcamadas (com residual + LayerNorm após cada uma):\n",
    "\n",
    "#### 2.5.1) **Masked Multi-Head Self-Attention** (MHA com máscara causal)\n",
    "**Entrada:** `X_tgt (ou a saída normalizada anterior) ∈ ℝ^{B×m×d_model}`  \n",
    "**Operação:** atenção **self** no target, **com máscara causal** que zera conexões para posições **futuras** (garante propriedade auto-regressiva).  \n",
    "**Saída:** `H_self ∈ ℝ^{B×m×d_model}`  \n",
    "**Intuição:** cada posição do target só pode olhar **até si mesma** (e anteriores); durante inferência, isso impede olhar o “próximo token” antes de gerá-lo.  \n",
    "\n",
    "#### 2.5.2) **Add & Norm** (após a self-attention do decoder)\n",
    "**Entrada:** `X_tgt` e `H_self`.  \n",
    "**Saída:** `Y₂ = LayerNorm(X_tgt + Dropout(H_self)) ∈ ℝ^{B×m×d_model}`  \n",
    "**Intuição:** preserva representações originais do target e estabiliza o treino (mesma lógica do encoder). \n",
    "\n",
    "#### 2.5.3) **Encoder–Decoder Attention (Cross-Attention)**\n",
    "**Entrada:** `Y₂` (fornece **queries**) e `M_enc` (fornece **keys/values** do encoder).  \n",
    "**Operação:** o decoder “pergunta” à memória do encoder **quais partes do source** são mais relevantes para **cada posição do target**; é MHA normal, mas agora **Q vem do decoder** e **K,V vêm do encoder**.  \n",
    "**Saída:** `H_cross ∈ ℝ^{B×m×d_model}`  \n",
    "**Intuição:** o decoder alinha/consulta o input inteiro para decidir **o que emitir** em cada passo do target. \n",
    "\n",
    "#### 2.5.4) **Add & Norm** (após a cross-attention)\n",
    "**Entrada:** `Y₂` e `H_cross`.  \n",
    "**Saída:** `Y₃ = LayerNorm(Y₂ + Dropout(H_cross)) ∈ ℝ^{B×m×d_model}`  \n",
    "**Intuição:** mistura informação do target com a **memória do encoder** de forma estável. \n",
    "\n",
    "#### 2.5.5) **Feed-Forward position-wise (FFN)**\n",
    "**Entrada:** `Y₃`.  \n",
    "**Operação:** mesmo MLP por posição do encoder (duas lineares + ReLU).  \n",
    "**Saída:** `H_ffn_dec ∈ ℝ^{B×m×d_model}`  \n",
    "**Intuição:** refina a representação por posição no target, após integrar contexto do input. \n",
    "\n",
    "#### 2.5.6) **Add & Norm** (após o FFN)\n",
    "**Entrada:** `Y₃` e `H_ffn_dec`.  \n",
    "**Saída:** `Z_dec = LayerNorm(Y₃ + Dropout(H_ffn_dec)) ∈ ℝ^{B×m×d_model}`  \n",
    "**Intuição:** esta é a **saída da camada do decoder**; após repetir **N** vezes, obtemos a **representação final do decoder** para cada posição do target.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2.6) **Linear → Softmax** (cabeçalho de saída)\n",
    "**Entrada:** `Z_dec ∈ ℝ^{B×m×d_model}`  \n",
    "**Operação:** projeção linear para o tamanho do vocabulário + softmax por token.  \n",
    "**Saída:** `logits ∈ ℝ^{B×m×|V|}` → `probs ∈ ℝ^{B×m×|V|}`  \n",
    "**Intuição:** para cada posição do target, obtemos uma **distribuição de probabilidade** sobre o próximo token; no treino, com *teacher forcing*, comparamos com o token-verdadeiro; na geração, usamos a **última posição** e amostramos/pegamos o argmax para produzir o próximo símbolo. \n",
    "\n",
    "---\n",
    "\n",
    "### 2.7) Por que isso funciona bem\n",
    "- **Paralelização:** o encoder e a parte “por bloco” do decoder operam **em paralelo** nas posições da sequência (exceto pela máscara causal no decoder), superando o gargalo **sequencial** das RNNs.   \n",
    "- **Dependências longas:** a self-attention conecta qualquer par de posições com **custo constante em camadas**, em contraste com CNNs (custo cresce com a distância); as **múltiplas cabeças** ajudam a mitigar a perda de “resolução” média. \n",
    "\n",
    "> **Resumo visual da figura:**  \n",
    "> Esquerda = **Encoder (N×)** com: *[Input Embedding + PE]* → **MHA** → **Add&Norm** → **FFN** → **Add&Norm**.  \n",
    "> Direita = **Decoder (N×)** com: *[Output Embedding + PE]* → **Masked MHA** → **Add&Norm** → **Cross MHA (com memória do encoder)** → **Add&Norm** → **FFN** → **Add&Norm** → **Linear + Softmax**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b683270",
   "metadata": {},
   "source": [
    "## 3. Relembrando a fórmula da atenção (Scaled Dot-Product)\n",
    "\n",
    "Dado um conjunto de vetores:\n",
    "- **Q** (*queries*), **K** (*keys*) e **V** (*values*),\n",
    "- Calculamos **similaridades** com `Q Kᵀ`, **escalamos** por `√dₖ`,\n",
    "- Aplicamos **softmax** para virar **pesos**, e\n",
    "- Fazemos a **média ponderada** dos valores **V**:\n",
    "\n",
    "$$\n",
    "\\text{Attention}(Q,K,V) = \\text{softmax}\\!\\left(\\frac{Q K^\\top}{\\sqrt{d_k}}\\right) V\n",
    "$$\n",
    "\n",
    "**Por que dividir por $\\sqrt{d_k}$?**  \n",
    "Sem essa divisão, quando a dimensionalidade \\(d_k\\) cresce, os produtos internos podem ficar muito grandes, empurrando a distribuição do softmax para extremos. A escala \\(\\sqrt{d_k}\\) ajuda a manter os logits em uma faixa mais estável, melhorando gradientes e treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde9c6db",
   "metadata": {},
   "source": [
    "## 4. Anatomia do encoder\n",
    "\n",
    "**Uma camada de encoder** (a típica do Transformer) contém:\n",
    "1) **Self-Attention** (aqui, sem máscara)  \n",
    "2) **Residual + LayerNorm**  \n",
    "3) **Feed-Forward** position-wise (duas lineares + não linearidade)  \n",
    "4) **Residual + LayerNorm** novamente\n",
    "\n",
    "**Importante:** Aqui implementaremos o \"miolo\" da etapa (1), com **uma cabeça** para enxergar as formas e pesos. Depois, generalizamos para **múltiplas cabeças** (multi-head) e integramos todo o bloco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d97b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_seed(s=42):\n",
    "    random.seed(s)\n",
    "    np.random.seed(s)\n",
    "    torch.manual_seed(s)\n",
    "    torch.cuda.manual_seed_all(s)\n",
    "\n",
    "set_seed(7)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def shape(x, name=None):\n",
    "    \"\"\"Imprime forma, dtype e device de um tensor para facilitar a didática.\"\"\"\n",
    "    tag = f\"[{name}] \" if name else \"\"\n",
    "    print(f\"{tag}shape={tuple(x.shape)}  dtype={x.dtype}  device={x.device}\")\n",
    "\n",
    "def peek(x, n=3):\n",
    "    \"\"\"Mostra os n primeiros elementos do tensor (no CPU) para inspeção.\"\"\"\n",
    "    print(x.detach().cpu().numpy()[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a76b4da",
   "metadata": {},
   "source": [
    "## 5. Implementação simples da Scaled Dot-Product Attention (uma cabeça)\n",
    "\n",
    "O plano:\n",
    "1) Receber tensores **Q**, **K** e **V** com formas compatíveis  \n",
    "2) Calcular os **logits** = $ QK^\\top / \\sqrt{d_k} $  \n",
    "3) Aplicar **máscara** (se houver) para \"zerar\" posições proibidas  \n",
    "4) Rodar **softmax** (ao longo do eixo das chaves) → **pesos**  \n",
    "5) Multiplicar por **V** → **saída** da atenção  \n",
    "6) Retornar também os **pesos** para podermos visualizá-los"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c163f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaled Dot-Product Attention (uma cabeça), com máscara opcional\n",
    "def scaled_dot_product_attention(Q, K, V, mask=None):\n",
    "    \"\"\"\n",
    "    Parâmetros:\n",
    "      Q: (batch, seq_q, d_k)\n",
    "      K: (batch, seq_k, d_k)\n",
    "      V: (batch, seq_k, d_v)\n",
    "      mask: (batch, seq_q, seq_k) com 1 onde PODE atender e 0 onde NÃO pode\n",
    "\n",
    "    Retorno:\n",
    "      out: (batch, seq_q, d_v)\n",
    "      attn_weights: (batch, seq_q, seq_k)\n",
    "    \"\"\"\n",
    "    d_k = Q.size(-1)\n",
    "    # 1) Logits de atenção (similaridade entre consultas e chaves), com escala\n",
    "    logits = torch.matmul(Q, K.transpose(-1, -2)) / math.sqrt(d_k)  # (B, seq_q, seq_k)\n",
    "\n",
    "    # 2) Máscara opcional: posições proibidas recebem -inf → peso ~ 0 após softmax\n",
    "    if mask is not None:\n",
    "        logits = logits.masked_fill(mask == 0, float(\"-inf\"))\n",
    "\n",
    "    # 3) Softmax para virar distribuição de probabilidade (pesos por linha)\n",
    "    attn_weights = F.softmax(logits, dim=-1)  # (B, seq_q, seq_k)\n",
    "\n",
    "    # 4) Combina valores V segundo os pesos\n",
    "    out = torch.matmul(attn_weights, V)       # (B, seq_q, d_v)\n",
    "    return out, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf51b9",
   "metadata": {},
   "source": [
    "## 6. Exemplo de **pesos de atenção reais**\n",
    "\n",
    "Vamos usar uma frase curtinha em português. Não vamos treinar nada; só faremos *forward* para **visualizar como cada token \"olha\" para os demais**.\n",
    "\n",
    "- Tokenização simples por espaço (para fins didáticos)  \n",
    "- Vocabulário pequeno, incluindo `<bos>` (início) e `<eos>` (fim)  \n",
    "- **Embeddings aleatórios** apenas para visualizar formas e o fluxo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "643e1b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5, 6, 7, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocabulário mínimo e tokenização simples \n",
    "vocab = {\n",
    "    \"<pad>\": 0, \"<bos>\": 1, \"<eos>\": 2,\n",
    "    \"o\": 3, \"gato\": 4, \"preto\": 5, \"correu\": 6, \".\": 7\n",
    "}\n",
    "ivocab = {i: t for t, i in vocab.items()}\n",
    "\n",
    "def tokenize(text):\n",
    "    return text.lower().strip().split()\n",
    "\n",
    "def encode(tokens, add_bos=True, add_eos=True):\n",
    "    ids = []\n",
    "    if add_bos: ids.append(vocab[\"<bos>\"])\n",
    "    for t in tokens:\n",
    "        ids.append(vocab.get(t, vocab[\"<pad>\"]))\n",
    "    if add_eos: ids.append(vocab[\"<eos>\"])\n",
    "    return ids\n",
    "\n",
    "sent_pt = \"O gato preto correu .\"\n",
    "ids = encode(tokenize(sent_pt))\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01883d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[emb] shape=(1, 7, 16)  dtype=torch.float32  device=cpu\n",
      "[[ 0.54  -1.817  1.748 -0.21   1.767 -1.367 -0.178  0.084  1.093 -0.683\n",
      "   0.602  0.187 -1.681  0.766 -0.124  1.078]\n",
      " [ 0.368  1.156  0.428  1.666  0.767 -0.685  0.528 -0.067  0.008  0.01\n",
      "  -1.918  1.062  0.369 -1.172 -2.315 -0.463]\n",
      " [ 0.014  1.636 -0.861 -0.042  0.137  0.104  0.611  0.05  -0.329 -1.987\n",
      "  -1.74  -0.894  0.564 -0.68  -0.353 -0.373]]\n"
     ]
    }
   ],
   "source": [
    "# (cont.) — Embeddings aleatórios para visualizar formas\n",
    "d_model = 16  # pequeno para facilitar impressão/entendimento\n",
    "embedding = nn.Embedding(num_embeddings=len(vocab), embedding_dim=d_model)\n",
    "\n",
    "x = torch.tensor(ids, dtype=torch.long).unsqueeze(0)  # (1, seq)\n",
    "emb = embedding(x).to(device)                         # (1, seq, d_model)\n",
    "\n",
    "shape(emb, \"emb\")\n",
    "peek(emb[0], n=3)  # mostra só os 3 primeiros vetores da sequência"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d678bcbe",
   "metadata": {},
   "source": [
    "## 7. Projeções lineares: gerando Q, K, V (1 cabeça)\n",
    "\n",
    "Atenção funciona com três conjuntos de vetores:\n",
    "- **Queries (Q)**: \"o que estou buscando?\"\n",
    "- **Keys (K)**: \"que tipo de informação guardo?\"\n",
    "- **Values (V)**: \"qual informação entrego quando sou relevante?\"\n",
    "\n",
    "Na prática, obtemos Q/K/V aplicando **projeções lineares** ao mesmo `emb` (ou seja, três `Linear` diferentes).  \n",
    "Nesta sessão, faremos **apenas 1 cabeça**. Na próxima, veremos **multi-head**, onde particionamos o espaço em subespaços para aprender *padrões complementares*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce60ed2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q] shape=(1, 7, 16)  dtype=torch.float32  device=cpu\n",
      "[K] shape=(1, 7, 16)  dtype=torch.float32  device=cpu\n",
      "[V] shape=(1, 7, 16)  dtype=torch.float32  device=cpu\n"
     ]
    }
   ],
   "source": [
    "# 1.8 — Projeções lineares para Q/K/V (uma cabeça)\n",
    "d_k = d_v = d_model  # para 1 cabeça didática, mantemos igual\n",
    "W_Q = nn.Linear(d_model, d_k, bias=False).to(device)\n",
    "W_K = nn.Linear(d_model, d_k, bias=False).to(device)\n",
    "W_V = nn.Linear(d_model, d_v, bias=False).to(device)\n",
    "\n",
    "Q = W_Q(emb)  # (1, seq, d_k)\n",
    "K = W_K(emb)  # (1, seq, d_k)\n",
    "V = W_V(emb)  # (1, seq, d_v)\n",
    "\n",
    "shape(Q, \"Q\"); shape(K, \"K\"); shape(V, \"V\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00853e3f",
   "metadata": {},
   "source": [
    "## 8. Self-Attention no encoder (sem máscara)\n",
    "\n",
    "No **encoder**, todas as posições **podem** se atender mutuamente (não há \"futuro proibido\").  \n",
    "Vamos calcular a saída de atenção e inspecionar **as formas** e **os pesos**:\n",
    "\n",
    "- `out` tem mesma quantidade de posições que a entrada, mas cada posição agora é uma **combinação ponderada** dos `V` de todas as posições (segundo os pesos aprendidos).\n",
    "- `attn_weights[i, j]` indica **quanto** a posição *i* \"olhou\" para a posição *j*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac04a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[out] shape=(1, 7, 16)  dtype=torch.float32  device=cpu\n",
      "[attn_weights] shape=(1, 7, 7)  dtype=torch.float32  device=cpu\n",
      "Tokens: ['<bos>', 'o', 'gato', 'preto', 'correu', '.', '<eos>']\n",
      "\n",
      "Pesos de atenção para o token na posição 0:\n",
      "[0.077 0.11  0.165 0.109 0.144 0.126 0.269]\n",
      "\n",
      "Matriz de atenção (valores ~ somam 1 por linha):\n",
      "[[0.077 0.11  0.165 0.109 0.144 0.126 0.269]\n",
      " [0.161 0.212 0.112 0.237 0.058 0.139 0.081]\n",
      " [0.093 0.125 0.215 0.183 0.109 0.14  0.135]\n",
      " [0.139 0.138 0.157 0.094 0.195 0.117 0.159]\n",
      " [0.193 0.125 0.14  0.16  0.136 0.135 0.111]\n",
      " [0.164 0.098 0.145 0.121 0.18  0.136 0.155]\n",
      " [0.106 0.113 0.136 0.144 0.237 0.165 0.1  ]]\n"
     ]
    }
   ],
   "source": [
    "# 1.9 — Atenção do encoder (sem máscara)\n",
    "out, attn = scaled_dot_product_attention(Q, K, V, mask=None)\n",
    "\n",
    "shape(out,  \"out\")\n",
    "shape(attn, \"attn_weights\")\n",
    "\n",
    "# Tokens correspondentes às posições\n",
    "tokens = [ivocab[i] for i in ids]\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Pesos de atenção da primeira posição (índice 0)\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(\"\\nPesos de atenção para o token na posição 0:\")\n",
    "print(attn[0, 0].detach().cpu().numpy())\n",
    "\n",
    "# \"tabelinha amigável\" (linhas=consultas, colunas=chaves)\n",
    "print(\"\\nMatriz de atenção (valores ~ somam 1 por linha):\")\n",
    "mat = attn[0].detach().cpu().numpy()\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c3c4c6",
   "metadata": {},
   "source": [
    "## 9. Visualização: heatmap dos pesos de atenção\n",
    "\n",
    "Para fins pedagógicos, um heatmap ajuda a **enxergar** rapidamente padrões (por exemplo, o token \"preto\" atendendo mais \"gato\").  \n",
    "Se você estiver em um ambiente sem interface gráfica, pode pular esta etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fbe9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.10 — Heatmap simples dos pesos de atenção\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_attn(attn_matrix, tokens, title=\"Atenção (encoder, 1 cabeça)\"):\n",
    "    \"\"\"\n",
    "    attn_matrix: (seq, seq) — uma única matriz (por exemplo, attn[0])\n",
    "    tokens: lista de strings com o rótulo de cada posição\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    im = ax.imshow(attn_matrix, aspect=\"auto\")\n",
    "    ax.set_xticks(range(len(tokens)))\n",
    "    ax.set_yticks(range(len(tokens)))\n",
    "    ax.set_xticklabels(tokens, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(tokens)\n",
    "    ax.set_xlabel(\"Chaves (K)\")\n",
    "    ax.set_ylabel(\"Consultas (Q)\")\n",
    "    ax.set_title(title)\n",
    "    plt.colorbar(im)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_attn(attn[0].detach().cpu().numpy(), tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f58c50",
   "metadata": {},
   "source": [
    "## 10. A Rede Feed-Forward Position-Wise (FFN)\n",
    "\n",
    "Dentro de **cada camada** do encoder e do decoder, além da atenção, existe uma **rede feed-forward totalmente conectada**, aplicada **separadamente em cada posição** da sequência.  \n",
    "\n",
    "No artigo *Attention Is All You Need*, ela é definida assim :\n",
    "\n",
    "$$\n",
    "\\text{FFN}(x) = \\max(0, \\, xW_1 + b_1)\\, W_2 + b_2\n",
    "$$\n",
    "\n",
    "### Estrutura\n",
    "- **Entrada:** vetor de dimensão `d_model` (ex.: 512).  \n",
    "- **Primeira transformação linear:** projeta para uma dimensão maior, chamada `d_ff` (no paper, 2048).  \n",
    "- **ReLU:** ativações não lineares, dando capacidade de aprender transformações complexas.  \n",
    "- **Segunda transformação linear:** projeta de volta para `d_model`.  \n",
    "- **Saída:** vetor refinado, mesma dimensão da entrada (`d_model`).\n",
    "\n",
    "### Formas (shapes)\n",
    "Se a entrada da camada for `(B, seq_len, d_model)`:\n",
    "1. Primeira linear → `(B, seq_len, d_ff)`  \n",
    "2. ReLU → `(B, seq_len, d_ff)`  \n",
    "3. Segunda linear → `(B, seq_len, d_model)`  \n",
    "4. Resultado final → mesma forma da entrada, mas com **informação transformada**.\n",
    "\n",
    "### Intuição\n",
    "- A **atenção** mistura informações **entre diferentes posições** da sequência.  \n",
    "- A **FFN** atua **dentro de cada posição individualmente**, como se fosse um pequeno MLP aplicado token a token.  \n",
    "- É como se o modelo tivesse dois momentos complementares:  \n",
    "  - **Atenção:** decide *“de onde puxar informação”*.  \n",
    "  - **FFN:** decide *“como processar essa informação dentro do token”*.  \n",
    "\n",
    "### Detalhes importantes\n",
    "- Os **pesos** (`W1`, `W2`, `b1`, `b2`) são **iguais para todas as posições** da sequência (compartilhados), garantindo consistência.  \n",
    "- Mas **cada camada** do encoder e do decoder tem **seu próprio conjunto de pesos** — ou seja, a camada 3 não compartilha parâmetros com a camada 4.  \n",
    "- Outra forma de ver: o FFN é equivalente a **duas convoluções 1×1** (kernel size = 1), já que cada posição é processada de forma independente.  \n",
    "\n",
    "👉 Em resumo: a atenção conecta posições diferentes, e a FFN “refina” cada posição individualmente. Juntas, elas permitem que cada token seja informado pelo contexto global e, ao mesmo tempo, processado localmente para extrair representações mais expressivas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab03a16b",
   "metadata": {},
   "source": [
    "## 10. Exercício\n",
    "\n",
    "1) **Altere a frase** para “O gato correu .” (remova “preto”).  \n",
    "2) **Reexecute** as células e observe como a **matriz de atenção** muda.  \n",
    "3) Aumente `d_model` para `32` e veja o impacto nos valores.  \n",
    "4) Explique: em que casos você **espera** que “gato” atenda mais a “preto”?  \n",
    "   - Dica: pense na relação *substantivo ↔ adjetivo* e na **co-ocorrência** semântica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54877406",
   "metadata": {},
   "source": [
    "## 11. Considerações Finais\n",
    "\n",
    "Agora que você:\n",
    "- Entendeu a **fórmula central** da atenção e viu pesos reais,\n",
    "- Observou o **fluxo de tensores** (formas de Q, K, V, pesos e saída),\n",
    "\n",
    "…vamos **generalizar**:\n",
    "\n",
    "**Na próxima aula:**\n",
    "- **Multi-Head Attention (MHA)**: dividir o espaço em `h` cabeças ($ d_k = d_v = d_{\\text{model}} / h $), atender **em paralelo** e **concatenar**.  \n",
    "- **Projeção de saída (Wᵒ)** após concatenar as cabeças.  \n",
    "- **Máscara causal** no **decoder** (impedir “olhar o futuro”) e intuição do **modo auto-regressivo**.  \n",
    "- (Logo depois) **Positional Encoding** senoidal: por que resolve a “dor” da ordem, fórmula completa e interpretação geométrica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5191ad",
   "metadata": {},
   "source": [
    "## Referência\n",
    "\n",
    "VASWANI, Ashish; SHAZEER, Noam; PARMAR, Niki; USZKOREIT, Jakob; JONES, Llion; GOMEZ, Aidan N.; KAISER, Łukasz; POLOSUKHIN, Illia. Attention is all you need. In: Advances in Neural Information Processing Systems (NeurIPS 2017). [S.l.: s.n.], 2017. p. 5998–6008."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de7e96",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-misc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
